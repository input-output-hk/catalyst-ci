{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 Welcome to the Catalyst CI documentation! The purpose of this documentation is to familiarize end-users with the various Project Catalyst CI processes. Our team uses a specific subset of technologies to build and deliver our services. It's critical to understand what those tools are and how they interact together in the CI process. The quickest way to get started learning is by going through the onboarding process . For more in-depth documentation, please review the reference section . Before contributing to an Earthfile , please review the style guide . If you want to learn how to build an Earthfile from scratch, check out the available guides .","title":"Introduction"},{"location":"#introduction","text":"Welcome to the Catalyst CI documentation! The purpose of this documentation is to familiarize end-users with the various Project Catalyst CI processes. Our team uses a specific subset of technologies to build and deliver our services. It's critical to understand what those tools are and how they interact together in the CI process. The quickest way to get started learning is by going through the onboarding process . For more in-depth documentation, please review the reference section . Before contributing to an Earthfile , please review the style guide . If you want to learn how to build an Earthfile from scratch, check out the available guides .","title":"Introduction"},{"location":"appendix/","text":"Appendix \u00b6 The appendix contains collections of extra information and examples relevant to Catalyst-CI.","title":"Appendix"},{"location":"appendix/#appendix","text":"The appendix contains collections of extra information and examples relevant to Catalyst-CI.","title":"Appendix"},{"location":"appendix/earthly/","text":"Earthly \u00b6 This appendix is designed to get you quickly up and running with Earthly . Earthly serves a central role in the CI process and is the primary orchestrator along with Github Actions. Getting Started with Earthly \u00b6 Warning The process described in this section is purely for educational purposes. While the CI process does use Earthly, it does so in a very specific and opinionated way. Do not package your service using the methodology shown below. Instead, refer to the onboarding documentation for a description and examples of the proper method. This section will get you started with the basics of Earthly in as little time as possible. To maximize learning, this section is written with a hands-on approach, and you are highly encouraged to follow along. Video \u00b6 If you prefer to learn visually, a video tutorial has been provided which introduces Earthly using a similar hands-on process. !!! note Before starting the video, check out the setup section below to get your local environment prepared to follow along. Pre-requisites \u00b6 The only pre-requisite knowledge that is required is experience working with Docker and Dockerfile s. Since Earthly is built on top of Docker, it's assumed you're already familiar with Docker concepts. Setup \u00b6 Installation \u00b6 See the installation methods available on the Earthly website. Clone the example \u00b6 Note Even though we're using Go, you don't need to be familiar with the language or its tooling. The process we will walk through is generic enough that applying it to other languages should be trivial. To demonstrate how to use Earthly, we'll be using a tiny Go program which simply prints \"Hello, World!\" to the screen. You can get a local copy by performing the following: git clone https://github.com/input-output-hk/catalyst-ci.git && \\ cd examples/onboarding/appendix_earthly Building an Earthfile \u00b6 To begin, we are first going to introduce the most fundamental component of Earthly: the Earthfile . The easiest way to think of an Earthfile is a mix between a Dockerfile and a GNU makefile . Like a Dockerfile , only a single Earthfile can exist per directory and it must be named Earthfile in order to be detected. Sample Structure \u00b6 VERSION 0.8 # This defines the \"schema version\" that this Earthfile satisfies # A target, which is functionally equivalent to a `makefile` target. deps: # A target can be thought of as a group of container image layers (think of Docker multi-stage builds) # For this target, we start by deriving from an image which contains the Go tooling we need FROM golang:1.22.4-alpine3.20 # Earthly has a 1:1 relationship with most Dockerfile commands, but there are a few exceptions WORKDIR /work Go ahead and copy the contents from above to an Earthfile in the local directory you cloned in the previous section. At a foundational level, an Earthfile is very similar to a Dockerfile . The commands are in all uppercase letters and there's typically only one command per line. Schema \u00b6 An Earthfile always starts by specifying a schema version which informs Earthly how it should go about parsing the file. This allows the syntax and format of an Earthfile to evolve while maintaining backwards compatibility. In our case, we target version 0.8 which is the latest version at the time of this writing. Targets \u00b6 An Earthfile also always has at least one target. A target can be thought of as a grouping of image layers, similar to the way multi-stage builds work with Docker. Each target then specifies one or more commands that create the image layers associated with that target. VERSION 0.8 deps: FROM golang:1.22.4-alpine3.20 WORKDIR /work # These commands work identical to their Dockerfile equivalent COPY go.mod go.sum . RUN go mod download src: # This target \"inherits\" from the `deps` target FROM +deps # The --dir flag is unique to Earthly and just ensures the entire directory # is copied (not just the contents inside of it) COPY --dir cmd . Like multi-stage builds, targets can inherit from other targets. In the above case, we now have two targets: the deps target downloads our external dependencies, and the src target copies the source files into the image. The src target inherits the deps target, meaning the go.mod , go.sum , and all externally downloaded dependencies will be present. Artifacts \u00b6 # Omitted for brevity src: FROM +deps COPY --dir cmd . build: FROM +src # This forces go to build a \"static\" binary with no dependencies ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go # This \"exports\" the built binary as an \"output\" of this target SAVE ARTIFACT bin/hello hello In the above example, we introduce yet another target which is responsible for building our Go binary. The above invocation is typical for building static Go binaries. What's new is the usage of SAVE ARTIFACT . This command takes two parameters: the local path inside the container to save, and a name to save it as. In this case, we are saving our binary ( bin/hello ) as hello . With this in place, other targets may now pull in this binary without having to inherit from the image. Our targets don't produce anything useful yet, but this is a good point to stop and actually invoke earthly: earthly +build Earthly provides a CLI which is used for invoking Earthly targets. The format is similar to GNU Make where you add a + followed by the target name. If everything is working correctly, the Earthly run should succeed. Images \u00b6 # Omitted for brevity build: FROM +src ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go SAVE ARTIFACT bin/hello hello docker: # Here we inherit from a \"fresh\" minimal alpine version FROM alpine:3.20.3 WORKDIR /app # By default, we'll output this image with the 'latest' tag, but this can be # changed ARG tag=latest # Since we saved the artifact in the previous target, we can now directly # copy the # binary to this \"fresh\" image with none of the dependency bloat. COPY +build/hello . ENTRYPOINT [\"/app/hello\"] # This tells Earthly that this target produces a container image we want to # use SAVE IMAGE hello:${tag} In the above example, we now add our fourth and final target which is responsible for building the final container image. Instead of inheriting from build , and thereby inheriting all of its bloat, we instead inherit from a \"fresh\" Alpine image. We then use COPY to pull in our binary that we saved from the build target. This is a special Earthly syntax and is a powerful way to copy single outputs from a target without worrying about inheriting the entire context. We also add an ARG which allows us to specify the tag of the image when its created by Earthly. By default, we set it to latest , but it can be changed in a number of ways, one of which is via the CLI: earthly +docker --tag = \"foobar\" If you run the above command, you should see the image show up in your local Docker registry: > docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE hello foobar 61c8a3947c93 About an hour ago 9 .95MB The reason Earthly produces an image is because of the SAVE IMAGE we included at the very end of the Earthfile . This informs Earthly that this target produces an image we actually want to use by saving it locally. You'll notice the size of the image is very small (< 10MB). This is because we started from a base alpine image and only copied the binary from our build target. Additionally, the image was saved with the foobar tag because we provided an alterative value for the tag argument when we called the Earthly CLI. Conclusion \u00b6 Congratulations, you've created your first container image using Earthly. We have only scratched the surface of the features provided by Earthly, and it's highly encouraged that you review the official documentation to learn more. You should now have enough knowledge to continue on with the onboarding process and learn about how Catalyst CI works using Earthly.","title":"Earthly"},{"location":"appendix/earthly/#earthly","text":"This appendix is designed to get you quickly up and running with Earthly . Earthly serves a central role in the CI process and is the primary orchestrator along with Github Actions.","title":"Earthly"},{"location":"appendix/earthly/#getting-started-with-earthly","text":"Warning The process described in this section is purely for educational purposes. While the CI process does use Earthly, it does so in a very specific and opinionated way. Do not package your service using the methodology shown below. Instead, refer to the onboarding documentation for a description and examples of the proper method. This section will get you started with the basics of Earthly in as little time as possible. To maximize learning, this section is written with a hands-on approach, and you are highly encouraged to follow along.","title":"Getting Started with Earthly"},{"location":"appendix/earthly/#video","text":"If you prefer to learn visually, a video tutorial has been provided which introduces Earthly using a similar hands-on process. !!! note Before starting the video, check out the setup section below to get your local environment prepared to follow along.","title":"Video"},{"location":"appendix/earthly/#pre-requisites","text":"The only pre-requisite knowledge that is required is experience working with Docker and Dockerfile s. Since Earthly is built on top of Docker, it's assumed you're already familiar with Docker concepts.","title":"Pre-requisites"},{"location":"appendix/earthly/#setup","text":"","title":"Setup"},{"location":"appendix/earthly/#installation","text":"See the installation methods available on the Earthly website.","title":"Installation"},{"location":"appendix/earthly/#clone-the-example","text":"Note Even though we're using Go, you don't need to be familiar with the language or its tooling. The process we will walk through is generic enough that applying it to other languages should be trivial. To demonstrate how to use Earthly, we'll be using a tiny Go program which simply prints \"Hello, World!\" to the screen. You can get a local copy by performing the following: git clone https://github.com/input-output-hk/catalyst-ci.git && \\ cd examples/onboarding/appendix_earthly","title":"Clone the example"},{"location":"appendix/earthly/#building-an-earthfile","text":"To begin, we are first going to introduce the most fundamental component of Earthly: the Earthfile . The easiest way to think of an Earthfile is a mix between a Dockerfile and a GNU makefile . Like a Dockerfile , only a single Earthfile can exist per directory and it must be named Earthfile in order to be detected.","title":"Building an Earthfile"},{"location":"appendix/earthly/#sample-structure","text":"VERSION 0.8 # This defines the \"schema version\" that this Earthfile satisfies # A target, which is functionally equivalent to a `makefile` target. deps: # A target can be thought of as a group of container image layers (think of Docker multi-stage builds) # For this target, we start by deriving from an image which contains the Go tooling we need FROM golang:1.22.4-alpine3.20 # Earthly has a 1:1 relationship with most Dockerfile commands, but there are a few exceptions WORKDIR /work Go ahead and copy the contents from above to an Earthfile in the local directory you cloned in the previous section. At a foundational level, an Earthfile is very similar to a Dockerfile . The commands are in all uppercase letters and there's typically only one command per line.","title":"Sample Structure"},{"location":"appendix/earthly/#schema","text":"An Earthfile always starts by specifying a schema version which informs Earthly how it should go about parsing the file. This allows the syntax and format of an Earthfile to evolve while maintaining backwards compatibility. In our case, we target version 0.8 which is the latest version at the time of this writing.","title":"Schema"},{"location":"appendix/earthly/#targets","text":"An Earthfile also always has at least one target. A target can be thought of as a grouping of image layers, similar to the way multi-stage builds work with Docker. Each target then specifies one or more commands that create the image layers associated with that target. VERSION 0.8 deps: FROM golang:1.22.4-alpine3.20 WORKDIR /work # These commands work identical to their Dockerfile equivalent COPY go.mod go.sum . RUN go mod download src: # This target \"inherits\" from the `deps` target FROM +deps # The --dir flag is unique to Earthly and just ensures the entire directory # is copied (not just the contents inside of it) COPY --dir cmd . Like multi-stage builds, targets can inherit from other targets. In the above case, we now have two targets: the deps target downloads our external dependencies, and the src target copies the source files into the image. The src target inherits the deps target, meaning the go.mod , go.sum , and all externally downloaded dependencies will be present.","title":"Targets"},{"location":"appendix/earthly/#artifacts","text":"# Omitted for brevity src: FROM +deps COPY --dir cmd . build: FROM +src # This forces go to build a \"static\" binary with no dependencies ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go # This \"exports\" the built binary as an \"output\" of this target SAVE ARTIFACT bin/hello hello In the above example, we introduce yet another target which is responsible for building our Go binary. The above invocation is typical for building static Go binaries. What's new is the usage of SAVE ARTIFACT . This command takes two parameters: the local path inside the container to save, and a name to save it as. In this case, we are saving our binary ( bin/hello ) as hello . With this in place, other targets may now pull in this binary without having to inherit from the image. Our targets don't produce anything useful yet, but this is a good point to stop and actually invoke earthly: earthly +build Earthly provides a CLI which is used for invoking Earthly targets. The format is similar to GNU Make where you add a + followed by the target name. If everything is working correctly, the Earthly run should succeed.","title":"Artifacts"},{"location":"appendix/earthly/#images","text":"# Omitted for brevity build: FROM +src ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go SAVE ARTIFACT bin/hello hello docker: # Here we inherit from a \"fresh\" minimal alpine version FROM alpine:3.20.3 WORKDIR /app # By default, we'll output this image with the 'latest' tag, but this can be # changed ARG tag=latest # Since we saved the artifact in the previous target, we can now directly # copy the # binary to this \"fresh\" image with none of the dependency bloat. COPY +build/hello . ENTRYPOINT [\"/app/hello\"] # This tells Earthly that this target produces a container image we want to # use SAVE IMAGE hello:${tag} In the above example, we now add our fourth and final target which is responsible for building the final container image. Instead of inheriting from build , and thereby inheriting all of its bloat, we instead inherit from a \"fresh\" Alpine image. We then use COPY to pull in our binary that we saved from the build target. This is a special Earthly syntax and is a powerful way to copy single outputs from a target without worrying about inheriting the entire context. We also add an ARG which allows us to specify the tag of the image when its created by Earthly. By default, we set it to latest , but it can be changed in a number of ways, one of which is via the CLI: earthly +docker --tag = \"foobar\" If you run the above command, you should see the image show up in your local Docker registry: > docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE hello foobar 61c8a3947c93 About an hour ago 9 .95MB The reason Earthly produces an image is because of the SAVE IMAGE we included at the very end of the Earthfile . This informs Earthly that this target produces an image we actually want to use by saving it locally. You'll notice the size of the image is very small (< 10MB). This is because we started from a base alpine image and only copied the binary from our build target. Additionally, the image was saved with the foobar tag because we provided an alterative value for the tag argument when we called the Earthly CLI.","title":"Images"},{"location":"appendix/earthly/#conclusion","text":"Congratulations, you've created your first container image using Earthly. We have only scratched the surface of the features provided by Earthly, and it's highly encouraged that you review the official documentation to learn more. You should now have enough knowledge to continue on with the onboarding process and learn about how Catalyst CI works using Earthly.","title":"Conclusion"},{"location":"appendix/tags/","text":"Tag Index \u00b6 ADR \u00b6 0002 Architecture Decision Records Bash \u00b6 Bash Scripts Dart \u00b6 Flutter Earthly \u00b6 Earthly Flutter \u00b6 Flutter Go \u00b6 Go PostgreSQL \u00b6 PostgreSQL Python \u00b6 Python Rust \u00b6 0005 Rust 0006 Rust Cargo Lock 0007 Rust Version configuration in `cargo.toml` Rust Spelling \u00b6 0003 Language 0004 Spelling arc42 \u00b6 0001 Architecture Documentation Standard 0002 Architecture Decision Records Index","title":"Tag Index"},{"location":"appendix/tags/#tag-index","text":"","title":"Tag Index"},{"location":"appendix/tags/#tag:adr","text":"0002 Architecture Decision Records","title":"ADR"},{"location":"appendix/tags/#tag:bash","text":"Bash Scripts","title":"Bash"},{"location":"appendix/tags/#tag:dart","text":"Flutter","title":"Dart"},{"location":"appendix/tags/#tag:earthly","text":"Earthly","title":"Earthly"},{"location":"appendix/tags/#tag:flutter","text":"Flutter","title":"Flutter"},{"location":"appendix/tags/#tag:go","text":"Go","title":"Go"},{"location":"appendix/tags/#tag:postgresql","text":"PostgreSQL","title":"PostgreSQL"},{"location":"appendix/tags/#tag:python","text":"Python","title":"Python"},{"location":"appendix/tags/#tag:rust","text":"0005 Rust 0006 Rust Cargo Lock 0007 Rust Version configuration in `cargo.toml` Rust","title":"Rust"},{"location":"appendix/tags/#tag:spelling","text":"0003 Language 0004 Spelling","title":"Spelling"},{"location":"appendix/tags/#tag:arc42","text":"0001 Architecture Documentation Standard 0002 Architecture Decision Records Index","title":"arc42"},{"location":"appendix/examples/","text":"Markdown Examples \u00b6 These are examples of the type of extended markdown documentation we can make.","title":"Markdown Examples"},{"location":"appendix/examples/#markdown-examples","text":"These are examples of the type of extended markdown documentation we can make.","title":"Markdown Examples"},{"location":"appendix/examples/abbreviations/","text":"Consistent Abbreviations \u00b6 The HTML Specification is maintained by the W3C . Note Abbreviations go in the docs/includes/abbreviations.md file. Except that doesn't work for some reason... So embed them like this at the end of a document: *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium","title":"Consistent Abbreviations"},{"location":"appendix/examples/abbreviations/#consistent-abbreviations","text":"The HTML Specification is maintained by the W3C . Note Abbreviations go in the docs/includes/abbreviations.md file. Except that doesn't work for some reason... So embed them like this at the end of a document: *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium","title":"Consistent Abbreviations"},{"location":"appendix/examples/admonitions/","text":"Admonitions \u00b6 A note with a custom title. This is a note. Collapsible note - Starts Closed. This is a note. Collapsible note - Starts Open. This is a note. Example See Admonitions Documentation for details.","title":"Admonitions"},{"location":"appendix/examples/admonitions/#admonitions","text":"A note with a custom title. This is a note. Collapsible note - Starts Closed. This is a note. Collapsible note - Starts Open. This is a note. Example See Admonitions Documentation for details.","title":"Admonitions"},{"location":"appendix/examples/code-formatting/","text":"Code Formatting \u00b6 Rust pub ( crate ) async fn do_something ( param : Option < String > ) -> Result < String > : { // Do something here. } Python async def sleep (): print ( f 'Time: { time . time () - start : .2f } ' ) await asyncio . sleep ( 1 )","title":"Code Formatting"},{"location":"appendix/examples/code-formatting/#code-formatting","text":"Rust pub ( crate ) async fn do_something ( param : Option < String > ) -> Result < String > : { // Do something here. } Python async def sleep (): print ( f 'Time: { time . time () - start : .2f } ' ) await asyncio . sleep ( 1 )","title":"Code Formatting"},{"location":"appendix/examples/d2-diagrams/","text":"Converting CQL to D2 \u00b6 This is the guide how to use the earthly target to convert a CQL schema file into D2 diagram entity. Following is the sample of using the target: VERSION 0.8 IMPORT utilities/cql-to-d2 AS cql-to-d2-utils example: FROM scratch COPY . . COPY (+cql-to-d2/diagrams --input=\"./input\") ./output RUN ls ./output Converting result sample \u00b6 This is the sample valid CQL schema code: CREATE TABLE IF NOT EXISTS sample_table ( column_name_1 int, column_name_2 int, column_name_3 int, column_name_4 text static, column_name_5 int, column_name_6 counter, column_name_7 list<int>, column_name_8 set<int>, column_name_9 map<int>, column_name_10 custom_int, column_name_11 tuple<int, set<int>>, column_name_12 int, PRIMARY KEY (column_name_1, column_name_2, column_name_3) ) WITH CLUSTERING ORDER BY (column_name_3 DESC); Resulted in D2: .d2-4af181a9d48740bc87fc2d9688a3c495 .text { font-family: \"d2-4af181a9d48740bc87fc2d9688a3c495-font-regular\"; } @font-face { font-family: d2-4af181a9d48740bc87fc2d9688a3c495-font-regular; src: url(\"data:application/font-woff;base64,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\"); } .shape { shape-rendering: geometricPrecision; stroke-linejoin: round; } .connection { stroke-linecap: round; stroke-linejoin: round; } .blend { mix-blend-mode: multiply; opacity: 0.5; } .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N1{fill:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N2{fill:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N3{fill:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N4{fill:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N5{fill:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N6{fill:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N7{fill:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B1{fill:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B2{fill:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B3{fill:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B4{fill:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B5{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B6{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA2{fill:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA4{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA5{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AB4{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AB5{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N1{stroke:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N2{stroke:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N3{stroke:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N4{stroke:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N5{stroke:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N6{stroke:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N7{stroke:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B1{stroke:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B2{stroke:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B3{stroke:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B4{stroke:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B5{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B6{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA2{stroke:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA4{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA5{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AB4{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AB5{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N1{background-color:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N2{background-color:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N3{background-color:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N4{background-color:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N5{background-color:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N6{background-color:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N7{background-color:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B1{background-color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B2{background-color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B3{background-color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B4{background-color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B5{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B6{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA2{background-color:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA4{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA5{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AB4{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AB5{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N1{color:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N2{color:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N3{color:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N4{color:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N5{color:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N6{color:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N7{color:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B1{color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B2{color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B3{color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B4{color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B5{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B6{color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA2{color:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA4{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA5{color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AB4{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none} sample_table column_name_1 (int) K column_name_2 (int) P\u2191 column_name_3 (int) P\u2193 column_name_4 (text) S column_name_5 (int) column_name_6 (bigint) ++ [column_name_7] (int) {column_name_8} (int) <column_name_9> (int) *column_name_10* (custom_int) (column_name_11) (int, set<int>) column_name_12 (int)","title":"Converting CQL to D2"},{"location":"appendix/examples/d2-diagrams/#converting-cql-to-d2","text":"This is the guide how to use the earthly target to convert a CQL schema file into D2 diagram entity. Following is the sample of using the target: VERSION 0.8 IMPORT utilities/cql-to-d2 AS cql-to-d2-utils example: FROM scratch COPY . . COPY (+cql-to-d2/diagrams --input=\"./input\") ./output RUN ls ./output","title":"Converting CQL to D2"},{"location":"appendix/examples/d2-diagrams/#converting-result-sample","text":"This is the sample valid CQL schema code: CREATE TABLE IF NOT EXISTS sample_table ( column_name_1 int, column_name_2 int, column_name_3 int, column_name_4 text static, column_name_5 int, column_name_6 counter, column_name_7 list<int>, column_name_8 set<int>, column_name_9 map<int>, column_name_10 custom_int, column_name_11 tuple<int, set<int>>, column_name_12 int, PRIMARY KEY (column_name_1, column_name_2, column_name_3) ) WITH CLUSTERING ORDER BY (column_name_3 DESC); Resulted in D2: .d2-4af181a9d48740bc87fc2d9688a3c495 .text { font-family: \"d2-4af181a9d48740bc87fc2d9688a3c495-font-regular\"; } @font-face { font-family: d2-4af181a9d48740bc87fc2d9688a3c495-font-regular; src: url(\"data:application/font-woff;base64,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\"); } .shape { shape-rendering: geometricPrecision; stroke-linejoin: round; } .connection { stroke-linecap: round; stroke-linejoin: round; } .blend { mix-blend-mode: multiply; opacity: 0.5; } .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N1{fill:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N2{fill:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N3{fill:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N4{fill:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N5{fill:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N6{fill:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-N7{fill:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B1{fill:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B2{fill:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B3{fill:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B4{fill:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B5{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-B6{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA2{fill:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA4{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AA5{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AB4{fill:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .fill-AB5{fill:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N1{stroke:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N2{stroke:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N3{stroke:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N4{stroke:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N5{stroke:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N6{stroke:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-N7{stroke:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B1{stroke:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B2{stroke:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B3{stroke:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B4{stroke:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B5{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-B6{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA2{stroke:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA4{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AA5{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AB4{stroke:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .stroke-AB5{stroke:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N1{background-color:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N2{background-color:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N3{background-color:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N4{background-color:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N5{background-color:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N6{background-color:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-N7{background-color:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B1{background-color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B2{background-color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B3{background-color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B4{background-color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B5{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-B6{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA2{background-color:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA4{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AA5{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AB4{background-color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .background-color-AB5{background-color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N1{color:#0A0F25;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N2{color:#676C7E;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N3{color:#9499AB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N4{color:#CFD2DD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N5{color:#DEE1EB;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N6{color:#EEF1F8;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-N7{color:#FFFFFF;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B1{color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B2{color:#0D32B2;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B3{color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B4{color:#E3E9FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B5{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-B6{color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA2{color:#4A6FF3;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA4{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AA5{color:#F7F8FE;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AB4{color:#EDF0FD;} .d2-4af181a9d48740bc87fc2d9688a3c495 .color-AB5{color:#F7F8FE;}.appendix text.text{fill:#0A0F25}.md{--color-fg-default:#0A0F25;--color-fg-muted:#676C7E;--color-fg-subtle:#9499AB;--color-canvas-default:#FFFFFF;--color-canvas-subtle:#EEF1F8;--color-border-default:#0D32B2;--color-border-muted:#0D32B2;--color-neutral-muted:#EEF1F8;--color-accent-fg:#0D32B2;--color-accent-emphasis:#0D32B2;--color-attention-subtle:#676C7E;--color-danger-fg:red;}.sketch-overlay-B1{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-B2{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-B3{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-B6{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AA2{fill:url(#streaks-dark-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:overlay}.sketch-overlay-AA4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AA5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AB4{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-AB5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N1{fill:url(#streaks-darker-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:lighten}.sketch-overlay-N2{fill:url(#streaks-dark-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:overlay}.sketch-overlay-N3{fill:url(#streaks-normal-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:color-burn}.sketch-overlay-N4{fill:url(#streaks-normal-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:color-burn}.sketch-overlay-N5{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N6{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.sketch-overlay-N7{fill:url(#streaks-bright-d2-4af181a9d48740bc87fc2d9688a3c495);mix-blend-mode:darken}.light-code{display: block}.dark-code{display: none} sample_table column_name_1 (int) K column_name_2 (int) P\u2191 column_name_3 (int) P\u2193 column_name_4 (text) S column_name_5 (int) column_name_6 (bigint) ++ [column_name_7] (int) {column_name_8} (int) <column_name_9> (int) *column_name_10* (custom_int) (column_name_11) (int, set<int>) column_name_12 (int)","title":"Converting result sample"},{"location":"appendix/examples/graphviz-diagrams/","text":"Graphviz Diagrams \u00b6 Graphviz SVG's \u00b6 Trees Graphs G - - x x ---x + + ---+ 3 3 x--3 5 5 x--5 2 2 +--2 4 4 +--4 Tree 1: Tree of Arithmetic Expressions G 5 5 4 4 5--4 32 3 5--32 31 3 4--31 22 2 4--22 23 2 32--23 15 1 32--15 21 2 31--21 12 1 31--12 11 1 21--11 02 0 21--02 13 1 22--13 05 0 22--05 14 1 23--14 07 0 23--07 01 0 11--01 03 0 12--03 04 0 13--04 06 0 14--06 08 0 15--08 Tree 2: Game Tree (of Nim) G 4 4 0 0 4--0 4--0 1 1 4--1 2 2 0--2 0--2 0--2 3 3 0--3 1--1 1--2 1--3 2--2 An Unweighted Undirected Multi-graph (with loops) G cluster0 Related Component cluster00 cycle cluster1 Related Component cluster2 Related Component 0 0 1 1 0->1 2 2 0->2 3 3 0->3 4 4 0->4 5 5 1->5 6 6 1->6 2->3 8 8 2->8 9 9 2->9 3->9 8->3 11 11 8->11 8->9 10 10 10->11 4->10 5->6 7 7 6->7 15 15 16 16 15->16 17 17 16->17 18 18 16->18 19 19 18->19 20 20 21 21 20->21 23 23 20->23 22 22 21->22 21->23 24 24 23->24 Graph G Undirected Unweighted Unrelated Graphviz inside Admonitions \u00b6 graphviz in UnExpanded Block G Earth Earth Mars Mars Earth->Mars graphviz in Expanded Block G Earth Earth Mars Mars Earth->Mars Graphviz PNG's (lower quality than SVGs) \u00b6 Graphviz Render Example of Code Syntax SYNTAX (WATCHOUT) : NO SPACES BETWEEN ``` and graphviz ```\u200agraphviz dot attack_plan.png digraph G { rankdir=LR Earth [peripheries=2] Mars Earth -> Mars } ```","title":"Graphviz Diagrams"},{"location":"appendix/examples/graphviz-diagrams/#graphviz-diagrams","text":"","title":"Graphviz Diagrams"},{"location":"appendix/examples/graphviz-diagrams/#graphviz-svgs","text":"Trees Graphs G - - x x ---x + + ---+ 3 3 x--3 5 5 x--5 2 2 +--2 4 4 +--4 Tree 1: Tree of Arithmetic Expressions G 5 5 4 4 5--4 32 3 5--32 31 3 4--31 22 2 4--22 23 2 32--23 15 1 32--15 21 2 31--21 12 1 31--12 11 1 21--11 02 0 21--02 13 1 22--13 05 0 22--05 14 1 23--14 07 0 23--07 01 0 11--01 03 0 12--03 04 0 13--04 06 0 14--06 08 0 15--08 Tree 2: Game Tree (of Nim) G 4 4 0 0 4--0 4--0 1 1 4--1 2 2 0--2 0--2 0--2 3 3 0--3 1--1 1--2 1--3 2--2 An Unweighted Undirected Multi-graph (with loops) G cluster0 Related Component cluster00 cycle cluster1 Related Component cluster2 Related Component 0 0 1 1 0->1 2 2 0->2 3 3 0->3 4 4 0->4 5 5 1->5 6 6 1->6 2->3 8 8 2->8 9 9 2->9 3->9 8->3 11 11 8->11 8->9 10 10 10->11 4->10 5->6 7 7 6->7 15 15 16 16 15->16 17 17 16->17 18 18 16->18 19 19 18->19 20 20 21 21 20->21 23 23 20->23 22 22 21->22 21->23 24 24 23->24 Graph G Undirected Unweighted Unrelated","title":"Graphviz SVG's"},{"location":"appendix/examples/graphviz-diagrams/#graphviz-inside-admonitions","text":"graphviz in UnExpanded Block G Earth Earth Mars Mars Earth->Mars graphviz in Expanded Block G Earth Earth Mars Mars Earth->Mars","title":"Graphviz inside Admonitions"},{"location":"appendix/examples/graphviz-diagrams/#graphviz-pngs-lower-quality-than-svgs","text":"Graphviz Render Example of Code Syntax SYNTAX (WATCHOUT) : NO SPACES BETWEEN ``` and graphviz ```\u200agraphviz dot attack_plan.png digraph G { rankdir=LR Earth [peripheries=2] Mars Earth -> Mars } ```","title":"Graphviz PNG's (lower quality than SVGs)"},{"location":"appendix/examples/latex/","text":"LaTex formulas \u00b6 Simple formula as a separate block: \\begin{equation} 5 = 2 + 3 \\end{equation} Simple formula inside the sentence: \\(5 = 2 + 3\\) . More complex examples: \\[\\begin{equation} e^{ix} = cox(x) + i sin(x) \\end{equation}\\] \\[\\begin{equation} cos(x) = \\frac{e^{ix} + e^{-ix}}{2} \\end{equation}\\] \\[\\begin{equation} sin(x) = \\frac{e^{ix} - e^{-ix}}{2i} \\end{equation}\\] \\[\\begin{equation} f(x) = \\frac{a_0}{2} + \\sum_{n=1}^{\\infty} (a_n cos(nx) + b_n sin(nx)) \\end{equation}\\]","title":"Latex"},{"location":"appendix/examples/latex/#latex-formulas","text":"Simple formula as a separate block: \\begin{equation} 5 = 2 + 3 \\end{equation} Simple formula inside the sentence: \\(5 = 2 + 3\\) . More complex examples: \\[\\begin{equation} e^{ix} = cox(x) + i sin(x) \\end{equation}\\] \\[\\begin{equation} cos(x) = \\frac{e^{ix} + e^{-ix}}{2} \\end{equation}\\] \\[\\begin{equation} sin(x) = \\frac{e^{ix} - e^{-ix}}{2i} \\end{equation}\\] \\[\\begin{equation} f(x) = \\frac{a_0}{2} + \\sum_{n=1}^{\\infty} (a_n cos(nx) + b_n sin(nx)) \\end{equation}\\]","title":"LaTex formulas"},{"location":"appendix/examples/mermaid-diagrams/","text":"Mermaid Diagrams \u00b6 Mermaid diagrams can be embedded inline. graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; click A \"https://www.github.com\" _blank","title":"Mermaid Diagrams"},{"location":"appendix/examples/mermaid-diagrams/#mermaid-diagrams","text":"Mermaid diagrams can be embedded inline. graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; click A \"https://www.github.com\" _blank","title":"Mermaid Diagrams"},{"location":"appendix/examples/built_docs/postgresql/migrations/","text":"Migrations (Version 2) \u00b6 users \u00b6 Schema Definition CREATE TABLE users ( name VARCHAR PRIMARY KEY , age INTEGER NOT NULL ); addresses \u00b6 Schema Definition CREATE TABLE address ( name VARCHAR PRIMARY KEY , address TEXT NOT NULL , FOREIGN KEY ( name ) REFERENCES users ( name ) );","title":"Migrations (Version 2)"},{"location":"appendix/examples/built_docs/postgresql/migrations/#migrations-version-2","text":"","title":"Migrations (Version 2)"},{"location":"appendix/examples/built_docs/postgresql/migrations/#users","text":"Schema Definition CREATE TABLE users ( name VARCHAR PRIMARY KEY , age INTEGER NOT NULL );","title":"users"},{"location":"appendix/examples/built_docs/postgresql/migrations/#addresses","text":"Schema Definition CREATE TABLE address ( name VARCHAR PRIMARY KEY , address TEXT NOT NULL , FOREIGN KEY ( name ) REFERENCES users ( name ) );","title":"addresses"},{"location":"appendix/examples/built_docs/postgresql/schema/","text":"iframe { position: fixed; left: 0; width: 100%; border: none; z-index: 1; } document.addEventListener('DOMContentLoaded', function() { var iframe = document.getElementById('schemaFrame'); var header = document.querySelector('header'); var footer = document.querySelector('footer'); function adjustIframePosition() { var headerHeight = header.offsetHeight; var footerHeight = footer.offsetHeight; iframe.style.top = (headerHeight) + 'px'; iframe.style.height = 'calc(100% - ' + (headerHeight + footerHeight) + 'px)'; } iframe.onload = function() { adjustIframePosition(); // Prevent default link behavior inside iframe to avoid page reloads iframe.contentWindow.addEventListener('click', function(e) { if (e.target.tagName === 'A') { e.preventDefault(); iframe.src = e.target.href; } }, true); }; // Adjust iframe position and height when window is resized window.addEventListener('resize', adjustIframePosition); // Initial adjustment adjustIframePosition(); });","title":"Schema"},{"location":"appendix/important/","text":"Important \u00b6","title":"Important"},{"location":"appendix/important/#important","text":"","title":"Important"},{"location":"appendix/important/coc/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u00b6 Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u00b6 Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u00b6 This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@iohk.io . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u00b6 Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u00b6 Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u00b6 Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u00b6 Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u00b6 Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Code of Conduct"},{"location":"appendix/important/coc/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"appendix/important/coc/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"appendix/important/coc/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"appendix/important/coc/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"appendix/important/coc/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"appendix/important/coc/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@iohk.io . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"appendix/important/coc/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"appendix/important/coc/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"appendix/important/coc/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"appendix/important/coc/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"appendix/important/coc/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"appendix/important/coc/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"appendix/important/contributing/","text":"Contributing to Catalyst CI \u00b6 First off, thanks for taking the time to contribute! \u2764\ufe0f Contributing to Catalyst CI Code of Conduct I Have a Question I Want To Contribute Reporting Bugs Before Submitting a Bug Report How Do I Submit a Good Bug Report? Suggesting Enhancements Before Submitting an Enhancement How Do I Submit a Good Enhancement Suggestion? Your First Code Contribution Improving The Documentation Style guides Rust Dart Flutter Commit Messages All types of contributions are encouraged and valued. Please make sure to read the relevant section before making your contribution. It will make it a lot easier for us maintainers and smooth out the experience for all involved. The community looks forward to your contributions. \ud83c\udf89 Code of Conduct \u00b6 This project and everyone participating in it is governed by the Catalyst CI Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to code-of-conduct@iohk.io . I Have a Question \u00b6 If you want to ask a question, we assume that you have read the available Documentation . Before you ask a question, it is best to search for existing Issues that might help you. In case you have found a suitable issue and still need clarification, you can write your question here . It is also advisable to search the internet for answers first. If you then still feel the need to ask a question and need clarification, we recommend the following: Open an Issue . Provide as much context as you can about what you're running into. Provide project and platform versions ( rustc --version --verbose , flutter doctor -v , etc), depending on what seems relevant. We will then take care of the issue as soon as possible. I Want To Contribute \u00b6 Reporting Bugs \u00b6 Before Submitting a Bug Report \u00b6 A good bug report shouldn't leave others needing to chase you up for more information. Therefore, we ask you to investigate carefully, collect information and describe the issue in detail in your report. Please complete the following steps in advance to help us fix any potential bug as fast as possible. Make sure that you are using the latest version. Determine if your bug is really a bug and not an error on your side. e.g. using incompatible environment components/versions (Make sure that you have read the documentation . If you are looking for support, you might want to check this section . To see if other users have experienced (and potentially already solved) the same issue you are having. Check if there is not already a bug report existing for your bug or error in the bug tracker . Also make sure to search the internet (including Stack Overflow) to see if users outside the GitHub community have discussed the issue. Collect information about the bug: Stack trace (Traceback) OS, Platform and Version (Windows, Linux, macOS, x86, ARM) Version of the interpreter, compiler, SDK, runtime environment, package manager, depending on what seems relevant. Possibly your input and the output Can you reliably reproduce the issue? And can you also reproduce it with older versions? How Do I Submit a Good Bug Report? \u00b6 You must never report security related issues, vulnerabilities or bugs including sensitive information to the issue tracker, or elsewhere in public. Instead sensitive bugs must be sent by email to security@iohk.io . We use GitHub issues to track bugs and errors. If you run into an issue with the project: Open an Issue . (Since we can't be sure at this point whether it is a bug or not, we ask you not to talk about a bug yet and not to label the issue.) Explain the behavior you would expect and the actual behavior. Please provide as much context as possible. Describe the reproduction steps that someone else can follow to recreate the issue on their own. This usually includes your code. For good bug reports you should isolate the problem and create a reduced test case. Provide the information you collected in the previous section. Once it's filed: The project team will label the issue accordingly. A team member will try to reproduce the issue with your provided steps. If there are no reproduction steps or no obvious way to reproduce the issue, the team will ask you for those steps. The issue would then be marked as needs-repro . Bugs with the needs-repro tag will not be addressed until they are reproduced. If the team is able to reproduce the issue, it will be marked bug . It may possibly be marked with other tags (such as critical ). The issue will then be left to be implemented by someone . Suggesting Enhancements \u00b6 This section guides you through submitting an enhancement suggestion for Catalyst CI, including completely new features and minor improvements to existing functionality . Following these guidelines will help maintainers and the community to understand your suggestion and find related suggestions. Before Submitting an Enhancement \u00b6 Make sure that you are using the latest version. Read the documentation carefully. Find out if the functionality is already covered, maybe by an individual configuration. Perform a search to see if the enhancement has already been suggested. If it has, add a comment to the existing issue instead of opening a new one. Find out whether your idea fits with the scope and aims of the project. It's up to you to make a strong case to convince the project's developers of the merits of this feature. Keep in mind that we want features that will be useful to the majority of our users and not just a small subset. If you're just targeting a minority of users, consider writing an add-on/plugin library. How Do I Submit a Good Enhancement Suggestion? \u00b6 Enhancement suggestions are tracked as GitHub issues . Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Describe the current behavior and explain which behavior you expected to see instead and why. At this point you can also tell which alternatives do not work for you. You may want to include screenshots and animated GIFs . This can help you demonstrate the steps or point out the part which the suggestion is related to. You can use this tool to record GIFs on macOS and Windows, and this tool or this tool on Linux. Explain why this enhancement would be useful to most Catalyst CI users. You may also want to point out the other projects that solved it better and which could serve as inspiration. Your First Code Contribution \u00b6 Embarking on your first code contribution can be an exhilarating yet intimidating endeavor. Here at Catalyst, we foster a welcoming and supportive environment to ensure that everyone can contribute to the codebase irrespective of their experience level. Below is a step-by-step guide to making your first code contribution to our repository: Set Up Your Environment : Fork the repository to your GitHub account. Clone your fork locally on your machine. Set up the development environment following the instructions in the README. Pick an Issue : Browse through the open issues in the GitHub repository. Pick an issue that interests you and aligns with your skills. Beginners might look for issues tagged as good first issue or beginner-friendly . Understand the Issue : Thoroughly read through the issue to understand the problem. Ask clarifying questions in the issue thread if necessary. Branch Out : Create a new branch on your local machine to work on the issue. It's a good practice to name your branch descriptively, e.g., fix-button-bug. Work on the Issue : Work on the issue in your local development environment. Adhere to the coding standards and guidelines provided in the Style guides section. Test Your Changes : Ensure that your changes are well-tested. Verify that your changes don't break any existing functionality. Commit Your Changes : Write a clear and concise commit message following the Style guides -> Commit Messages section guidelines. Push Your Changes : Push your changes to your fork on GitHub. Open a Pull Request : Open a pull request from your fork to the main repository. Provide a detailed description of your changes, the issue it addresses, and any additional information that might help maintainers review your contribution. Review and Revision : Respond to any feedback from the maintainers. Make necessary revisions to your code. Merge and Celebrate : Once your pull request is approved, it will be merged into the main codebase. Celebrate your contribution and share it with the community! Remember, every contributor was new at some point, and we are thrilled to welcome new members to our community. The journey of becoming an adept open-source contributor is rewarding and educational. Your contribution, no matter how small, can make a significant impact. Happy coding! Improving The Documentation \u00b6 Documentation is a cornerstone of any successful open-source project. It aids developers in understanding the purpose, structure, and functioning of the code, making the project accessible to all, irrespective of their level of expertise. Our project thrives on the contributions from the community, and improving the documentation is one of the significant ways you can contribute. Here are some ways you could help improve our documentation: Clarification : If you find any ambiguous or unclear documentation, feel free to clarify the wording or suggest improvements through a pull request. Expansion : If areas of the documentation are lacking in detail or missing altogether, contributing expanded explanations or new sections is highly encouraged. Correction : Spot a mistake? Whether it's a spelling error, grammatical error, or incorrect information, your corrections are welcome. Examples : Adding examples to the documentation can significantly enhance utility. If you have examples that illustrate the use of our code, we'd love to include them. Consistency : Ensure the documentation maintains a consistent style and tone. Adhering to the style guidelines specified in our Style guides section is crucial. Technical Accuracy : Ensure that the documentation reflects the current state of the codebase and is technically accurate. Your contributions should follow the guidelines specified in our Style guides section to maintain high quality and consistency. Before making a substantial change, it's a good practice to open an issue to discuss the proposed changes or find an existing issue to work on. Together, we can ensure that our documentation is a valuable resource for all new and experienced developers. Style guides \u00b6 Rust \u00b6 For Rust, we follow the Rust Style Guide . Dart \u00b6 For Dart, we follow the Effective Dart style guide. Flutter \u00b6 For Flutter, we follow the Flutter Style Guide . Commit Messages \u00b6 Clear and consistent commit messages are crucial for maintaining a readable history in our collaborative environment. Adhering to a structured commit message format also enables us to generate changelogs and navigate through the project's history more efficiently. We follow the Conventional Commits standard for all commit messages in this repository. Here's a brief overview of the Conventional Commits standard: Type : The type of change being made (e.g., feat, fix, chore, docs, style, refactor, perf, test). Scope (Optional) : The scope of the change, denoting what part of the codebase is being altered. Description : A short, descriptive message of the change, written in the imperative mood. Format: <type>(<scope>): <description> Example: feat(button): add a 'submit' button to form component fix(modal): resolve issue with modal overlay not closing chore(tests): update unit tests for utilities module Breaking Changes : If your commit introduces a breaking change, it should be flagged with a ! after the type. Include BREAKING CHANGE: in the body or footer of the commit message to describe what changed and its implications. Example: feat!(dropdown): change the behavior of dropdown component BREAKING CHANGE: alters dropdown trigger to be activated on hover instead of on click. Footer (Optional) : Any additional metadata regarding your commit, such as related issue trackers or BREAKING CHANGE annotations. Following this format makes the version control history readable and reflects professionalism and foresight in maintaining a clean, well-documented codebase.","title":"Contributing"},{"location":"appendix/important/contributing/#contributing-to-catalyst-ci","text":"First off, thanks for taking the time to contribute! \u2764\ufe0f Contributing to Catalyst CI Code of Conduct I Have a Question I Want To Contribute Reporting Bugs Before Submitting a Bug Report How Do I Submit a Good Bug Report? Suggesting Enhancements Before Submitting an Enhancement How Do I Submit a Good Enhancement Suggestion? Your First Code Contribution Improving The Documentation Style guides Rust Dart Flutter Commit Messages All types of contributions are encouraged and valued. Please make sure to read the relevant section before making your contribution. It will make it a lot easier for us maintainers and smooth out the experience for all involved. The community looks forward to your contributions. \ud83c\udf89","title":"Contributing to Catalyst CI"},{"location":"appendix/important/contributing/#code-of-conduct","text":"This project and everyone participating in it is governed by the Catalyst CI Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to code-of-conduct@iohk.io .","title":"Code of Conduct"},{"location":"appendix/important/contributing/#i-have-a-question","text":"If you want to ask a question, we assume that you have read the available Documentation . Before you ask a question, it is best to search for existing Issues that might help you. In case you have found a suitable issue and still need clarification, you can write your question here . It is also advisable to search the internet for answers first. If you then still feel the need to ask a question and need clarification, we recommend the following: Open an Issue . Provide as much context as you can about what you're running into. Provide project and platform versions ( rustc --version --verbose , flutter doctor -v , etc), depending on what seems relevant. We will then take care of the issue as soon as possible.","title":"I Have a Question"},{"location":"appendix/important/contributing/#i-want-to-contribute","text":"","title":"I Want To Contribute"},{"location":"appendix/important/contributing/#reporting-bugs","text":"","title":"Reporting Bugs"},{"location":"appendix/important/contributing/#before-submitting-a-bug-report","text":"A good bug report shouldn't leave others needing to chase you up for more information. Therefore, we ask you to investigate carefully, collect information and describe the issue in detail in your report. Please complete the following steps in advance to help us fix any potential bug as fast as possible. Make sure that you are using the latest version. Determine if your bug is really a bug and not an error on your side. e.g. using incompatible environment components/versions (Make sure that you have read the documentation . If you are looking for support, you might want to check this section . To see if other users have experienced (and potentially already solved) the same issue you are having. Check if there is not already a bug report existing for your bug or error in the bug tracker . Also make sure to search the internet (including Stack Overflow) to see if users outside the GitHub community have discussed the issue. Collect information about the bug: Stack trace (Traceback) OS, Platform and Version (Windows, Linux, macOS, x86, ARM) Version of the interpreter, compiler, SDK, runtime environment, package manager, depending on what seems relevant. Possibly your input and the output Can you reliably reproduce the issue? And can you also reproduce it with older versions?","title":"Before Submitting a Bug Report"},{"location":"appendix/important/contributing/#how-do-i-submit-a-good-bug-report","text":"You must never report security related issues, vulnerabilities or bugs including sensitive information to the issue tracker, or elsewhere in public. Instead sensitive bugs must be sent by email to security@iohk.io . We use GitHub issues to track bugs and errors. If you run into an issue with the project: Open an Issue . (Since we can't be sure at this point whether it is a bug or not, we ask you not to talk about a bug yet and not to label the issue.) Explain the behavior you would expect and the actual behavior. Please provide as much context as possible. Describe the reproduction steps that someone else can follow to recreate the issue on their own. This usually includes your code. For good bug reports you should isolate the problem and create a reduced test case. Provide the information you collected in the previous section. Once it's filed: The project team will label the issue accordingly. A team member will try to reproduce the issue with your provided steps. If there are no reproduction steps or no obvious way to reproduce the issue, the team will ask you for those steps. The issue would then be marked as needs-repro . Bugs with the needs-repro tag will not be addressed until they are reproduced. If the team is able to reproduce the issue, it will be marked bug . It may possibly be marked with other tags (such as critical ). The issue will then be left to be implemented by someone .","title":"How Do I Submit a Good Bug Report?"},{"location":"appendix/important/contributing/#suggesting-enhancements","text":"This section guides you through submitting an enhancement suggestion for Catalyst CI, including completely new features and minor improvements to existing functionality . Following these guidelines will help maintainers and the community to understand your suggestion and find related suggestions.","title":"Suggesting Enhancements"},{"location":"appendix/important/contributing/#before-submitting-an-enhancement","text":"Make sure that you are using the latest version. Read the documentation carefully. Find out if the functionality is already covered, maybe by an individual configuration. Perform a search to see if the enhancement has already been suggested. If it has, add a comment to the existing issue instead of opening a new one. Find out whether your idea fits with the scope and aims of the project. It's up to you to make a strong case to convince the project's developers of the merits of this feature. Keep in mind that we want features that will be useful to the majority of our users and not just a small subset. If you're just targeting a minority of users, consider writing an add-on/plugin library.","title":"Before Submitting an Enhancement"},{"location":"appendix/important/contributing/#how-do-i-submit-a-good-enhancement-suggestion","text":"Enhancement suggestions are tracked as GitHub issues . Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Describe the current behavior and explain which behavior you expected to see instead and why. At this point you can also tell which alternatives do not work for you. You may want to include screenshots and animated GIFs . This can help you demonstrate the steps or point out the part which the suggestion is related to. You can use this tool to record GIFs on macOS and Windows, and this tool or this tool on Linux. Explain why this enhancement would be useful to most Catalyst CI users. You may also want to point out the other projects that solved it better and which could serve as inspiration.","title":"How Do I Submit a Good Enhancement Suggestion?"},{"location":"appendix/important/contributing/#your-first-code-contribution","text":"Embarking on your first code contribution can be an exhilarating yet intimidating endeavor. Here at Catalyst, we foster a welcoming and supportive environment to ensure that everyone can contribute to the codebase irrespective of their experience level. Below is a step-by-step guide to making your first code contribution to our repository: Set Up Your Environment : Fork the repository to your GitHub account. Clone your fork locally on your machine. Set up the development environment following the instructions in the README. Pick an Issue : Browse through the open issues in the GitHub repository. Pick an issue that interests you and aligns with your skills. Beginners might look for issues tagged as good first issue or beginner-friendly . Understand the Issue : Thoroughly read through the issue to understand the problem. Ask clarifying questions in the issue thread if necessary. Branch Out : Create a new branch on your local machine to work on the issue. It's a good practice to name your branch descriptively, e.g., fix-button-bug. Work on the Issue : Work on the issue in your local development environment. Adhere to the coding standards and guidelines provided in the Style guides section. Test Your Changes : Ensure that your changes are well-tested. Verify that your changes don't break any existing functionality. Commit Your Changes : Write a clear and concise commit message following the Style guides -> Commit Messages section guidelines. Push Your Changes : Push your changes to your fork on GitHub. Open a Pull Request : Open a pull request from your fork to the main repository. Provide a detailed description of your changes, the issue it addresses, and any additional information that might help maintainers review your contribution. Review and Revision : Respond to any feedback from the maintainers. Make necessary revisions to your code. Merge and Celebrate : Once your pull request is approved, it will be merged into the main codebase. Celebrate your contribution and share it with the community! Remember, every contributor was new at some point, and we are thrilled to welcome new members to our community. The journey of becoming an adept open-source contributor is rewarding and educational. Your contribution, no matter how small, can make a significant impact. Happy coding!","title":"Your First Code Contribution"},{"location":"appendix/important/contributing/#improving-the-documentation","text":"Documentation is a cornerstone of any successful open-source project. It aids developers in understanding the purpose, structure, and functioning of the code, making the project accessible to all, irrespective of their level of expertise. Our project thrives on the contributions from the community, and improving the documentation is one of the significant ways you can contribute. Here are some ways you could help improve our documentation: Clarification : If you find any ambiguous or unclear documentation, feel free to clarify the wording or suggest improvements through a pull request. Expansion : If areas of the documentation are lacking in detail or missing altogether, contributing expanded explanations or new sections is highly encouraged. Correction : Spot a mistake? Whether it's a spelling error, grammatical error, or incorrect information, your corrections are welcome. Examples : Adding examples to the documentation can significantly enhance utility. If you have examples that illustrate the use of our code, we'd love to include them. Consistency : Ensure the documentation maintains a consistent style and tone. Adhering to the style guidelines specified in our Style guides section is crucial. Technical Accuracy : Ensure that the documentation reflects the current state of the codebase and is technically accurate. Your contributions should follow the guidelines specified in our Style guides section to maintain high quality and consistency. Before making a substantial change, it's a good practice to open an issue to discuss the proposed changes or find an existing issue to work on. Together, we can ensure that our documentation is a valuable resource for all new and experienced developers.","title":"Improving The Documentation"},{"location":"appendix/important/contributing/#style-guides","text":"","title":"Style guides"},{"location":"appendix/important/contributing/#rust","text":"For Rust, we follow the Rust Style Guide .","title":"Rust"},{"location":"appendix/important/contributing/#dart","text":"For Dart, we follow the Effective Dart style guide.","title":"Dart"},{"location":"appendix/important/contributing/#flutter","text":"For Flutter, we follow the Flutter Style Guide .","title":"Flutter"},{"location":"appendix/important/contributing/#commit-messages","text":"Clear and consistent commit messages are crucial for maintaining a readable history in our collaborative environment. Adhering to a structured commit message format also enables us to generate changelogs and navigate through the project's history more efficiently. We follow the Conventional Commits standard for all commit messages in this repository. Here's a brief overview of the Conventional Commits standard: Type : The type of change being made (e.g., feat, fix, chore, docs, style, refactor, perf, test). Scope (Optional) : The scope of the change, denoting what part of the codebase is being altered. Description : A short, descriptive message of the change, written in the imperative mood. Format: <type>(<scope>): <description> Example: feat(button): add a 'submit' button to form component fix(modal): resolve issue with modal overlay not closing chore(tests): update unit tests for utilities module Breaking Changes : If your commit introduces a breaking change, it should be flagged with a ! after the type. Include BREAKING CHANGE: in the body or footer of the commit message to describe what changed and its implications. Example: feat!(dropdown): change the behavior of dropdown component BREAKING CHANGE: alters dropdown trigger to be activated on hover instead of on click. Footer (Optional) : Any additional metadata regarding your commit, such as related issue trackers or BREAKING CHANGE annotations. Following this format makes the version control history readable and reflects professionalism and foresight in maintaining a clean, well-documented codebase.","title":"Commit Messages"},{"location":"appendix/important/license/","text":"License \u00b6 Apache 2 License Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright (c) 2023 Input Output (IOG). Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. MIT License Copyright (c) 2023 Input Output (IOG). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"appendix/important/license/#license","text":"Apache 2 License Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright (c) 2023 Input Output (IOG). Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. MIT License Copyright (c) 2023 Input Output (IOG). Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"appendix/important/security/","text":"Security \u00b6 Reporting a Vulnerability \u00b6 Please report (suspected) security vulnerabilities to security@iohk.io . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible. Please provide a clear and concise description of the vulnerability, including: the affected version(s), steps that can be followed to exercise the vulnerability, any workarounds or mitigation's. If you have developed any code or utilities that can help demonstrate the suspected vulnerability, please mention them in your email but DO NOT attempt to include them as attachments as this may cause your Email to be blocked by spam filters.","title":"Security"},{"location":"appendix/important/security/#security","text":"","title":"Security"},{"location":"appendix/important/security/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@iohk.io . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible. Please provide a clear and concise description of the vulnerability, including: the affected version(s), steps that can be followed to exercise the vulnerability, any workarounds or mitigation's. If you have developed any code or utilities that can help demonstrate the suspected vulnerability, please mention them in your email but DO NOT attempt to include them as attachments as this may cause your Email to be blocked by spam filters.","title":"Reporting a Vulnerability"},{"location":"architecture/","text":"Architecture \u00b6 About arc42 \u00b6 The architecture documentation is based upon the Arc42 documentation standard . arc42, the template for documentation of software and system architecture. Template Version 8.2 EN. (based upon AsciiDoc version), January 2023 Created, maintained and \u00a9 by Dr. Peter Hruschka, Dr. Gernot Starke and contributors. See https://arc42.org .","title":"Index"},{"location":"architecture/#architecture","text":"","title":"Architecture"},{"location":"architecture/#about-arc42","text":"The architecture documentation is based upon the Arc42 documentation standard . arc42, the template for documentation of software and system architecture. Template Version 8.2 EN. (based upon AsciiDoc version), January 2023 Created, maintained and \u00a9 by Dr. Peter Hruschka, Dr. Gernot Starke and contributors. See https://arc42.org .","title":"About arc42"},{"location":"architecture/01_introduction_and_goals/","text":"Introduction and Goals \u00b6 Requirements Overview \u00b6 Quality Goals \u00b6 Stakeholders \u00b6 Role/Name Contact Expectations Role-1 Contact-1 Expectation-1 Role-2 Contact-2 Expectation-2","title":"Introduction and Goals"},{"location":"architecture/01_introduction_and_goals/#introduction-and-goals","text":"","title":"Introduction and Goals"},{"location":"architecture/01_introduction_and_goals/#requirements-overview","text":"","title":"Requirements Overview"},{"location":"architecture/01_introduction_and_goals/#quality-goals","text":"","title":"Quality Goals"},{"location":"architecture/01_introduction_and_goals/#stakeholders","text":"Role/Name Contact Expectations Role-1 Contact-1 Expectation-1 Role-2 Contact-2 Expectation-2","title":"Stakeholders"},{"location":"architecture/02_architecture_constraints/","text":"Architecture Constraints \u00b6","title":"Architecture Constraints"},{"location":"architecture/02_architecture_constraints/#architecture-constraints","text":"","title":"Architecture Constraints"},{"location":"architecture/03_system_scope_and_context/","text":"System Scope and Context \u00b6 Business Context \u00b6 ... ~Diagram or Table~ ... ~optionally: Explanation of external domain interfaces~ Technical Context \u00b6 ... ~Diagram or Table~ ... ~optionally: Explanation of technical interfaces~ ... ~Mapping Input/Output to Channels~","title":"System Scope and Context"},{"location":"architecture/03_system_scope_and_context/#system-scope-and-context","text":"","title":"System Scope and Context"},{"location":"architecture/03_system_scope_and_context/#business-context","text":"... ~Diagram or Table~ ... ~optionally: Explanation of external domain interfaces~","title":"Business Context"},{"location":"architecture/03_system_scope_and_context/#technical-context","text":"... ~Diagram or Table~ ... ~optionally: Explanation of technical interfaces~ ... ~Mapping Input/Output to Channels~","title":"Technical Context"},{"location":"architecture/04_solution_strategy/","text":"Solution Strategy \u00b6","title":"Solution Strategy"},{"location":"architecture/04_solution_strategy/#solution-strategy","text":"","title":"Solution Strategy"},{"location":"architecture/05_building_block_view/","text":"Building Block View \u00b6 White box Overall System \u00b6 ... ~Overview Diagram~ Motivation ... ~text explanation~ Contained Building Blocks ... ~Description of contained building block (black boxes)~ Important Interfaces ... ~Description of important interfaces~ ~Name black box 1~ \u00b6 ... Purpose/Responsibility ... Interface(s) ... ~(Optional) Quality/Performance Characteristics~ ... ~(Optional) Directory/File Location~ ... ~(Optional) Fulfilled Requirements~ ... ~(optional) Open Issues/Problems/Risks~ ~Name black box 2~ \u00b6 ... ~black box template~ ~Name black box n~ \u00b6 ... ~black box template~ ~Name interface 1~ \u00b6 \u2026 ~Name interface m~ \u00b6 Level 2 \u00b6 White Box ~building block 1~ \u00b6 ... ~white box template~ White Box ~building block 2~ \u00b6 ... ~white box template~ \u2026 White Box ~building block m~ \u00b6 ... ~white box template~ Level 3 \u00b6 White Box ~_building block x.1_~ \u00b6 ... ~white box template~ White Box ~_building block x.2_~ \u00b6 ... ~white box template~ White Box ~_building block y.1_~ \u00b6 ... ~white box template~","title":"Building Block View"},{"location":"architecture/05_building_block_view/#building-block-view","text":"","title":"Building Block View"},{"location":"architecture/05_building_block_view/#white-box-overall-system","text":"... ~Overview Diagram~ Motivation ... ~text explanation~ Contained Building Blocks ... ~Description of contained building block (black boxes)~ Important Interfaces ... ~Description of important interfaces~","title":"White box Overall System"},{"location":"architecture/05_building_block_view/#name-black-box-1","text":"... Purpose/Responsibility ... Interface(s) ... ~(Optional) Quality/Performance Characteristics~ ... ~(Optional) Directory/File Location~ ... ~(Optional) Fulfilled Requirements~ ... ~(optional) Open Issues/Problems/Risks~","title":"~Name black box 1~"},{"location":"architecture/05_building_block_view/#name-black-box-2","text":"... ~black box template~","title":"~Name black box 2~"},{"location":"architecture/05_building_block_view/#name-black-box-n","text":"... ~black box template~","title":"~Name black box n~"},{"location":"architecture/05_building_block_view/#name-interface-1","text":"\u2026","title":"~Name interface 1~"},{"location":"architecture/05_building_block_view/#name-interface-m","text":"","title":"~Name interface m~"},{"location":"architecture/05_building_block_view/#level-2","text":"","title":"Level 2"},{"location":"architecture/05_building_block_view/#white-box-building-block-1","text":"... ~white box template~","title":"White Box ~building block 1~"},{"location":"architecture/05_building_block_view/#white-box-building-block-2","text":"... ~white box template~ \u2026","title":"White Box ~building block 2~"},{"location":"architecture/05_building_block_view/#white-box-building-block-m","text":"... ~white box template~","title":"White Box ~building block m~"},{"location":"architecture/05_building_block_view/#level-3","text":"","title":"Level 3"},{"location":"architecture/05_building_block_view/#white-box-_building-block-x1_","text":"... ~white box template~","title":"White Box ~_building block x.1_~"},{"location":"architecture/05_building_block_view/#white-box-_building-block-x2_","text":"... ~white box template~","title":"White Box ~_building block x.2_~"},{"location":"architecture/05_building_block_view/#white-box-_building-block-y1_","text":"... ~white box template~","title":"White Box ~_building block y.1_~"},{"location":"architecture/06_runtime_view/","text":"Runtime View \u00b6 ~Runtime Scenario 1~ \u00b6 ~insert runtime diagram or textual description of the scenario~ ~insert description of the notable aspects of the interactions between the building block instances depicted in this diagram.~ ~Runtime Scenario 2~ \u00b6 \u2026 \u00b6 ~Runtime Scenario n~ \u00b6","title":"Runtime View"},{"location":"architecture/06_runtime_view/#runtime-view","text":"","title":"Runtime View"},{"location":"architecture/06_runtime_view/#runtime-scenario-1","text":"~insert runtime diagram or textual description of the scenario~ ~insert description of the notable aspects of the interactions between the building block instances depicted in this diagram.~","title":"~Runtime Scenario 1~"},{"location":"architecture/06_runtime_view/#runtime-scenario-2","text":"","title":"~Runtime Scenario 2~"},{"location":"architecture/06_runtime_view/#_1","text":"","title":"\u2026"},{"location":"architecture/06_runtime_view/#runtime-scenario-n","text":"","title":"~Runtime Scenario n~"},{"location":"architecture/07_deployment_view/","text":"Deployment View \u00b6 Infrastructure Level 1 \u00b6 ... ~Overview Diagram~ Motivation ... ~explanation in text form~ Quality and/or Performance Features ... ~explanation in text form~ Mapping of Building Blocks to Infrastructure ... ~description of the mapping~ Infrastructure Level 2 \u00b6 ~Infrastructure Element 1~ \u00b6 ... ~diagram + explanation~ ~Infrastructure Element 2~ \u00b6 ... ~diagram + explanation~ \u2026 ~Infrastructure Element n~ \u00b6 ... ~diagram + explanation~","title":"Deployment View"},{"location":"architecture/07_deployment_view/#deployment-view","text":"","title":"Deployment View"},{"location":"architecture/07_deployment_view/#infrastructure-level-1","text":"... ~Overview Diagram~ Motivation ... ~explanation in text form~ Quality and/or Performance Features ... ~explanation in text form~ Mapping of Building Blocks to Infrastructure ... ~description of the mapping~","title":"Infrastructure Level 1"},{"location":"architecture/07_deployment_view/#infrastructure-level-2","text":"","title":"Infrastructure Level 2"},{"location":"architecture/07_deployment_view/#infrastructure-element-1","text":"... ~diagram + explanation~","title":"~Infrastructure Element 1~"},{"location":"architecture/07_deployment_view/#infrastructure-element-2","text":"... ~diagram + explanation~ \u2026","title":"~Infrastructure Element 2~"},{"location":"architecture/07_deployment_view/#infrastructure-element-n","text":"... ~diagram + explanation~","title":"~Infrastructure Element n~"},{"location":"architecture/08_concepts/","text":"Cross-cutting Concepts \u00b6 ~Concept 1~ \u00b6 ... explanation ~Concept 2~ \u00b6 ... explanation \u2026 ~Concept n~ \u00b6 ... explanation","title":"Cross-cutting Concepts"},{"location":"architecture/08_concepts/#cross-cutting-concepts","text":"","title":"Cross-cutting Concepts"},{"location":"architecture/08_concepts/#concept-1","text":"... explanation","title":"~Concept 1~"},{"location":"architecture/08_concepts/#concept-2","text":"... explanation \u2026","title":"~Concept 2~"},{"location":"architecture/08_concepts/#concept-n","text":"... explanation","title":"~Concept n~"},{"location":"architecture/10_quality_requirements/","text":"Quality Requirements \u00b6 Quality Tree \u00b6 Quality Scenarios \u00b6","title":"Quality Requirements"},{"location":"architecture/10_quality_requirements/#quality-requirements","text":"","title":"Quality Requirements"},{"location":"architecture/10_quality_requirements/#quality-tree","text":"","title":"Quality Tree"},{"location":"architecture/10_quality_requirements/#quality-scenarios","text":"","title":"Quality Scenarios"},{"location":"architecture/11_technical_risks/","text":"Risks and Technical Debts \u00b6","title":"Risks and Technical Debts"},{"location":"architecture/11_technical_risks/#risks-and-technical-debts","text":"","title":"Risks and Technical Debts"},{"location":"architecture/12_glossary/","text":"Glossary \u00b6 Term Definition Term-1 definition-1 Term-2 definition-2","title":"Glossary"},{"location":"architecture/12_glossary/#glossary","text":"Term Definition Term-1 definition-1 Term-2 definition-2","title":"Glossary"},{"location":"architecture/09_architecture_decisions/0001-arch-std/","text":"Context \u00b6 There needs to be a commonly understood and well documented structure to Architecture Documentation. Architecture Documentation is the responsibility of the entire team. A standardized structure to that documentation helps with collaboration. Assumptions \u00b6 Architecture documentation is the collective responsibility of the development team. A well documented structure to that documentation will aid in collaboration and maintenance of the documentation. Decision \u00b6 We will be using the arc42 standard for organizing architecture documentation. Risks \u00b6 That arc42 becomes unmaintained upstream, or some flaw is found with its methodology. That the team does not understand the structure of the architecture documentation or necessity to maintain it. Consequences \u00b6 If we do: It is easier to maintain documentation when there is an agreed structure to it. It is easier to on-board new members of the team when there are resources to help understand the documentation and its structure. Architecture Documentation will be of higher quality and more meaningfully reviewed in the context of an agreed structure. If we don't: Architecture docs will be \"ad-hoc\". Difficult for the team to meaningfully collaborate on Architecture. Difficult to maintain. Difficult to ensure the necessary information is captured. Difficult to iterate and be agile. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 arc42 Original Templates Main Documentation Books Examples","title":"0001 Architecture Documentation Standard"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#context","text":"There needs to be a commonly understood and well documented structure to Architecture Documentation. Architecture Documentation is the responsibility of the entire team. A standardized structure to that documentation helps with collaboration.","title":"Context"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#assumptions","text":"Architecture documentation is the collective responsibility of the development team. A well documented structure to that documentation will aid in collaboration and maintenance of the documentation.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#decision","text":"We will be using the arc42 standard for organizing architecture documentation.","title":"Decision"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#risks","text":"That arc42 becomes unmaintained upstream, or some flaw is found with its methodology. That the team does not understand the structure of the architecture documentation or necessity to maintain it.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#consequences","text":"If we do: It is easier to maintain documentation when there is an agreed structure to it. It is easier to on-board new members of the team when there are resources to help understand the documentation and its structure. Architecture Documentation will be of higher quality and more meaningfully reviewed in the context of an agreed structure. If we don't: Architecture docs will be \"ad-hoc\". Difficult for the team to meaningfully collaborate on Architecture. Difficult to maintain. Difficult to ensure the necessary information is captured. Difficult to iterate and be agile.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0001-arch-std/#more-information","text":"arc42 Original Templates Main Documentation Books Examples","title":"More Information"},{"location":"architecture/09_architecture_decisions/0002-adr/","text":"Context \u00b6 Architecture Decision Records are part of arc42 . We need an efficient and automated way to manage them. The system needs to be easy for anyone to use as documenting Architecture Decisions is a team responsibility. Assumptions \u00b6 The team as a whole is responsible for creating and maintaining Architecture Decision Records. Decision \u00b6 We will use the MkDocs Material ADR Plugin to assist in ADR documentation and automation. Risks \u00b6 The plugin doesn't get maintained or has technical issues This risk can be mitigated because the plugin is simple, and it would be easy for us to fork and maintain it as required. Consequences \u00b6 ADR become easier for people to author. This should assist in making the team more pro-active in their creation and maintenance. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 arc42 arc42 ADR Guide MkDocs Material ADR Plugin Fixed fork of MkDocs Material ADR Plugin","title":"0002 Architecture Decision Records"},{"location":"architecture/09_architecture_decisions/0002-adr/#context","text":"Architecture Decision Records are part of arc42 . We need an efficient and automated way to manage them. The system needs to be easy for anyone to use as documenting Architecture Decisions is a team responsibility.","title":"Context"},{"location":"architecture/09_architecture_decisions/0002-adr/#assumptions","text":"The team as a whole is responsible for creating and maintaining Architecture Decision Records.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0002-adr/#decision","text":"We will use the MkDocs Material ADR Plugin to assist in ADR documentation and automation.","title":"Decision"},{"location":"architecture/09_architecture_decisions/0002-adr/#risks","text":"The plugin doesn't get maintained or has technical issues This risk can be mitigated because the plugin is simple, and it would be easy for us to fork and maintain it as required.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0002-adr/#consequences","text":"ADR become easier for people to author. This should assist in making the team more pro-active in their creation and maintenance.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0002-adr/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0002-adr/#more-information","text":"arc42 arc42 ADR Guide MkDocs Material ADR Plugin Fixed fork of MkDocs Material ADR Plugin","title":"More Information"},{"location":"architecture/09_architecture_decisions/0003-language/","text":"Context \u00b6 Any project contains a large amount of human readable text. The team is multi-national and a common primary language needs to be chosen for the project. Assumptions \u00b6 That everyone on the team will have a reasonable grasp of the primary language of the project. That it will be reasonable to enforce the primary language on all team members contributions. Decision \u00b6 After consultation with the existing team, and considerations of the audience for the project the primary language of the project will be: US English Risks \u00b6 That people where English is not a primary language will have difficulty conforming to the requirement. Consequences \u00b6 Having a uniform language for the project makes it easier for people to interact on a common basis. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 Why English is the Lingua Franca of Programming","title":"0003 Language"},{"location":"architecture/09_architecture_decisions/0003-language/#context","text":"Any project contains a large amount of human readable text. The team is multi-national and a common primary language needs to be chosen for the project.","title":"Context"},{"location":"architecture/09_architecture_decisions/0003-language/#assumptions","text":"That everyone on the team will have a reasonable grasp of the primary language of the project. That it will be reasonable to enforce the primary language on all team members contributions.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0003-language/#decision","text":"After consultation with the existing team, and considerations of the audience for the project the primary language of the project will be: US English","title":"Decision"},{"location":"architecture/09_architecture_decisions/0003-language/#risks","text":"That people where English is not a primary language will have difficulty conforming to the requirement.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0003-language/#consequences","text":"Having a uniform language for the project makes it easier for people to interact on a common basis.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0003-language/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0003-language/#more-information","text":"Why English is the Lingua Franca of Programming","title":"More Information"},{"location":"architecture/09_architecture_decisions/0004-spelling/","text":"Context \u00b6 Any project contains a large amount of human readable text. The team is multi-national and it can not be assumed that everyone has a strong skills with the primary language of the project. Assumptions \u00b6 That everyone on the team has a reasonable grasp of the primary language of the project. Decision \u00b6 That the spelling of the Primary Language will be enforced in CI using: CSpell US English dictionaries Technical words Custom words on a pre-project basis Secondary Languages which are used in translating the UI, will also be checked with CSpell . Risks \u00b6 That a dictionary for a Secondary language does not exist for CSpell. It is possible to use custom dictionaries with CSpell . If a standard dictionary does not exist, a custom language dictionary can be added. This risk is mitigated. Consequences \u00b6 Enforcing spelling in CI helps enforce consistency of all Human Readable text. By using automation we ensure this consistency, regardless of a contributors proficiency with the primary language cspell Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 CSpell","title":"0004 Spelling"},{"location":"architecture/09_architecture_decisions/0004-spelling/#context","text":"Any project contains a large amount of human readable text. The team is multi-national and it can not be assumed that everyone has a strong skills with the primary language of the project.","title":"Context"},{"location":"architecture/09_architecture_decisions/0004-spelling/#assumptions","text":"That everyone on the team has a reasonable grasp of the primary language of the project.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0004-spelling/#decision","text":"That the spelling of the Primary Language will be enforced in CI using: CSpell US English dictionaries Technical words Custom words on a pre-project basis Secondary Languages which are used in translating the UI, will also be checked with CSpell .","title":"Decision"},{"location":"architecture/09_architecture_decisions/0004-spelling/#risks","text":"That a dictionary for a Secondary language does not exist for CSpell. It is possible to use custom dictionaries with CSpell . If a standard dictionary does not exist, a custom language dictionary can be added. This risk is mitigated.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0004-spelling/#consequences","text":"Enforcing spelling in CI helps enforce consistency of all Human Readable text. By using automation we ensure this consistency, regardless of a contributors proficiency with the primary language cspell","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0004-spelling/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0004-spelling/#more-information","text":"CSpell","title":"More Information"},{"location":"architecture/09_architecture_decisions/0005-rust/","text":"Context \u00b6 Languages used in the project need to be chosen based on: their strengths suitability to the tasks they are used for familiarity with the team. Assumptions \u00b6 That the language chosen will continue to be a mainstream language. That it will be reasonably easy to find developers proficient in it. Decision \u00b6 Backend and System level services can be coded in: Rust Other languages can be also be used for these services as described by their own ADR. Risks \u00b6 Learning Curve: Rust has a steep learning curve, especially for developers who are new to systems programming or low-level languages. The language enforces strict memory safety rules and introduces concepts like ownership, borrowing, and lifetimes, which can be challenging to grasp initially. This learning curve may require additional time and effort for developers to become proficient in Rust. Ecosystem Immaturity: While Rust has a growing ecosystem, it may not have the same level of maturity and breadth as more established languages. This can result in a smaller selection of libraries and tools compared to languages like Python or Java. However, the Rust community actively develops and maintains high-quality libraries, and many common use cases are well-supported. Development Speed: Rust's focus on safety and strict compile-time checks can sometimes slow down development speed, especially for rapid prototyping or small-scale projects. The compile times in Rust can be longer compared to other languages, which may impact the iterative development process. However, the benefits of safety and performance often outweigh this trade-off in larger-scale projects. Despite these risks, Rust's benefits in terms of memory safety, performance, and concurrency make it a compelling choice for backend systems programming. Consequences \u00b6 Memory Safety: Rust's ownership system and borrow checker ensure memory safety at compile time, preventing common bugs like null pointer dereferences, buffer overflows, and data races. Performance: Rust enables low-level control over resources, developers can write efficient code with minimal runtime overhead. It offers zero-cost abstractions and fine-grained control over memory allocation. Concurrency: Rust's ownership model and built-in concurrency primitives, such as threads and channels, make it easy to write safe and concurrent code. The async/await syntax and the tokio library provide powerful asynchronous programming capabilities. Safety Guarantees: Rust's strict compile-time checks enforce safe programming practices, eliminating undefined behavior and making code more reliable. The language prevents common programming mistakes by catching them at compile time. Developer Experience: Rust has a growing ecosystem of libraries and tools, making it easier to build robust applications. The language promotes clear and explicit code, with helpful error messages and a strong type system that aids in code maintainability. Cross-platform Support: Rust is designed to be portable and can target a wide range of platforms, including desktop, mobile, and embedded systems. It supports various architectures and operating systems, making it versatile for different use cases. Interoperability: Rust can seamlessly interface with other languages, allowing developers to leverage existing code-bases or libraries. It provides C-compatible FFI (Foreign Function Interface) and supports integration with languages like C, C++, and Python. Community: Rust has a vibrant and supportive community that actively contributes to the language's development and provides valuable resources, documentation, and libraries. The community fosters a culture of knowledge sharing and collaboration. Tooling: Rust has a powerful package manager called Cargo, which simplifies dependency management and project build processes. It also offers excellent IDE support, code formatting, and extensive testing frameworks. Future-proofing: Rust is designed for long-term stability and compatibility. The language emphasizes backward compatibility and provides a strong commitment to avoiding breaking changes. This ensures that code written in Rust today will continue to work in the future. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 Rust Rust: A Language for the Next 40 Years - This video presentation by Carol Nichols highlights Rust's strengths and discusses its unique features, including memory safety, zero-cost abstractions, and concurrency.","title":"0005 Rust"},{"location":"architecture/09_architecture_decisions/0005-rust/#context","text":"Languages used in the project need to be chosen based on: their strengths suitability to the tasks they are used for familiarity with the team.","title":"Context"},{"location":"architecture/09_architecture_decisions/0005-rust/#assumptions","text":"That the language chosen will continue to be a mainstream language. That it will be reasonably easy to find developers proficient in it.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0005-rust/#decision","text":"Backend and System level services can be coded in: Rust Other languages can be also be used for these services as described by their own ADR.","title":"Decision"},{"location":"architecture/09_architecture_decisions/0005-rust/#risks","text":"Learning Curve: Rust has a steep learning curve, especially for developers who are new to systems programming or low-level languages. The language enforces strict memory safety rules and introduces concepts like ownership, borrowing, and lifetimes, which can be challenging to grasp initially. This learning curve may require additional time and effort for developers to become proficient in Rust. Ecosystem Immaturity: While Rust has a growing ecosystem, it may not have the same level of maturity and breadth as more established languages. This can result in a smaller selection of libraries and tools compared to languages like Python or Java. However, the Rust community actively develops and maintains high-quality libraries, and many common use cases are well-supported. Development Speed: Rust's focus on safety and strict compile-time checks can sometimes slow down development speed, especially for rapid prototyping or small-scale projects. The compile times in Rust can be longer compared to other languages, which may impact the iterative development process. However, the benefits of safety and performance often outweigh this trade-off in larger-scale projects. Despite these risks, Rust's benefits in terms of memory safety, performance, and concurrency make it a compelling choice for backend systems programming.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0005-rust/#consequences","text":"Memory Safety: Rust's ownership system and borrow checker ensure memory safety at compile time, preventing common bugs like null pointer dereferences, buffer overflows, and data races. Performance: Rust enables low-level control over resources, developers can write efficient code with minimal runtime overhead. It offers zero-cost abstractions and fine-grained control over memory allocation. Concurrency: Rust's ownership model and built-in concurrency primitives, such as threads and channels, make it easy to write safe and concurrent code. The async/await syntax and the tokio library provide powerful asynchronous programming capabilities. Safety Guarantees: Rust's strict compile-time checks enforce safe programming practices, eliminating undefined behavior and making code more reliable. The language prevents common programming mistakes by catching them at compile time. Developer Experience: Rust has a growing ecosystem of libraries and tools, making it easier to build robust applications. The language promotes clear and explicit code, with helpful error messages and a strong type system that aids in code maintainability. Cross-platform Support: Rust is designed to be portable and can target a wide range of platforms, including desktop, mobile, and embedded systems. It supports various architectures and operating systems, making it versatile for different use cases. Interoperability: Rust can seamlessly interface with other languages, allowing developers to leverage existing code-bases or libraries. It provides C-compatible FFI (Foreign Function Interface) and supports integration with languages like C, C++, and Python. Community: Rust has a vibrant and supportive community that actively contributes to the language's development and provides valuable resources, documentation, and libraries. The community fosters a culture of knowledge sharing and collaboration. Tooling: Rust has a powerful package manager called Cargo, which simplifies dependency management and project build processes. It also offers excellent IDE support, code formatting, and extensive testing frameworks. Future-proofing: Rust is designed for long-term stability and compatibility. The language emphasizes backward compatibility and provides a strong commitment to avoiding breaking changes. This ensures that code written in Rust today will continue to work in the future.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0005-rust/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0005-rust/#more-information","text":"Rust Rust: A Language for the Next 40 Years - This video presentation by Carol Nichols highlights Rust's strengths and discusses its unique features, including memory safety, zero-cost abstractions, and concurrency.","title":"More Information"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/","text":"Context \u00b6 Rust has an optional cargo.lock file which can lock the dependencies of a project. There are pros and cons to using the lock file. Assumptions \u00b6 This ADR is deliberately limited to the initial bring up phase of our projects, and subject to review. Decision \u00b6 Rust will not use cargo.lock when consuming libraries. It will ONLY respect it for building binaries. As we are in the initial stages of a number of projects, it is easier to iterate without worrying about cargo.lock being up-to-date. Accordingly, until the binaries we would publish approach releasable state we will not use the cargo.lock file. Risks \u00b6 We forget to introduce cargo.lock on our binaries when we approach release. Consequences \u00b6 This should make it a little easier to iterate with less issues caused by out of date cargo.lock files finding there way into CI. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 Cargo/toml vs Cargo.lock Why have Cargo.lock in Version Control","title":"0006 Rust Cargo Lock"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#context","text":"Rust has an optional cargo.lock file which can lock the dependencies of a project. There are pros and cons to using the lock file.","title":"Context"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#assumptions","text":"This ADR is deliberately limited to the initial bring up phase of our projects, and subject to review.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#decision","text":"Rust will not use cargo.lock when consuming libraries. It will ONLY respect it for building binaries. As we are in the initial stages of a number of projects, it is easier to iterate without worrying about cargo.lock being up-to-date. Accordingly, until the binaries we would publish approach releasable state we will not use the cargo.lock file.","title":"Decision"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#risks","text":"We forget to introduce cargo.lock on our binaries when we approach release.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#consequences","text":"This should make it a little easier to iterate with less issues caused by out of date cargo.lock files finding there way into CI.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0006-rust-cargo-lock/#more-information","text":"Cargo/toml vs Cargo.lock Why have Cargo.lock in Version Control","title":"More Information"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/","text":"Context \u00b6 In the Rust cargo.toml it is possible to specify a minimum version of Rust supported by a Crate/Application. This rust projects which consume crates to ensure they or on a supported version. There should be a policy about How many old versions of Rust is supported by our project. Assumptions \u00b6 This ADR is deliberately limited to the initial bring up phase of our projects, and subject to review. Decision \u00b6 We will not use the rust-version feature of cargo.toml during initial bring up. We have not defined a maximum range of valid Rust versions, and always build ONLY with the version defined in rust-toolchain.toml . Currently the ONLY supported rust version is the one specified by rust-toolchain.toml . However rust-toolchain.toml breaks CI when it is used, so this file is ONLY used for local development and MUST be synchronized with the toolchain version used in CI. If at a later time, a range of rust versions is decided to be supported then: This ADR will be obsoleted by a new one which defines that range of supported versions. The allowable range will need to be enforced in CI to ensure a Cargo.toml file does not specify the wrong thing. All Rust versions in that range will need to be tested in CI to ensure they are properly supported. Risks \u00b6 None, this decision is subject to review at any time. Consequences \u00b6 Development should be easier, and CI faster as we are specifically locked to a single Rust toolchain version. Scope \u00b6 This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project. More Information \u00b6 rust-version field","title":"0007 Rust Version configuration in `cargo.toml`"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#context","text":"In the Rust cargo.toml it is possible to specify a minimum version of Rust supported by a Crate/Application. This rust projects which consume crates to ensure they or on a supported version. There should be a policy about How many old versions of Rust is supported by our project.","title":"Context"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#assumptions","text":"This ADR is deliberately limited to the initial bring up phase of our projects, and subject to review.","title":"Assumptions"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#decision","text":"We will not use the rust-version feature of cargo.toml during initial bring up. We have not defined a maximum range of valid Rust versions, and always build ONLY with the version defined in rust-toolchain.toml . Currently the ONLY supported rust version is the one specified by rust-toolchain.toml . However rust-toolchain.toml breaks CI when it is used, so this file is ONLY used for local development and MUST be synchronized with the toolchain version used in CI. If at a later time, a range of rust versions is decided to be supported then: This ADR will be obsoleted by a new one which defines that range of supported versions. The allowable range will need to be enforced in CI to ensure a Cargo.toml file does not specify the wrong thing. All Rust versions in that range will need to be tested in CI to ensure they are properly supported.","title":"Decision"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#risks","text":"None, this decision is subject to review at any time.","title":"Risks"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#consequences","text":"Development should be easier, and CI faster as we are specifically locked to a single Rust toolchain version.","title":"Consequences"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#scope","text":"This ADR applies to all projects which consume Catalyst-CI unless they define an ADR specific to that project.","title":"Scope"},{"location":"architecture/09_architecture_decisions/0007-minimum-rust-version-supported/#more-information","text":"rust-version field","title":"More Information"},{"location":"guides/","text":"Guides \u00b6 This section contains guides for using the Catalyst CI to perform common tasks. If you're just getting started with Catalyst CI, these guides will prove useful for getting going as fast as possible. Each guide contains a full reference Earthfile as well as step-by-step instructions for building it. Most guides are broken down by a particular task. The language section contains guides for getting started with a particular programming language. If you don't see a guide, please feel free to submit an issue requesting it. Even better, open a PR that adds the guide!","title":"Guides"},{"location":"guides/#guides","text":"This section contains guides for using the Catalyst CI to perform common tasks. If you're just getting started with Catalyst CI, these guides will prove useful for getting going as fast as possible. Each guide contains a full reference Earthfile as well as step-by-step instructions for building it. Most guides are broken down by a particular task. The language section contains guides for getting started with a particular programming language. If you don't see a guide, please feel free to submit an issue requesting it. Even better, open a PR that adds the guide!","title":"Guides"},{"location":"guides/docs/","text":"Docs \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how this docs was built. This guide will get you started with using the Catalyst CI to build MkDocs documentation. By the end of it, we'll have an Earthfile that utilizes docs build process, and it has been publishing on github pages. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to docs directory to find current documentation which you are reading right now. This folder already has an Earthfile in it, which contains all build process. Building docs image \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . VERSION 0.8 # Copy all the source we need to build the docs src: # Common src setup DO ../earthly/docs+SRC # Now copy into that any artifacts we pull from the builds. COPY --dir ../+repo-docs/repo includes The first step of building process it preparing a source files. It is mandatory to have a src directory with all documentation md files in it and mkdocs.yml file. This directory and file will be picked during the execution of +SRC Function. Also it is possible to replace defined includes , macros and overrides dirs to customize some docs appearance and configuration. Default value of the content of includes , macros and overrides dirs you can find in earthly/docs/common folder. Additionally it is possible to provide some additional files as for example to extend includes dir content. The standard theme is defined in the std-theme.yml . It must be included in the first line of the documentations mkdocs.yml file like so: INHERIT: std-theme.yml This file can be found in the earthly/docs/common folder. Changes to the standard theme should be intended to effect all documentation that uses the standard theme. Individual documentation targets can customize the theme in their mkdocs.yml file. # Build the docs here. docs: FROM +src DO ../earthly/docs+BUILD To build a docs artifact which will be used later just invoke +BUILD Function on the already prepared docs environment +src target which we have discussed before. # Make a docker image that can serve the docs for development purposes. # This target is only for local developer use. local: DO ../earthly/docs+PACKAGE COPY +docs/ /usr/share/nginx/html SAVE IMAGE cat-ci-docs:latest To finally build a docker image which is pretty strait forward process, you should firstly invoke +PACKAGE Function which will prepare an environment for future docs image, next step is to copy builded artifact from the previous step to /usr/share/nginx/html folder. And the last step is to save a docker image with the specified name, tag and registry if it is needed. Local docs run \u00b6 To locally run docs which it is needed to get a earthly/docs/dev/local.py python script which will automatically invoke +local to build docs image what was discussed before. This script will locally deploy docs and rebuild them if they changed every 10 seconds. Script should be run from the root of the repository in which docs folder exists with all documentation in it and already discussed Earthfile . Script arguments: container_name - Name of the container. --exposed-port - Exposed port of the container (default 8123 ). --target - Earthly target to run (default ./docs+local ). -no-browser - Do not open the browser. Here is an example how to run it for current repo earthly/docs/dev/local.py cat-ci-docs:latest Note To deploy docs for any other repositories as for example catalyst-voices or any other as it was mentioned above it is needed to get local.py script and run it from the root of your repo as for example <path_to_catalyst_ci>/earthly/docs/dev/local.py <docker_image_name> Doc's update PR \u00b6 When a PR is raised the documentation for that PR is built and published. Branch docs are published to <pages>/branch/<branch_name> . <branch_name> is the name of the branch with all non alpha-numeric characters replaced by underscore ( _ ). When the branch is finally merged, the branch documentation is removed. This allows us to easily validate what any PR will do to the published documentation before its published officially. All PR's documentation should be checked as part of PR review. Not just the contents of the PR itself.","title":"Docs"},{"location":"guides/docs/#docs","text":"","title":"Docs"},{"location":"guides/docs/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how this docs was built. This guide will get you started with using the Catalyst CI to build MkDocs documentation. By the end of it, we'll have an Earthfile that utilizes docs build process, and it has been publishing on github pages. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to docs directory to find current documentation which you are reading right now. This folder already has an Earthfile in it, which contains all build process.","title":"Introduction"},{"location":"guides/docs/#building-docs-image","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . VERSION 0.8 # Copy all the source we need to build the docs src: # Common src setup DO ../earthly/docs+SRC # Now copy into that any artifacts we pull from the builds. COPY --dir ../+repo-docs/repo includes The first step of building process it preparing a source files. It is mandatory to have a src directory with all documentation md files in it and mkdocs.yml file. This directory and file will be picked during the execution of +SRC Function. Also it is possible to replace defined includes , macros and overrides dirs to customize some docs appearance and configuration. Default value of the content of includes , macros and overrides dirs you can find in earthly/docs/common folder. Additionally it is possible to provide some additional files as for example to extend includes dir content. The standard theme is defined in the std-theme.yml . It must be included in the first line of the documentations mkdocs.yml file like so: INHERIT: std-theme.yml This file can be found in the earthly/docs/common folder. Changes to the standard theme should be intended to effect all documentation that uses the standard theme. Individual documentation targets can customize the theme in their mkdocs.yml file. # Build the docs here. docs: FROM +src DO ../earthly/docs+BUILD To build a docs artifact which will be used later just invoke +BUILD Function on the already prepared docs environment +src target which we have discussed before. # Make a docker image that can serve the docs for development purposes. # This target is only for local developer use. local: DO ../earthly/docs+PACKAGE COPY +docs/ /usr/share/nginx/html SAVE IMAGE cat-ci-docs:latest To finally build a docker image which is pretty strait forward process, you should firstly invoke +PACKAGE Function which will prepare an environment for future docs image, next step is to copy builded artifact from the previous step to /usr/share/nginx/html folder. And the last step is to save a docker image with the specified name, tag and registry if it is needed.","title":"Building docs image"},{"location":"guides/docs/#local-docs-run","text":"To locally run docs which it is needed to get a earthly/docs/dev/local.py python script which will automatically invoke +local to build docs image what was discussed before. This script will locally deploy docs and rebuild them if they changed every 10 seconds. Script should be run from the root of the repository in which docs folder exists with all documentation in it and already discussed Earthfile . Script arguments: container_name - Name of the container. --exposed-port - Exposed port of the container (default 8123 ). --target - Earthly target to run (default ./docs+local ). -no-browser - Do not open the browser. Here is an example how to run it for current repo earthly/docs/dev/local.py cat-ci-docs:latest Note To deploy docs for any other repositories as for example catalyst-voices or any other as it was mentioned above it is needed to get local.py script and run it from the root of your repo as for example <path_to_catalyst_ci>/earthly/docs/dev/local.py <docker_image_name>","title":"Local docs run"},{"location":"guides/docs/#docs-update-pr","text":"When a PR is raised the documentation for that PR is built and published. Branch docs are published to <pages>/branch/<branch_name> . <branch_name> is the name of the branch with all non alpha-numeric characters replaced by underscore ( _ ). When the branch is finally merged, the branch documentation is removed. This allows us to easily validate what any PR will do to the published documentation before its published officially. All PR's documentation should be checked as part of PR review. Not just the contents of the PR itself.","title":"Doc's update PR"},{"location":"guides/json_yaml_linter/","text":"Spectral / JSON and YAML Linter \u00b6 JSON and YAML files can be linted with custom rules using Spectral . The goal of using this linter is to ensure that best practice is followed. Configuration \u00b6 Each repo will need one configuration file in the root of the repository. .spectral.yml - Configures rules, which can be used to lint the JSON or YAML files. There are rules available to be used or customization is possible too. For more information, please visit Spectral Document Usage \u00b6 The linter can be used in different purpose, so a FUNCTION named BUILD_SPECTRAL is implemented to make it suit the purpose. BUILD_SPECTRAL contains four main arguments file_type : the file type that will be lint. If it is set to json , minifying the JSON files will be performed. JSON and YAML linting are not allowed simultaneously to prevent conflicts. Enforcing separate linting ensures accurate analysis for each file type in a folder, avoiding errors. dir : A directory that contains files to be lint. src : The root directory rule_set : Rules set that is used Example \u00b6 The example of using the linter can be found in link . The target check-lint-openapi is currently used for linting OpenAPI JSON file. The current rules set that is being used are: OWASP TOP 10 Spectral Documentation OpenAPI The example of OpenAPI documentation can be found in link . Warning Please note that this OpenAPI documentation provided in this repository is used for example purposes only. For more information about OpenAPI Specification, please visit the official documentation .","title":"Json yaml linter"},{"location":"guides/json_yaml_linter/#spectral-json-and-yaml-linter","text":"JSON and YAML files can be linted with custom rules using Spectral . The goal of using this linter is to ensure that best practice is followed.","title":"Spectral / JSON and YAML Linter"},{"location":"guides/json_yaml_linter/#configuration","text":"Each repo will need one configuration file in the root of the repository. .spectral.yml - Configures rules, which can be used to lint the JSON or YAML files. There are rules available to be used or customization is possible too. For more information, please visit Spectral Document","title":"Configuration"},{"location":"guides/json_yaml_linter/#usage","text":"The linter can be used in different purpose, so a FUNCTION named BUILD_SPECTRAL is implemented to make it suit the purpose. BUILD_SPECTRAL contains four main arguments file_type : the file type that will be lint. If it is set to json , minifying the JSON files will be performed. JSON and YAML linting are not allowed simultaneously to prevent conflicts. Enforcing separate linting ensures accurate analysis for each file type in a folder, avoiding errors. dir : A directory that contains files to be lint. src : The root directory rule_set : Rules set that is used","title":"Usage"},{"location":"guides/json_yaml_linter/#example","text":"The example of using the linter can be found in link . The target check-lint-openapi is currently used for linting OpenAPI JSON file. The current rules set that is being used are: OWASP TOP 10 Spectral Documentation OpenAPI The example of OpenAPI documentation can be found in link . Warning Please note that this OpenAPI documentation provided in this repository is used for example purposes only. For more information about OpenAPI Specification, please visit the official documentation .","title":"Example"},{"location":"guides/markdown/","text":"Markdown Check \u00b6 This Earthly Target and Function enables uniform linting of Markdown files to maintain consistency and quality. This Function is NOT intended to be used inside container builds. Its sole purpose is to enforce uniform style rules for all markdown files in a repository. It makes no assumptions about which files may or may not end up inside a container or are part of a build. This is INTENTIONAL . IF this Function is used inside a container build, it is NOT a bug if it does not do the correct thing. Introduction \u00b6 Markdown file checking is integrated into the check pipeline. The reference to the pipeline can be found here . The goal of the check stage is to ensure the overall health of the project. Specifically, for markdown checks, it ensures that all markdown files follow valid rules. Configuration \u00b6 Each repo will need two configuration files in the root of the repository: .markdownlint.jsonc - Configures individual markdown rules. .markdownlint-cli2.jsonc - Configures the CLI Tool. The configuration should be copied from the root of the Catalyst-CI repository into the target repo. Individual projects should have no need to individually customize these rules. Any changes to the markdown rules should be it's own PR. It should first be made to the Base rules in the Catalyst-CI project and only once merged, copied into all other effected repos. This is to ensure a consistent rule set across all repos. Additional references to the rules can be read here How it works \u00b6 Linting is performed with the mdlint-cli2 program. This linter is to be used in preference to any other Markdown linter. This is because we need to provide uniform and consistent Markdown formatting and linting across the project and between projects. Using the markdown check \u00b6 Locally \u00b6 Running check \u00b6 Executing earthly +check will automatically run all checks, including the verification of markdown files in the repository. To view the specific checks performed during the check stage, use the command earthly doc . All the check done in check target should be named as check-<name> . Running markdown fix \u00b6 If an error occurs, earthly +markdown-check-fix can be used to automatically fix the error. Note Please note that this command will fix the issues based on the capabilities of the linter. Remotely \u00b6 Performing a markdown check can be done in your repository by adding the following code: Checking the markdown in your repo \u00b6 check-markdown: DO github.com/input-output-hk/catalyst-ci/earthly/mdlint:<tag>+CHECK Note that the source directory is not required since default is set as current directory. Checking and fixing the markdown in your repo \u00b6 markdown-check-fix: LOCALLY DO github.com/input-output-hk/catalyst-ci/earthly/mdlint:<tag>+MDLINT_LOCALLY --src=$(echo ${PWD}) --fix=--fix In this use case, the Function is run Locally, so that the markdown in the repo can be directly checked. Note tag is needed to be specified to the right version. Disable markdownlint rules \u00b6 Markdown linter rules can be disable for specific file or lines. <!-- markdownlint-disable rules --> For more example, please refer to this doc Editor Integration \u00b6 mdlint-cli2 is integrated into VSCode and may be integrated into other Editors. The editor integration should pick up both the .markdownlint.jsonc and .markdownlint-cli2.jsonc configuration files. It will then behave exactly the same as the Earthly Function.","title":"Markdown Check"},{"location":"guides/markdown/#markdown-check","text":"This Earthly Target and Function enables uniform linting of Markdown files to maintain consistency and quality. This Function is NOT intended to be used inside container builds. Its sole purpose is to enforce uniform style rules for all markdown files in a repository. It makes no assumptions about which files may or may not end up inside a container or are part of a build. This is INTENTIONAL . IF this Function is used inside a container build, it is NOT a bug if it does not do the correct thing.","title":"Markdown Check"},{"location":"guides/markdown/#introduction","text":"Markdown file checking is integrated into the check pipeline. The reference to the pipeline can be found here . The goal of the check stage is to ensure the overall health of the project. Specifically, for markdown checks, it ensures that all markdown files follow valid rules.","title":"Introduction"},{"location":"guides/markdown/#configuration","text":"Each repo will need two configuration files in the root of the repository: .markdownlint.jsonc - Configures individual markdown rules. .markdownlint-cli2.jsonc - Configures the CLI Tool. The configuration should be copied from the root of the Catalyst-CI repository into the target repo. Individual projects should have no need to individually customize these rules. Any changes to the markdown rules should be it's own PR. It should first be made to the Base rules in the Catalyst-CI project and only once merged, copied into all other effected repos. This is to ensure a consistent rule set across all repos. Additional references to the rules can be read here","title":"Configuration"},{"location":"guides/markdown/#how-it-works","text":"Linting is performed with the mdlint-cli2 program. This linter is to be used in preference to any other Markdown linter. This is because we need to provide uniform and consistent Markdown formatting and linting across the project and between projects.","title":"How it works"},{"location":"guides/markdown/#using-the-markdown-check","text":"","title":"Using the markdown check"},{"location":"guides/markdown/#locally","text":"","title":"Locally"},{"location":"guides/markdown/#running-check","text":"Executing earthly +check will automatically run all checks, including the verification of markdown files in the repository. To view the specific checks performed during the check stage, use the command earthly doc . All the check done in check target should be named as check-<name> .","title":"Running check"},{"location":"guides/markdown/#running-markdown-fix","text":"If an error occurs, earthly +markdown-check-fix can be used to automatically fix the error. Note Please note that this command will fix the issues based on the capabilities of the linter.","title":"Running markdown fix"},{"location":"guides/markdown/#remotely","text":"Performing a markdown check can be done in your repository by adding the following code:","title":"Remotely"},{"location":"guides/markdown/#checking-the-markdown-in-your-repo","text":"check-markdown: DO github.com/input-output-hk/catalyst-ci/earthly/mdlint:<tag>+CHECK Note that the source directory is not required since default is set as current directory.","title":"Checking the markdown in your repo"},{"location":"guides/markdown/#checking-and-fixing-the-markdown-in-your-repo","text":"markdown-check-fix: LOCALLY DO github.com/input-output-hk/catalyst-ci/earthly/mdlint:<tag>+MDLINT_LOCALLY --src=$(echo ${PWD}) --fix=--fix In this use case, the Function is run Locally, so that the markdown in the repo can be directly checked. Note tag is needed to be specified to the right version.","title":"Checking and fixing the markdown in your repo"},{"location":"guides/markdown/#disable-markdownlint-rules","text":"Markdown linter rules can be disable for specific file or lines. <!-- markdownlint-disable rules --> For more example, please refer to this doc","title":"Disable markdownlint rules"},{"location":"guides/markdown/#editor-integration","text":"mdlint-cli2 is integrated into VSCode and may be integrated into other Editors. The editor integration should pick up both the .markdownlint.jsonc and .markdownlint-cli2.jsonc configuration files. It will then behave exactly the same as the Earthly Function.","title":"Editor Integration"},{"location":"guides/simulate/","text":"Earthly Simulator \u00b6 Overview \u00b6 The following document provides an overview and usage guide for simulating Earthly locally. The simulation can be done in 2 ways Running a command line simulate : This will run Earthly command on every targets that match the given input targets. The targets will run sequentially, then preview the outcomes. Running a command line generate : This will create an Earthfile, which is set to be created at the generate/ folder inside the current directory. Inside the Earthfile, it contains a main target called simulate . This main simulate target will contains all the targets that match the given input targets. In order to test it, earthly +simulate can be run directly. Setup \u00b6 Both of the commands are written in Go, which located in catalyst-ci . Note Make sure that your GOPATH is set correctly. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to cli directory. The command can be found in cli/cmd/main.go Running the command \u00b6 In the cli directory, the following command can be run go run ./cmd/main.go <command> <path> <flag> Build a binary file \u00b6 Instead of running the command directly from main.go , building binary file can be done instead. go build -o bin/ci cmd/main.go Now the ci command can be run directly without Go command Simulate Command Usage \u00b6 SimulateCmd Struct \u00b6 The simulateCmd struct is designed to be used with a command-line interface (CLI) and has the following fields: Path : Specifies the directory path to be iterated to search for targets within the Earthfile. Target : A list of Earthly target patterns that the simulation will run. If the flag is not set, the default pipeline will be run check check-* build test test-* Default targets workflow \u00b6 If the target flag is not set, the default target patterns will be used. The defaults value include check check-* build test test-* . ci simulate . Customize targets workflow \u00b6 Specific stages can be simulated by adding target flag. The argument is a list of target pattern, for example, -t \"<target> <target2>\" ci simulate . -t \"test\" -t \"test-*\" Generate Command Usage \u00b6 GenerateCmd Struct \u00b6 The generateCmd struct is designed to be used with a command-line interface (CLI) and has the following fields: Path : Specifies the directory path to be iterated to search for targets within the Earthfile. Target : A list of Earthly target patterns that the simulation will run. If the flag is not set, the default pipeline will be run check check-* build test test-* Version : An Earthly version that need to be specify at the top of Earthfile. The default version is 0.8 Default value \u00b6 If the target flag is not set, the default target patterns will be used. The defaults value include check check-* build test test-* . ci generate . The ci will create an Earthfile in generate/ folder of the current directory. The version of the Earthly will be set to 0.8 The targets will be listed under the simulate target. eg. BUILD ../test/+target Customize targets workflow \u00b6 Customization can be done by specifying flags. Adding target flag -t \"<target>\" -t \"<target2>\" Adding version flag -v <version> ci generate . -t \"test-*\" -t \"check-*\" -v 0 .6 The ci will create an Earthfile in generate/ folder of the current directory. The command above will iterate through the current directory. Find the target that match test-* and check-* . Set the version of Earthly to 0.6. Warning Make sure that the directory of the Earthfile is not conflict with the existing Earthfile. The Earthfile should be ignore in the .gitignore","title":"Earthly Simulator"},{"location":"guides/simulate/#earthly-simulator","text":"","title":"Earthly Simulator"},{"location":"guides/simulate/#overview","text":"The following document provides an overview and usage guide for simulating Earthly locally. The simulation can be done in 2 ways Running a command line simulate : This will run Earthly command on every targets that match the given input targets. The targets will run sequentially, then preview the outcomes. Running a command line generate : This will create an Earthfile, which is set to be created at the generate/ folder inside the current directory. Inside the Earthfile, it contains a main target called simulate . This main simulate target will contains all the targets that match the given input targets. In order to test it, earthly +simulate can be run directly.","title":"Overview"},{"location":"guides/simulate/#setup","text":"Both of the commands are written in Go, which located in catalyst-ci . Note Make sure that your GOPATH is set correctly. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to cli directory. The command can be found in cli/cmd/main.go","title":"Setup"},{"location":"guides/simulate/#running-the-command","text":"In the cli directory, the following command can be run go run ./cmd/main.go <command> <path> <flag>","title":"Running the command"},{"location":"guides/simulate/#build-a-binary-file","text":"Instead of running the command directly from main.go , building binary file can be done instead. go build -o bin/ci cmd/main.go Now the ci command can be run directly without Go command","title":"Build a binary file"},{"location":"guides/simulate/#simulate-command-usage","text":"","title":"Simulate Command Usage"},{"location":"guides/simulate/#simulatecmd-struct","text":"The simulateCmd struct is designed to be used with a command-line interface (CLI) and has the following fields: Path : Specifies the directory path to be iterated to search for targets within the Earthfile. Target : A list of Earthly target patterns that the simulation will run. If the flag is not set, the default pipeline will be run check check-* build test test-*","title":"SimulateCmd Struct"},{"location":"guides/simulate/#default-targets-workflow","text":"If the target flag is not set, the default target patterns will be used. The defaults value include check check-* build test test-* . ci simulate .","title":"Default targets workflow"},{"location":"guides/simulate/#customize-targets-workflow","text":"Specific stages can be simulated by adding target flag. The argument is a list of target pattern, for example, -t \"<target> <target2>\" ci simulate . -t \"test\" -t \"test-*\"","title":"Customize targets workflow"},{"location":"guides/simulate/#generate-command-usage","text":"","title":"Generate Command Usage"},{"location":"guides/simulate/#generatecmd-struct","text":"The generateCmd struct is designed to be used with a command-line interface (CLI) and has the following fields: Path : Specifies the directory path to be iterated to search for targets within the Earthfile. Target : A list of Earthly target patterns that the simulation will run. If the flag is not set, the default pipeline will be run check check-* build test test-* Version : An Earthly version that need to be specify at the top of Earthfile. The default version is 0.8","title":"GenerateCmd Struct"},{"location":"guides/simulate/#default-value","text":"If the target flag is not set, the default target patterns will be used. The defaults value include check check-* build test test-* . ci generate . The ci will create an Earthfile in generate/ folder of the current directory. The version of the Earthly will be set to 0.8 The targets will be listed under the simulate target. eg. BUILD ../test/+target","title":"Default value"},{"location":"guides/simulate/#customize-targets-workflow_1","text":"Customization can be done by specifying flags. Adding target flag -t \"<target>\" -t \"<target2>\" Adding version flag -v <version> ci generate . -t \"test-*\" -t \"check-*\" -v 0 .6 The ci will create an Earthfile in generate/ folder of the current directory. The command above will iterate through the current directory. Find the target that match test-* and check-* . Set the version of Earthly to 0.6. Warning Make sure that the directory of the Earthfile is not conflict with the existing Earthfile. The Earthfile should be ignore in the .gitignore","title":"Customize targets workflow"},{"location":"guides/spellcheck/","text":"Spell Checking \u00b6 Introduction \u00b6 checking is integrated into the check pipeline. The reference to the pipeline can be found here . The goal of the check stage is to ensure the overall health of the project. This utilizes cspell under the hood for checking code and other text documents. It can be used to check for misspelled words, identify potential errors, and suggest corrections. Using the spell checking \u00b6 In an Earthfile in your repo, add the following: check-spelling: DO github.com/input-output-hk/catalyst-ci/earthly/cspell:<tag>+CHECK Executing earthly +check-spelling will automatically run the spell checking to all files in the repository. Configuration \u00b6 Each repo will need a cspell.json file in the root of the repo. This file configures cspell . The file provided in the Catalyst-CI repo should be taken as a starting point for new projects. Adding specific words to documents \u00b6 Words must ONLY be added to document words if they are correctly spelled. Project Words \u00b6 It will be necessary for each project to have a list of custom words. This list extends the list of valid words accepted by the spellchecker. These words are added to the file: <repo root>/.config/dictionaries/project.dic The path can also be configured in the cspell.json file. \"dictionaryDefinitions\" : [ { \"name\" : \"project-words\" , \"path\" : \".config/dictionaries/project.dic\" , \"description\" : \"Words used in this project.\" , \"addWords\" : true } ], This can be necessary for the following reasons: The built-in dictionaries do not contain all possible valid words. This is especially true when using names of Companies, Products or Technology. There are identifiers used in the code which are used which fail spell checks. Words must ONLY be added to project words if they are correctly spelled. Project words that are added MUST be included in any PR where they became necessary. PR Review MUST check that the added words are both reasonable and valid. Before a word is added to the project dictionary, it should be considered if it is a word likely to occur many times. Some spelling errors may only occur once, or a handful of times. Or, they may be an artifact of the code itself. In these cases it is MUCH better to disable the spelling error inline rather than add a word to the project dictionary. See In Document Settings for details. Specific file patterns words \u00b6 Custom words and dictionaries for specific file patterns can be configured inside cspell.json in the root of the repo. This can be made by adding overrides with custom specifications for specific file patterns. \"overrides\" : [ { \"language\" : \"es,es_ES\" , \"filename\" : \"**/*_es.arb\" , \"dictionaries\" : [ \"es-es\" ] }, { \"filename\" : \"**/*.pbxproj\" , \"allowCompoundWords\" : true , \"words\" : [ \"iphoneos\" , \"onone\" , \"xcassets\" , \"objc\" , \"xcconfig\" , \"lproj\" , \"libc\" , \"objc\" , \"dsym\" ] } ] Inline specific words \u00b6 It is possible to specify custom words within a file by adding comments. cspell: words <words> Here are some examples for inlining: Comments on Earthfiles # cspell: words libgcc freetype lcms openjpeg etag Comments on markdown files <!-- cspell: words healthcheck isready psql --> Generated Files \u00b6 Automatically generated files are likely to contain large amounts of spelling errors. For these files/paths, exclude them from the spell check by adding their filenames to \"ignorePaths\": [] in the cspell.json file. Editor Integration \u00b6 cspell is integrated into VSCode and may be integrated into other Editors. The editor integration should pick up the cspell.json configuration file and behave exactly the same as the Earthly Function.","title":"Spell Checking"},{"location":"guides/spellcheck/#spell-checking","text":"","title":"Spell Checking"},{"location":"guides/spellcheck/#introduction","text":"checking is integrated into the check pipeline. The reference to the pipeline can be found here . The goal of the check stage is to ensure the overall health of the project. This utilizes cspell under the hood for checking code and other text documents. It can be used to check for misspelled words, identify potential errors, and suggest corrections.","title":"Introduction"},{"location":"guides/spellcheck/#using-the-spell-checking","text":"In an Earthfile in your repo, add the following: check-spelling: DO github.com/input-output-hk/catalyst-ci/earthly/cspell:<tag>+CHECK Executing earthly +check-spelling will automatically run the spell checking to all files in the repository.","title":"Using the spell checking"},{"location":"guides/spellcheck/#configuration","text":"Each repo will need a cspell.json file in the root of the repo. This file configures cspell . The file provided in the Catalyst-CI repo should be taken as a starting point for new projects.","title":"Configuration"},{"location":"guides/spellcheck/#adding-specific-words-to-documents","text":"Words must ONLY be added to document words if they are correctly spelled.","title":"Adding specific words to documents"},{"location":"guides/spellcheck/#project-words","text":"It will be necessary for each project to have a list of custom words. This list extends the list of valid words accepted by the spellchecker. These words are added to the file: <repo root>/.config/dictionaries/project.dic The path can also be configured in the cspell.json file. \"dictionaryDefinitions\" : [ { \"name\" : \"project-words\" , \"path\" : \".config/dictionaries/project.dic\" , \"description\" : \"Words used in this project.\" , \"addWords\" : true } ], This can be necessary for the following reasons: The built-in dictionaries do not contain all possible valid words. This is especially true when using names of Companies, Products or Technology. There are identifiers used in the code which are used which fail spell checks. Words must ONLY be added to project words if they are correctly spelled. Project words that are added MUST be included in any PR where they became necessary. PR Review MUST check that the added words are both reasonable and valid. Before a word is added to the project dictionary, it should be considered if it is a word likely to occur many times. Some spelling errors may only occur once, or a handful of times. Or, they may be an artifact of the code itself. In these cases it is MUCH better to disable the spelling error inline rather than add a word to the project dictionary. See In Document Settings for details.","title":"Project Words"},{"location":"guides/spellcheck/#specific-file-patterns-words","text":"Custom words and dictionaries for specific file patterns can be configured inside cspell.json in the root of the repo. This can be made by adding overrides with custom specifications for specific file patterns. \"overrides\" : [ { \"language\" : \"es,es_ES\" , \"filename\" : \"**/*_es.arb\" , \"dictionaries\" : [ \"es-es\" ] }, { \"filename\" : \"**/*.pbxproj\" , \"allowCompoundWords\" : true , \"words\" : [ \"iphoneos\" , \"onone\" , \"xcassets\" , \"objc\" , \"xcconfig\" , \"lproj\" , \"libc\" , \"objc\" , \"dsym\" ] } ]","title":"Specific file patterns words"},{"location":"guides/spellcheck/#inline-specific-words","text":"It is possible to specify custom words within a file by adding comments. cspell: words <words> Here are some examples for inlining: Comments on Earthfiles # cspell: words libgcc freetype lcms openjpeg etag Comments on markdown files <!-- cspell: words healthcheck isready psql -->","title":"Inline specific words"},{"location":"guides/spellcheck/#generated-files","text":"Automatically generated files are likely to contain large amounts of spelling errors. For these files/paths, exclude them from the spell check by adding their filenames to \"ignorePaths\": [] in the cspell.json file.","title":"Generated Files"},{"location":"guides/spellcheck/#editor-integration","text":"cspell is integrated into VSCode and may be integrated into other Editors. The editor integration should pick up the cspell.json configuration file and behave exactly the same as the Earthly Function.","title":"Editor Integration"},{"location":"guides/languages/","text":"Languages \u00b6 Introduction \u00b6 These guide will get you started with using the Catalyst CI to build projects in the supported programming languages. By the end of each guide, you will have an Earthfile that utilizes the Catalyst CI to build, release, and publish your program.","title":"Languages"},{"location":"guides/languages/#languages","text":"","title":"Languages"},{"location":"guides/languages/#introduction","text":"These guide will get you started with using the Catalyst CI to build projects in the supported programming languages. By the end of each guide, you will have an Earthfile that utilizes the Catalyst CI to build, release, and publish your program.","title":"Introduction"},{"location":"guides/languages/bash/","text":"Bash Scripts \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build projects that include Bash scripts. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI that can check your Bash scripts. Bash is not considered a stand alone target, although bash scripts are used extensively across multiple targets. The Bash support consists solely of a single repo wide check target which validates: Are any of the bash shell scripts redundant. This prevent maintenance issues where common scripts are copy/pasted rather than being properly organized. Do the bash scripts pass shellcheck lints. This forces us to follow a consistent style guide, and also checks for problematic Bash syntax. To begin, clone the Catalyst CI repository: Adding Bash checks to your Repo that is already using Catalyst-CI \u00b6 Bash script checking is to be added to a repo that is already using Catalyst CI. All that needs to happen is the following be added to the Earthfile in the root of the repo. # Internal: shell-check - test all bash files against our shell check rules. shell-check: FROM alpine:3.20.3 DO github.com/input-output-hk/catalyst-ci/earthly/bash:vx.y.z+SHELLCHECK --src=. # check all repo wide checks are run from here check: FROM alpine:3.20.3 # Lint all bash files. BUILD +shell-check Note It is expected that there may be multiple repo level checks . This pattern shown above allows for this by separating the individual checks into their own targets. The check target then just executed BUILD once for each check. Common Scripts \u00b6 It is not a good practice to copy bash scripts with common functionality. Accordingly, the Utility target ./utilities/scripts+bash-scripts exists to provide a central location for common scripts. These are used locally to this repo and may be used by other repos using catalyst-ci. These scripts are intended to be used inside Earthly builds, and not locally. A common pattern to include these common scripts is the following: # Copy our target specific scripts COPY --dir scripts /scripts # Copy our common scripts so we can use them inside the container. DO ../../utilities/scripts+ADD_BASH_SCRIPTS Note Always source scripts using source \"/scripts/include/something.sh\" . This will ensure the scripts are properly located. bash has no concept of the directory a script is located and so relative source commands are unreliable. Note This is just an example, and you would adapt it to your specific requirements. Running checks \u00b6 From the root of the repo, you can check all bash scripts within the repo by running: earthly +check This will also run all other repo-wide checks that are in use. Build and test \u00b6 Bash scripts should not have a build target. They can form part of the Build of other targets. Releasing \u00b6 Bash scripts should not have a discreet release target. They can form part of the release of other targets. Publishing \u00b6 Bash scripts should not have a discreet publish target. They can form part of the publish of other targets. Conclusion \u00b6 You can see the final Earthfile here . This Earthfile will check the quality of the Bash files within the Catalyst-CI repo.","title":"Bash Scripts"},{"location":"guides/languages/bash/#bash-scripts","text":"","title":"Bash Scripts"},{"location":"guides/languages/bash/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build projects that include Bash scripts. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI that can check your Bash scripts. Bash is not considered a stand alone target, although bash scripts are used extensively across multiple targets. The Bash support consists solely of a single repo wide check target which validates: Are any of the bash shell scripts redundant. This prevent maintenance issues where common scripts are copy/pasted rather than being properly organized. Do the bash scripts pass shellcheck lints. This forces us to follow a consistent style guide, and also checks for problematic Bash syntax. To begin, clone the Catalyst CI repository:","title":"Introduction"},{"location":"guides/languages/bash/#adding-bash-checks-to-your-repo-that-is-already-using-catalyst-ci","text":"Bash script checking is to be added to a repo that is already using Catalyst CI. All that needs to happen is the following be added to the Earthfile in the root of the repo. # Internal: shell-check - test all bash files against our shell check rules. shell-check: FROM alpine:3.20.3 DO github.com/input-output-hk/catalyst-ci/earthly/bash:vx.y.z+SHELLCHECK --src=. # check all repo wide checks are run from here check: FROM alpine:3.20.3 # Lint all bash files. BUILD +shell-check Note It is expected that there may be multiple repo level checks . This pattern shown above allows for this by separating the individual checks into their own targets. The check target then just executed BUILD once for each check.","title":"Adding Bash checks to your Repo that is already using Catalyst-CI"},{"location":"guides/languages/bash/#common-scripts","text":"It is not a good practice to copy bash scripts with common functionality. Accordingly, the Utility target ./utilities/scripts+bash-scripts exists to provide a central location for common scripts. These are used locally to this repo and may be used by other repos using catalyst-ci. These scripts are intended to be used inside Earthly builds, and not locally. A common pattern to include these common scripts is the following: # Copy our target specific scripts COPY --dir scripts /scripts # Copy our common scripts so we can use them inside the container. DO ../../utilities/scripts+ADD_BASH_SCRIPTS Note Always source scripts using source \"/scripts/include/something.sh\" . This will ensure the scripts are properly located. bash has no concept of the directory a script is located and so relative source commands are unreliable. Note This is just an example, and you would adapt it to your specific requirements.","title":"Common Scripts"},{"location":"guides/languages/bash/#running-checks","text":"From the root of the repo, you can check all bash scripts within the repo by running: earthly +check This will also run all other repo-wide checks that are in use.","title":"Running checks"},{"location":"guides/languages/bash/#build-and-test","text":"Bash scripts should not have a build target. They can form part of the Build of other targets.","title":"Build and test"},{"location":"guides/languages/bash/#releasing","text":"Bash scripts should not have a discreet release target. They can form part of the release of other targets.","title":"Releasing"},{"location":"guides/languages/bash/#publishing","text":"Bash scripts should not have a discreet publish target. They can form part of the publish of other targets.","title":"Publishing"},{"location":"guides/languages/bash/#conclusion","text":"You can see the final Earthfile here . This Earthfile will check the quality of the Bash files within the Catalyst-CI repo.","title":"Conclusion"},{"location":"guides/languages/flutter/","text":"Flutter \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build Flutter-based projects. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our Flutter app. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/flutter to find a very basic Flutter program. This folder already has an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Building the Earthfile \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . Prepare base builder \u00b6 The first target builder is responsible for preparing configured Flutter environments, and install all needed tools and dependencies. VERSION 0.8 IMPORT github.com/input-output-hk/catalyst-ci/earthly/flutter:3.0.3 AS flutter-ci # Set up the CI environment for Flutter app. builder: DO flutter-ci+SETUP COPY --dir . . Running Bootstrap \u00b6 In case your project use Melos for monorepo management, you can configure the bootstrap target to call BOOTSTRAP function. bootstrap: FROM +builder DO flutter-ci+BOOTSTRAP Running analyze \u00b6 The next step we run analyze target, which will run flutter analyze or melos analyze command. analyze: FROM +builder DO flutter-ci+ANALYZE Running format \u00b6 After that we check if the code format is correct. format: FROM +builder DO flutter-ci+FORMAT Running Unit Tests \u00b6 In case you have unit tests in your project, you can run them with unit-tests target. unit-tests: FROM +builder DO flutter-ci+UNIT_TESTS Build Flutter app for Web \u00b6 An finally we build the Flutter app for Web (atm the only supported platform by Catalyst). build-web: FROM +builder ARG --required WORKDIR ARG --required TARGET DO flutter-ci+BUILD_WEB --WORKDIR=$WORKDIR --TARGET=$TARGET You can run it like this: earthly +build-web --WORKDIR = path/to/flutter/app/ --TARGET = lib/main.dart Running checks \u00b6 In addition to setting up a Flutter-based project, it is highly recommended to run a check to ensure the project is clean and well-defined. The example below illustrates how to implement a license_checker , allowing you to configure the licenses of dependencies to permit, reject, or approve using the license_checker package. This configuration can be managed through a YAML configuration file. check-license: FROM flutter-ci+license-checker-base COPY . . DO flutter-ci+LICENSE_CHECK --license_checker_file=license_checker.yaml To prevent the unintended approval of a package, a template license_checker.yaml is included within the earthly/flutter/Earthfile . This template will be compared with the provided YAML file specified by the --license_checker_file argument. If the files do not match, the program will return an error. Release and publish \u00b6 To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image. Enhancing Flutter \u00b6 Integrating Flutter with Rust using flutter_rust_bridge \u00b6 The flutter_rust_bridge allows you to integrate Rust with Flutter app, while maintaining the rest of the app in Dart. This can be useful for situations where you need to run complex algorithms, handle data processing, or interact with low-level system APIs, but still want to leverage the Flutter ecosystem for UI and app management. Start by creating a new builder where all the necessary setup is done under the flutter_rust_bridge+builder , then copy the Flutter project that already have flutter_rust_bridge setup. Refer to https://cjycode.com/flutter_rust_bridge/ for how to setup the project. builder-frb: FROM flutter_rust_bridge+builder COPY . . Then generate a binding between Rust and Flutter # Generated necessary files for running Flutter web locally and save it locally. code-generator-web: FROM +builder-frb DO flutter_rust_bridge+CODE_GENERATOR_WEB SAVE ARTIFACT ./assets/js AS LOCAL ./assets/js SAVE ARTIFACT ./rust/src/frb_generated.rs AS LOCAL ./rust/src/frb_generated.rs SAVE ARTIFACT ./lib/src AS LOCAL ./lib/src Conclusion \u00b6 You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Rust project, as you can see it is pretty simple.","title":"Flutter"},{"location":"guides/languages/flutter/#flutter","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build Flutter-based projects. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our Flutter app. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/flutter to find a very basic Flutter program. This folder already has an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file.","title":"Flutter"},{"location":"guides/languages/flutter/#building-the-earthfile","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example .","title":"Building the Earthfile"},{"location":"guides/languages/flutter/#prepare-base-builder","text":"The first target builder is responsible for preparing configured Flutter environments, and install all needed tools and dependencies. VERSION 0.8 IMPORT github.com/input-output-hk/catalyst-ci/earthly/flutter:3.0.3 AS flutter-ci # Set up the CI environment for Flutter app. builder: DO flutter-ci+SETUP COPY --dir . .","title":"Prepare base builder"},{"location":"guides/languages/flutter/#running-bootstrap","text":"In case your project use Melos for monorepo management, you can configure the bootstrap target to call BOOTSTRAP function. bootstrap: FROM +builder DO flutter-ci+BOOTSTRAP","title":"Running Bootstrap"},{"location":"guides/languages/flutter/#running-analyze","text":"The next step we run analyze target, which will run flutter analyze or melos analyze command. analyze: FROM +builder DO flutter-ci+ANALYZE","title":"Running analyze"},{"location":"guides/languages/flutter/#running-format","text":"After that we check if the code format is correct. format: FROM +builder DO flutter-ci+FORMAT","title":"Running format"},{"location":"guides/languages/flutter/#running-unit-tests","text":"In case you have unit tests in your project, you can run them with unit-tests target. unit-tests: FROM +builder DO flutter-ci+UNIT_TESTS","title":"Running Unit Tests"},{"location":"guides/languages/flutter/#build-flutter-app-for-web","text":"An finally we build the Flutter app for Web (atm the only supported platform by Catalyst). build-web: FROM +builder ARG --required WORKDIR ARG --required TARGET DO flutter-ci+BUILD_WEB --WORKDIR=$WORKDIR --TARGET=$TARGET You can run it like this: earthly +build-web --WORKDIR = path/to/flutter/app/ --TARGET = lib/main.dart","title":"Build Flutter app for Web"},{"location":"guides/languages/flutter/#running-checks","text":"In addition to setting up a Flutter-based project, it is highly recommended to run a check to ensure the project is clean and well-defined. The example below illustrates how to implement a license_checker , allowing you to configure the licenses of dependencies to permit, reject, or approve using the license_checker package. This configuration can be managed through a YAML configuration file. check-license: FROM flutter-ci+license-checker-base COPY . . DO flutter-ci+LICENSE_CHECK --license_checker_file=license_checker.yaml To prevent the unintended approval of a package, a template license_checker.yaml is included within the earthly/flutter/Earthfile . This template will be compared with the provided YAML file specified by the --license_checker_file argument. If the files do not match, the program will return an error.","title":"Running checks"},{"location":"guides/languages/flutter/#release-and-publish","text":"To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image.","title":"Release and publish"},{"location":"guides/languages/flutter/#enhancing-flutter","text":"","title":"Enhancing Flutter"},{"location":"guides/languages/flutter/#integrating-flutter-with-rust-using-flutter_rust_bridge","text":"The flutter_rust_bridge allows you to integrate Rust with Flutter app, while maintaining the rest of the app in Dart. This can be useful for situations where you need to run complex algorithms, handle data processing, or interact with low-level system APIs, but still want to leverage the Flutter ecosystem for UI and app management. Start by creating a new builder where all the necessary setup is done under the flutter_rust_bridge+builder , then copy the Flutter project that already have flutter_rust_bridge setup. Refer to https://cjycode.com/flutter_rust_bridge/ for how to setup the project. builder-frb: FROM flutter_rust_bridge+builder COPY . . Then generate a binding between Rust and Flutter # Generated necessary files for running Flutter web locally and save it locally. code-generator-web: FROM +builder-frb DO flutter_rust_bridge+CODE_GENERATOR_WEB SAVE ARTIFACT ./assets/js AS LOCAL ./assets/js SAVE ARTIFACT ./rust/src/frb_generated.rs AS LOCAL ./rust/src/frb_generated.rs SAVE ARTIFACT ./lib/src AS LOCAL ./lib/src","title":"Integrating Flutter with Rust using flutter_rust_bridge"},{"location":"guides/languages/flutter/#conclusion","text":"You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Rust project, as you can see it is pretty simple.","title":"Conclusion"},{"location":"guides/languages/go/","text":"Go \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build Go-based projects. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our Go program. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/go to find a very basic Go program which prints \"Hello, world!\" to the terminal screen using cowsay . This folder already has an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Building the Earthfile \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . Installing dependencies \u00b6 VERSION 0.8 deps: # This target is used to install external Go dependencies. FROM golang:1.22.4-alpine3.20 WORKDIR /work # Any build dependencies should also be captured in this target. RUN apk add --no-cache gcc musl-dev # This Function automatically copies the go.mod and go.sum files and runs # `go mod download` to install the dependencies. DO ../../earthly/go+DEPS The first target we are going to create will be responsible for downloading the external dependencies that our Go program uses. By design, the only files we need for this are the go.mod and go.sum files. By only copying these files, we ensure that this target is cached for most development and only rebuilds when we add new dependencies. We are going to be inheriting from an alpine image because we are pushing for a fully static build. When using example as a starting place, feel free to change the base image. This image is only used during the build steps, so it's not important we minimize its size. Keep in mind, though, excessively large targets can impact the speed of the caching step (due to lots of I/O). This target is also going to build responsible for installing external build dependencies. These are dependencies that are not specific to a language and usually get installed system-wide. In our case, since we're building a static binary, we need gcc and musl . Finally, the actual logic we will be using is encapsulate in a Function. This is a very common pattern, as an Earthfile can get repetitive across a repository. In our case, we use the go+DEPS Function that will automatically copy our go.mod and go.sum files and then execute go mod download . The Function will also establish a cache for the Go tooling. This means that, even if our source code changes, we'll see a substantial speed boost when compiling because the cache is preserved across Earthly runs. Running checks \u00b6 src: # This target copies the source code into the current build context FROM +deps COPY --dir cmd . check: # This target checks the overall health of the source code. FROM +src # This Function validates the code is formatted according to Go standards. DO ../../earthly/go+FMT --src=\"go.mod go.sum cmd\" # This Function runs golangci-lint to check for common errors. DO ../../earthly/go+LINT --src=\"go.mod go.sum cmd\" With our dependencies installed, we're now ready to start operating with the source code. To do this, we establish a dedicated src target that is solely responsible for copying the local source code into the context. This is a common pattern as it ensures we perform this only once and it makes future changes easier (as we only copy in a single place). Any future targets which need access to the source code will inherit from this target. Now that the source code is available, we can begin performing static checks. These checks are intended to verify the code is healthy and conforms to a certain standard. As we did in the previous section, here we rely on Functions again to perform these checks. These two Functions will validate the code formatting is correct and also perform a series of lints to validate code quality. Note that these checks are fast (compared to later steps) and perform quick feedback on code quality. Since this is the first target run in CI, we want to fail the CI as quickly as possible if we can easily find code quality issues. In future targets, we will run tests which can tend to take significantly more time to run than static analysis tools. Build and test \u00b6 build: # This target builds the application. FROM +src # The below just creates a fully static binary with no CGO dependencies. ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go # We save the artifact here so that future targets can use it. SAVE ARTIFACT bin/hello hello test: # This target runs unit tests. FROM +build RUN go test ./... With the basic checks out of the way, it's finally time to compile our Go program. Since we need the source code to do this, we'll inherit from the src target. The actual build process is fairly straight-forward, and the additional flags are simply there to ensure a fully static output is created. It's important we use SAVE ARTIFACT at the end of the build to make the compiled binary available to other targets. Remember that targets can reference other targets, even ones in another Earthfile . So by SAVE ARTIFACT here, we're making this binary available to any other Earthfile which may need to use it. Finally, after building the binary, we will run our tests. In the case of this example, there are no actual tests to run, so the target will complete very quickly. However, we would expect a more complex project to contain many tests. Notice that we inherit from the build target: this is because in most cases there will be a layer of compilation before actually running tests. By choosing to make our test target inherit from build , we ensure that we can maximize reusing the cached binary that was created in the previous target. This is a good pattern to observe and follow where practical, as it can dramatically improve CI times. Releasing \u00b6 release: # This target is called by the CI when performing a release. It should use # `SAVE ARTIFACT` to save the release artifact which is then picked up by # the CI. FROM +build SAVE ARTIFACT bin/hello hello With our source code checked, binary built, and tests passed, we're now ready to release. The release target will instruct the CI to take whatever artifact we save in this target and automatically include it as part of a GitHub Release when a new release is created (i.e., a new git tag is created). In some cases, it makes sense to skip this step, like for projects which produce artifacts that are only usable in a container. For our case, since our example program prints something to the terminal (and it's statically built), it makes sense to release the binary by itself. The actual logic used in this target is minimal. Since we already built the binary in the build target, we can simply inherit from it and do another SAVE ARTIFACT . This may seem redundant, but the CI sees the build and release targets as two separate steps. Note that we could have also sourced from a new image and used COPY +build/hello . with SAVE ARTIFACT . However, if we did this, we would be needlessly adding time to the CI by creating a new image with a single layer. It's much faster to simply inherit from the target and then use SAVE ARTIFACT . Publishing \u00b6 publish-example: # This target is called by CI when publishing images. It should use the # `SAVE IMAGE` command to save the image which is then picked up by the CI. # Note that we start from a \"fresh\" base image. FROM alpine:3.20.3 WORKDIR /app ARG tag=latest # Prefer to use `latest` by default, the CI will override this. COPY +build/hello . # Use the cached artifact from the build target. ENTRYPOINT [\"/app/hello\"] SAVE IMAGE hello:${tag} Now we want to publish a container image that runs our binary. While the actual use-case for a container is a bit vague, we create one here for demonstration purposes. It also serves as a natural way to use our program without having to rely on a package manager (i.e. docker run ... ). In this target, it's important we start with a \"fresh\" image by using FROM . Unlike the previous targets, here the size of the image matters as the resulting image will be published to a registry. In our case, we just take a plain alpine image as we don't need any of the Go tooling we used previously (since the binary has already been built for us). We add a tag argument out of convention. During local testing, it's sometimes helpful to call earthly +publish and specify a different tag to test different versions of the container image. However, the CI will not pass this argument when it executes the target, so it's important to always set a default value. Instead, the CI will re-tag the image with the appropriate tags after building it. Since the binary has already been built, we can simply COPY it from the build target. As in the release target, this ensures we use the cache as much as possible. It also meets the best practice of having a single place where artifacts are built and copied from. Finally, we set the appropriate entrypoint and use SAVE IMAGE to instruct Earthly to save the final container image. When the CI executes this target, it will automatically detect the saved image and publish it to the configured container registries. Conclusion \u00b6 You can see the final Earthfile here . This Earthfile will check the health of our source code, build and test our binary, and then finally release it to GitHub and publish it to one or more container registries. At this point, please feel free to experiment more and run each target individually. Once you're ready, you can copy this example and modify it for your specific context.","title":"Go"},{"location":"guides/languages/go/#go","text":"","title":"Go"},{"location":"guides/languages/go/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build Go-based projects. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our Go program. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/go to find a very basic Go program which prints \"Hello, world!\" to the terminal screen using cowsay . This folder already has an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file.","title":"Introduction"},{"location":"guides/languages/go/#building-the-earthfile","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example .","title":"Building the Earthfile"},{"location":"guides/languages/go/#installing-dependencies","text":"VERSION 0.8 deps: # This target is used to install external Go dependencies. FROM golang:1.22.4-alpine3.20 WORKDIR /work # Any build dependencies should also be captured in this target. RUN apk add --no-cache gcc musl-dev # This Function automatically copies the go.mod and go.sum files and runs # `go mod download` to install the dependencies. DO ../../earthly/go+DEPS The first target we are going to create will be responsible for downloading the external dependencies that our Go program uses. By design, the only files we need for this are the go.mod and go.sum files. By only copying these files, we ensure that this target is cached for most development and only rebuilds when we add new dependencies. We are going to be inheriting from an alpine image because we are pushing for a fully static build. When using example as a starting place, feel free to change the base image. This image is only used during the build steps, so it's not important we minimize its size. Keep in mind, though, excessively large targets can impact the speed of the caching step (due to lots of I/O). This target is also going to build responsible for installing external build dependencies. These are dependencies that are not specific to a language and usually get installed system-wide. In our case, since we're building a static binary, we need gcc and musl . Finally, the actual logic we will be using is encapsulate in a Function. This is a very common pattern, as an Earthfile can get repetitive across a repository. In our case, we use the go+DEPS Function that will automatically copy our go.mod and go.sum files and then execute go mod download . The Function will also establish a cache for the Go tooling. This means that, even if our source code changes, we'll see a substantial speed boost when compiling because the cache is preserved across Earthly runs.","title":"Installing dependencies"},{"location":"guides/languages/go/#running-checks","text":"src: # This target copies the source code into the current build context FROM +deps COPY --dir cmd . check: # This target checks the overall health of the source code. FROM +src # This Function validates the code is formatted according to Go standards. DO ../../earthly/go+FMT --src=\"go.mod go.sum cmd\" # This Function runs golangci-lint to check for common errors. DO ../../earthly/go+LINT --src=\"go.mod go.sum cmd\" With our dependencies installed, we're now ready to start operating with the source code. To do this, we establish a dedicated src target that is solely responsible for copying the local source code into the context. This is a common pattern as it ensures we perform this only once and it makes future changes easier (as we only copy in a single place). Any future targets which need access to the source code will inherit from this target. Now that the source code is available, we can begin performing static checks. These checks are intended to verify the code is healthy and conforms to a certain standard. As we did in the previous section, here we rely on Functions again to perform these checks. These two Functions will validate the code formatting is correct and also perform a series of lints to validate code quality. Note that these checks are fast (compared to later steps) and perform quick feedback on code quality. Since this is the first target run in CI, we want to fail the CI as quickly as possible if we can easily find code quality issues. In future targets, we will run tests which can tend to take significantly more time to run than static analysis tools.","title":"Running checks"},{"location":"guides/languages/go/#build-and-test","text":"build: # This target builds the application. FROM +src # The below just creates a fully static binary with no CGO dependencies. ENV CGO_ENABLED=0 RUN go mod tidy RUN go build -ldflags=\"-extldflags=-static\" -o bin/hello cmd/main.go # We save the artifact here so that future targets can use it. SAVE ARTIFACT bin/hello hello test: # This target runs unit tests. FROM +build RUN go test ./... With the basic checks out of the way, it's finally time to compile our Go program. Since we need the source code to do this, we'll inherit from the src target. The actual build process is fairly straight-forward, and the additional flags are simply there to ensure a fully static output is created. It's important we use SAVE ARTIFACT at the end of the build to make the compiled binary available to other targets. Remember that targets can reference other targets, even ones in another Earthfile . So by SAVE ARTIFACT here, we're making this binary available to any other Earthfile which may need to use it. Finally, after building the binary, we will run our tests. In the case of this example, there are no actual tests to run, so the target will complete very quickly. However, we would expect a more complex project to contain many tests. Notice that we inherit from the build target: this is because in most cases there will be a layer of compilation before actually running tests. By choosing to make our test target inherit from build , we ensure that we can maximize reusing the cached binary that was created in the previous target. This is a good pattern to observe and follow where practical, as it can dramatically improve CI times.","title":"Build and test"},{"location":"guides/languages/go/#releasing","text":"release: # This target is called by the CI when performing a release. It should use # `SAVE ARTIFACT` to save the release artifact which is then picked up by # the CI. FROM +build SAVE ARTIFACT bin/hello hello With our source code checked, binary built, and tests passed, we're now ready to release. The release target will instruct the CI to take whatever artifact we save in this target and automatically include it as part of a GitHub Release when a new release is created (i.e., a new git tag is created). In some cases, it makes sense to skip this step, like for projects which produce artifacts that are only usable in a container. For our case, since our example program prints something to the terminal (and it's statically built), it makes sense to release the binary by itself. The actual logic used in this target is minimal. Since we already built the binary in the build target, we can simply inherit from it and do another SAVE ARTIFACT . This may seem redundant, but the CI sees the build and release targets as two separate steps. Note that we could have also sourced from a new image and used COPY +build/hello . with SAVE ARTIFACT . However, if we did this, we would be needlessly adding time to the CI by creating a new image with a single layer. It's much faster to simply inherit from the target and then use SAVE ARTIFACT .","title":"Releasing"},{"location":"guides/languages/go/#publishing","text":"publish-example: # This target is called by CI when publishing images. It should use the # `SAVE IMAGE` command to save the image which is then picked up by the CI. # Note that we start from a \"fresh\" base image. FROM alpine:3.20.3 WORKDIR /app ARG tag=latest # Prefer to use `latest` by default, the CI will override this. COPY +build/hello . # Use the cached artifact from the build target. ENTRYPOINT [\"/app/hello\"] SAVE IMAGE hello:${tag} Now we want to publish a container image that runs our binary. While the actual use-case for a container is a bit vague, we create one here for demonstration purposes. It also serves as a natural way to use our program without having to rely on a package manager (i.e. docker run ... ). In this target, it's important we start with a \"fresh\" image by using FROM . Unlike the previous targets, here the size of the image matters as the resulting image will be published to a registry. In our case, we just take a plain alpine image as we don't need any of the Go tooling we used previously (since the binary has already been built for us). We add a tag argument out of convention. During local testing, it's sometimes helpful to call earthly +publish and specify a different tag to test different versions of the container image. However, the CI will not pass this argument when it executes the target, so it's important to always set a default value. Instead, the CI will re-tag the image with the appropriate tags after building it. Since the binary has already been built, we can simply COPY it from the build target. As in the release target, this ensures we use the cache as much as possible. It also meets the best practice of having a single place where artifacts are built and copied from. Finally, we set the appropriate entrypoint and use SAVE IMAGE to instruct Earthly to save the final container image. When the CI executes this target, it will automatically detect the saved image and publish it to the configured container registries.","title":"Publishing"},{"location":"guides/languages/go/#conclusion","text":"You can see the final Earthfile here . This Earthfile will check the health of our source code, build and test our binary, and then finally release it to GitHub and publish it to one or more container registries. At this point, please feel free to experiment more and run each target individually. Once you're ready, you can copy this example and modify it for your specific context.","title":"Conclusion"},{"location":"guides/languages/postgresql/","text":"PostgreSQL \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build PostgreSQL database. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our PostgreSQL database. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/postgresql to find a basic PostgreSQL database configuration with some initial data. This folder already contains an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Building the Earthfile \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . Prepare base builder \u00b6 VERSION 0.8 builder: FROM ./../../earthly/postgresql+postgres-base WORKDIR /build COPY --dir ./migrations ./data ./refinery.toml . DO ./../../earthly/postgresql+BUILDER The first target we are going to consider will be responsible to prepare a PostgreSQL environment (Earthly +postgres-base target), migrations, migrations configuration and seed data ( COPY --dir ./migrations ./data ./refinery.toml . ), doing some final build step (Earthly +BUILDER Function). In the next steps we are going to inheriting from this +builder target which contains all necessary data, dependencies, environment to properly run PostgreSQL database. Running checks \u00b6 check: FROM +builder DO ./../../earthly/postgresql+CHECK build-sqlfluff: BUILD ./../../earthly/postgresql+sqlfluff-image format: LOCALLY RUN earthly +build-sqlfluff DO ./../../earthly/postgresql+FORMAT --src=$(echo ${PWD}) With prepared environment and all data, we're now ready to start operating with the source code - *.sql files. At this step we can begin performing static checks against *.sql files. These checks are intended to verify the code is healthy and well formatted to a certain standard and done with the help of the sqlfluff tool which is already configured during the +postgres-base target. To apply and fix some formatting issues you can run +format target which will picks up directory where your Earthly file lies in as a source dir for formatting and run +FORMAT Function. Under the hood +FORMAT Function runs sqlfluff-image docker image, which contains the same configuration and setup which is applied during the +check . Note Specific configuration of sqlfluff which is applied during the check and formatting you can find at the example . Build \u00b6 build: FROM +builder ARG tag=\"latest\" ARG registry DO ./../../earthly/postgresql+BUILD --image_name=example-db --tag=$tag --registry=$registry With the *.sql files validation out of the way, we can finally build our PostgreSQL docker image. Since we need migration and seed data files, we'll inherit from the builder target. The actual image build process is pretty straight-forward and fully defined under the +BUILD Function. The only thing it is needed to specify is a few arguments: tag - the tag of the image, default value latest . registry - the registry of the image. image_name - the name of the image (required). Run \u00b6 To run already builded docker image it is possible with the following docker-compose.yml version : \"3\" services : postgres : image : postgres:16 restart : unless-stopped environment : POSTGRES_USER : postgres POSTGRES_PASSWORD : postgres POSTGRES_DB : postgres healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}\" ] interval : 2s timeout : 5s retries : 10 ports : - 5433:5432 example : image : example-db:latest environment : # Required environment variables for migrations - DB_HOST=${DB_HOST:-localhost} - DB_PORT=5432 - DB_NAME=ExampleDb - DB_DESCRIPTION=Example DB - DB_SUPERUSER=postgres - DB_SUPERUSER_PASSWORD=postgres - DB_USER=example-dev - DB_USER_PASSWORD=example-pass - INIT_AND_DROP_DB=${INIT_AND_DROP_DB:-true} - WITH_MIGRATIONS=${WITH_MIGRATIONS:-true} - WITH_SEED_DATA=${WITH_SEED_DATA:-true} ports : - 5432:5432 There are 4 possible options how to run: If DB_HOST env var established to localhost , PostgreSQL server runs as a part of the example service, otherwise will relies on remote PostgreSQL server connection (as an example already defined postgres service). INIT_AND_DROP_DB env var defines to run initial initialization of the db with the clean state or not (optional, default false ). WITH_MIGRATIONS env var defines to run migrations defined inside ./migrations dir or not (optional, default false ). WITH_SEED_DATA env var defines to setup db with some seed data defined inside ./data dir or not (optional, default false ). Test \u00b6 Finally we can test already configured and prepared PostgreSQL image and trial it against 4 different cases # Container runs PostgreSQL server, drops and initialise db, applies migrations, applies seed data. test-1: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA true COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n---------+-----\\n Alice | 20\\n Bob | 30\\n Charlie | 40\\n(3 rows)\");\\ assert_eq \"$expected\" \"$res\" END # Container runs PostgreSQL server, drops and initialise db, doesn't apply migrations, doesn't apply seed data. test-2: FROM ./../../earthly/postgresql+postgres-base ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS false ENV WITH_SEED_DATA false COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ ! psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\" END # Container runs PostgreSQL server, drops and initialise db, applies migrations, doesn't apply seed data. test-3: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA false COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n------+-----\\n(0 rows)\");\\ assert_eq \"$expected\" \"$res\" END # PostgreSQL server runs as a separate service, drops and initialise db, applies migrations, applies seed data. test-4: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV DB_HOST postgres ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA true COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --pull postgres:16 \\ --load example-db:latest=+build \\ --service example \\ --service postgres \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://postgres:postgres@0.0.0.0:5433/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n---------+-----\\n Alice | 20\\n Bob | 30\\n Charlie | 40\\n(3 rows)\");\\ assert_eq \"$expected\" \"$res\" END # Invoke all tests test: BUILD +test-1 BUILD +test-2 BUILD +test-3 BUILD +test-4 It is a pretty standard way how to test builded image with the specified docker-compose.yml file, which was mentioned below. Notice that it is used basic postgres-base environment instead of builder as before, because we dont need to have migrations and seed data as a part of the test environment itself. With the help of ENV we are specifying DB_HOST , INIT_AND_DROP_DB , WITH_MIGRATIONS , WITH_SEED_DATA environment variables for various test cases. Release and publish \u00b6 To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image. Conclusion \u00b6 You can see the final Earthfile here and any other files in the same directory. This Earthfile will check the health of our source code, build and test PostgreSQL image, and then finally release it to GitHub and publish it to one or more container registries. At this point, please feel free to experiment more and run each target individually. Once you're ready, you can copy this example and modify it for your specific context.","title":"PostgreSQL"},{"location":"guides/languages/postgresql/#postgresql","text":"","title":"PostgreSQL"},{"location":"guides/languages/postgresql/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to build PostgreSQL database. By the end of the guide, we'll have an Earthfile that utilizes the Catalyst CI to build, release, and publish our PostgreSQL database. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/postgresql to find a basic PostgreSQL database configuration with some initial data. This folder already contains an Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file.","title":"Introduction"},{"location":"guides/languages/postgresql/#building-the-earthfile","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example .","title":"Building the Earthfile"},{"location":"guides/languages/postgresql/#prepare-base-builder","text":"VERSION 0.8 builder: FROM ./../../earthly/postgresql+postgres-base WORKDIR /build COPY --dir ./migrations ./data ./refinery.toml . DO ./../../earthly/postgresql+BUILDER The first target we are going to consider will be responsible to prepare a PostgreSQL environment (Earthly +postgres-base target), migrations, migrations configuration and seed data ( COPY --dir ./migrations ./data ./refinery.toml . ), doing some final build step (Earthly +BUILDER Function). In the next steps we are going to inheriting from this +builder target which contains all necessary data, dependencies, environment to properly run PostgreSQL database.","title":"Prepare base builder"},{"location":"guides/languages/postgresql/#running-checks","text":"check: FROM +builder DO ./../../earthly/postgresql+CHECK build-sqlfluff: BUILD ./../../earthly/postgresql+sqlfluff-image format: LOCALLY RUN earthly +build-sqlfluff DO ./../../earthly/postgresql+FORMAT --src=$(echo ${PWD}) With prepared environment and all data, we're now ready to start operating with the source code - *.sql files. At this step we can begin performing static checks against *.sql files. These checks are intended to verify the code is healthy and well formatted to a certain standard and done with the help of the sqlfluff tool which is already configured during the +postgres-base target. To apply and fix some formatting issues you can run +format target which will picks up directory where your Earthly file lies in as a source dir for formatting and run +FORMAT Function. Under the hood +FORMAT Function runs sqlfluff-image docker image, which contains the same configuration and setup which is applied during the +check . Note Specific configuration of sqlfluff which is applied during the check and formatting you can find at the example .","title":"Running checks"},{"location":"guides/languages/postgresql/#build","text":"build: FROM +builder ARG tag=\"latest\" ARG registry DO ./../../earthly/postgresql+BUILD --image_name=example-db --tag=$tag --registry=$registry With the *.sql files validation out of the way, we can finally build our PostgreSQL docker image. Since we need migration and seed data files, we'll inherit from the builder target. The actual image build process is pretty straight-forward and fully defined under the +BUILD Function. The only thing it is needed to specify is a few arguments: tag - the tag of the image, default value latest . registry - the registry of the image. image_name - the name of the image (required).","title":"Build"},{"location":"guides/languages/postgresql/#run","text":"To run already builded docker image it is possible with the following docker-compose.yml version : \"3\" services : postgres : image : postgres:16 restart : unless-stopped environment : POSTGRES_USER : postgres POSTGRES_PASSWORD : postgres POSTGRES_DB : postgres healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}\" ] interval : 2s timeout : 5s retries : 10 ports : - 5433:5432 example : image : example-db:latest environment : # Required environment variables for migrations - DB_HOST=${DB_HOST:-localhost} - DB_PORT=5432 - DB_NAME=ExampleDb - DB_DESCRIPTION=Example DB - DB_SUPERUSER=postgres - DB_SUPERUSER_PASSWORD=postgres - DB_USER=example-dev - DB_USER_PASSWORD=example-pass - INIT_AND_DROP_DB=${INIT_AND_DROP_DB:-true} - WITH_MIGRATIONS=${WITH_MIGRATIONS:-true} - WITH_SEED_DATA=${WITH_SEED_DATA:-true} ports : - 5432:5432 There are 4 possible options how to run: If DB_HOST env var established to localhost , PostgreSQL server runs as a part of the example service, otherwise will relies on remote PostgreSQL server connection (as an example already defined postgres service). INIT_AND_DROP_DB env var defines to run initial initialization of the db with the clean state or not (optional, default false ). WITH_MIGRATIONS env var defines to run migrations defined inside ./migrations dir or not (optional, default false ). WITH_SEED_DATA env var defines to setup db with some seed data defined inside ./data dir or not (optional, default false ).","title":"Run"},{"location":"guides/languages/postgresql/#test","text":"Finally we can test already configured and prepared PostgreSQL image and trial it against 4 different cases # Container runs PostgreSQL server, drops and initialise db, applies migrations, applies seed data. test-1: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA true COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n---------+-----\\n Alice | 20\\n Bob | 30\\n Charlie | 40\\n(3 rows)\");\\ assert_eq \"$expected\" \"$res\" END # Container runs PostgreSQL server, drops and initialise db, doesn't apply migrations, doesn't apply seed data. test-2: FROM ./../../earthly/postgresql+postgres-base ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS false ENV WITH_SEED_DATA false COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ ! psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\" END # Container runs PostgreSQL server, drops and initialise db, applies migrations, doesn't apply seed data. test-3: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA false COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --load example-db:latest=+build \\ --service example \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://example-dev:example-pass@0.0.0.0:5432/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n------+-----\\n(0 rows)\");\\ assert_eq \"$expected\" \"$res\" END # PostgreSQL server runs as a separate service, drops and initialise db, applies migrations, applies seed data. test-4: FROM ./../../earthly/postgresql+postgres-base COPY ./../../earthly/utils+shell-assert/assert.sh . ENV DB_HOST postgres ENV INIT_AND_DROP_DB true ENV WITH_MIGRATIONS true ENV WITH_SEED_DATA true COPY ./docker-compose.yml . WITH DOCKER \\ --compose docker-compose.yml \\ --pull postgres:16 \\ --load example-db:latest=+build \\ --service example \\ --service postgres \\ --allow-privileged RUN sleep 5;\\ res=$(psql postgresql://postgres:postgres@0.0.0.0:5433/ExampleDb -c \"SELECT * FROM users\");\\ source assert.sh;\\ expected=$(printf \" name | age \\n---------+-----\\n Alice | 20\\n Bob | 30\\n Charlie | 40\\n(3 rows)\");\\ assert_eq \"$expected\" \"$res\" END # Invoke all tests test: BUILD +test-1 BUILD +test-2 BUILD +test-3 BUILD +test-4 It is a pretty standard way how to test builded image with the specified docker-compose.yml file, which was mentioned below. Notice that it is used basic postgres-base environment instead of builder as before, because we dont need to have migrations and seed data as a part of the test environment itself. With the help of ENV we are specifying DB_HOST , INIT_AND_DROP_DB , WITH_MIGRATIONS , WITH_SEED_DATA environment variables for various test cases.","title":"Test"},{"location":"guides/languages/postgresql/#release-and-publish","text":"To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image.","title":"Release and publish"},{"location":"guides/languages/postgresql/#conclusion","text":"You can see the final Earthfile here and any other files in the same directory. This Earthfile will check the health of our source code, build and test PostgreSQL image, and then finally release it to GitHub and publish it to one or more container registries. At this point, please feel free to experiment more and run each target individually. Once you're ready, you can copy this example and modify it for your specific context.","title":"Conclusion"},{"location":"guides/languages/python/","text":"Python \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to work with Python based projects. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/python to find a basic Python project, with the Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Building the Earthfile \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . Prepare base builder \u00b6 VERSION 0.8 builder: FROM ./../../earthly/python+python-base COPY --dir ./src . DO ./../../earthly/python+BUILDER The first target builder is responsible to prepare an already configured Python environment, instal all needed tools and dependencies. Every Python project must be a poetry based project, so it is mandatory to have pyproject.toml and poetry.lock files in the root dir of the project. The fist step of the builder target is prepare a Python environment with poetry via +python-base target. Next step is to copy source code of the project and finally finalize the build with some poetry project setup which is done with +BUILDER Function. Running checks \u00b6 TODO Test \u00b6 test: FROM +builder RUN poetry run pytest As the final step, after proper setup of the Python project we can run tests, to do so inherit from the already discussed +builder target and just run poetry run pytest or with any other way which are suitable for your project setup. And that's it! Release and publish \u00b6 To prepare a release artifact and publish it to some external container registries please follow this guide . The only things you need is too define release and publish Earthly targets with the proper configuration of the artifacts for your project. Conclusion \u00b6 You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Python project, as you can see it is pretty simple.","title":"Python"},{"location":"guides/languages/python/#python","text":"","title":"Python"},{"location":"guides/languages/python/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to work with Python based projects. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/python to find a basic Python project, with the Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file.","title":"Introduction"},{"location":"guides/languages/python/#building-the-earthfile","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example .","title":"Building the Earthfile"},{"location":"guides/languages/python/#prepare-base-builder","text":"VERSION 0.8 builder: FROM ./../../earthly/python+python-base COPY --dir ./src . DO ./../../earthly/python+BUILDER The first target builder is responsible to prepare an already configured Python environment, instal all needed tools and dependencies. Every Python project must be a poetry based project, so it is mandatory to have pyproject.toml and poetry.lock files in the root dir of the project. The fist step of the builder target is prepare a Python environment with poetry via +python-base target. Next step is to copy source code of the project and finally finalize the build with some poetry project setup which is done with +BUILDER Function.","title":"Prepare base builder"},{"location":"guides/languages/python/#running-checks","text":"TODO","title":"Running checks"},{"location":"guides/languages/python/#test","text":"test: FROM +builder RUN poetry run pytest As the final step, after proper setup of the Python project we can run tests, to do so inherit from the already discussed +builder target and just run poetry run pytest or with any other way which are suitable for your project setup. And that's it!","title":"Test"},{"location":"guides/languages/python/#release-and-publish","text":"To prepare a release artifact and publish it to some external container registries please follow this guide . The only things you need is too define release and publish Earthly targets with the proper configuration of the artifacts for your project.","title":"Release and publish"},{"location":"guides/languages/python/#conclusion","text":"You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Python project, as you can see it is pretty simple.","title":"Conclusion"},{"location":"guides/languages/rust/","text":"Rust \u00b6 Introduction \u00b6 Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to work with Rust based projects. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/rust to find a basic Rust project, with the Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Also we will take a look how we are setup Rust projects and what configuration is used. Building the Earthfile \u00b6 Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example . Prepare base builder \u00b6 VERSION 0.8 IMPORT ./../../earthly/rust AS rust-ci # Set up our target toolchains, and copy our files. builder: DO rust-ci+SETUP COPY --dir .cargo .config crates . COPY Cargo.toml . COPY clippy.toml deny.toml rustfmt.toml . The first target builder is responsible for preparing configured Rust environments and, install all needed tools and dependencies. Builder steps \u00b6 First step of +builder target is to prepare a Rust environment via +installer target, which is called in +SETUP FUNCTION. The +installer target installs necessary tools for +rust-base target and copies common scripts and standardized Rust configs. The +rust-base provides a base Rustup build environment. It installs necessary packages, including development libraries and tools. Clippy linter, LLVM tools for generating code coverage, and nightly toolchain are installed. Next step is to copy source code of the project. Note that you need to copy only needed files for Rust build process, any other irrelevant stuff should omitted. And finally finalize the build with +SETUP FUNCTION which takes no arguments. Warning Please ensure that Rust version set in rust-toolchain.toml matches the Docker image tag uses in +rust-base target. Running checks \u00b6 # Run check using the most efficient host tooling # CI Automated Entry point. check: FROM +builder DO rust-ci+EXECUTE --cmd=\"/scripts/std_checks.py\" # Test which runs check with all supported host tooling. Needs qemu or rosetta to run. # Only used to validate tooling is working across host toolsets. all-hosts-check: BUILD --platform=linux/amd64 --platform=linux/arm64 +check With prepared environment and all data, we're now ready to start operating with the source code and configuration files. The +check target performs all checks and validation procedures using the help of std_checks.py script. This script performs static checks of the Rust project as cargo fmt , cargo machete , cargo deny which will validate formatting, find unused dependencies and any supply chain issues with dependencies. Here is the list of steps (look at ./earthly/rust/scripts/std_checks.py ): cargo fmtchk ( cargo alias , look at ./earthly/rust/stdcfgs/cargo_config.toml )Checking Rust Code Format. Checking configuration files for consistency. cargo machete - Checking for Unused Dependencies. cargo deny check - Checking for Supply Chain Issues. As it was mentioned above, it validates configuration files as .cargo/config.toml , rustfmt.toml , .config/nextest.toml , clippy.toml , deny.toml to be the same as defined in earthly/rust/stdcfgs directory of the catalyst-ci repo. So when you are going to setup a new Rust project, copy these configuration files described above to the appropriate location of your Rust project. Another target as +all-hosts-check just invokes +check with the specified --platform . It is needed for the local development to double check that everything works for different platforms. It is important to define a linux target platform with a proper CPU architecture for the Rust project when you are building it inside Docker and check the build process with different scenarios. The same approach will be seen in other targets throughout this guide. Build \u00b6 # Run build using the most efficient host tooling # CI Automated Entry point. build: FROM +builder # This WILL save the junit and coverage reports even if it fails. DO rust-ci+EXECUTE \\ --cmd=\"/scripts/std_build.py --cov_report=$HOME/coverage-report.info --libs=bar --bins=foo/foo\" \\ --junit=\"example.junit-report.xml\" \\ --coverage=\"example.coverage-report.info\" \\ --output=\"release/[^\\./]+\" \\ --docs=\"true\" SAVE ARTIFACT target/release/foo foo # Test which runs check with all supported host tooling. Needs qemu or rosetta to run. # Only used to validate tooling is working across host toolsets. all-hosts-build: BUILD --platform=linux/amd64 --platform=linux/arm64 +build After successful performing checks of the Rust project we can finally build artifacts. Obviously it inherits +builder target environment and then performs build of the binary. Important to note that in this particular example we are dealing with the executable Rust project, so it produces binary as a final artifact. We will discuss another scenario of building a Rust library later. Actual build process is done with the std_build.py script. Here is the full list of configuration of this script: usage: std_build.py [ -h ] [ -v ] [ --build_flags BUILD_FLAGS ] [ --doctest_flags DOCTEST_FLAGS ] [ --test_flags TEST_FLAGS ] [ --bench_flags BENCH_FLAGS ] [ --with_test ] [ --cov_report COV_REPORT ] [ --with_bench ] [ --libs LIBS ] [ --bins BINS ] Rust build processing. options: -h, --help Show this help message and exit. -v --verbose Show the output of executed commands verbosely. --build_flags BUILD_FLAGS Additional command-line flags that can be passed to the ` cargo build ` command. --lint_flags LINT_FLAGS Additional command-line flags that can be passed to the ` cargo lint ` command. --doctest_flags DOCTEST_FLAGS Additional command-line flags that can be passed to the ` cargo testdocs ` command. --test_flags TEST_FLAGS Additional command-line flags that can be passed to the ` cargo testunit ` command. --bench_flags BENCH_FLAGS Additional command-line flags that can be passed to the ` cargo bench ` command. --cov_report COV_REPORT The output coverage report file path. If omitted, coverage will not be run. --disable_tests Flag to disable to run tests ( including unit tests and doc tests ) . --disable_benches Flag to disable to run benchmarks. --disable_docs Flag to disable docs building ( including graphs, trees etc. ) or not. --libs LIBS The list of lib crates ` cargo-modules ` docs to build separated by comma. --bins BINS The list of binaries ` cargo-modules ` docs to build and make a smoke tests on them. Note that the libs argument takes a list of library crate's names in your Rust project, e.g. --libs=\"crate1 crate2\" . The bins argument takes a list of binary crate's names and binary names in your Rust project, e.g. --bins=\"crate1/bin1 crate1/bin2 crate2/bin1\" , note that each binary name correspond to each crate and separated in this list with / symbol. Under this build process we perform different steps of compiling and validating of our Rust project, here is the list of steps (look at ./earthly/rust/scripts/std_build.py and ./earthly/rust/scripts/std_docs.py ): cargo build - Building all code in the workspace. cargo lint ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml ) Checking all Clippy Lints in the workspace. cargo docs ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Documentation can be generated OK. cargo testunit ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Self contained Unit tests all pass. cargo testdocs ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Documentation tests all pass. cargo testcov ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Self contained Unit tests all pass and collect coverage. cargo bench - Checking Benchmarks all run to completion. cargo depgraph - Generating dependency graph based on the Rust code. Generated artifacts are doc/workspace.dot , doc/full.dot , doc/all.dot files. cargo modules - Generating modules trees and graphs based on the Rust code. Generated artifacts are doc/$crate.$bin.bin.modules.tree , doc/$crate.$bin.bin.modules.dot for the specified --bins=\"crate1/bin1\" argument and target/doc/$crate.lib.modules.tree , target/doc/$crate.lib.modules.dot for the specified --libs=\"crate1\" argument. Running smoke tests on provided binary names ( --bins argument). Final step is to provide desired artifacts: docs and binary. Note that all commands within the std_build.py are written to be run in parallel, resulting in a faster speeds. Test \u00b6 As you already mentioned that running of unit tests is done during the build process, but if you need some integration tests please follow this PostgreSQL builder , Rust will have the same approach. Release and publish \u00b6 To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image. Rust nightly channel \u00b6 Be aware that we are running some tools in the nightly channel, such as cargo fmt and cargo docs . It is highly likely that the nightly toolchain version on the CI machines differs from what you have locally. Unfortunately, Rust tooling does not have the capability to preserve and maintain consistency between stable and nightly toolchains simultaneously. In our builds, we only preserve the stable toolchain version ( rust-toolchain.toml file). Rust tools \u00b6 All the necessary Rust tools can be found in tool . Rust FUNCTIONs \u00b6 While leveraging the Earthly lib/rust , the following Rust FUNCTIONs are customize to align with our specific requirements that our project needed. EXECUTE : This FUNCTION, adapted from the Earthly lib/rust , is tailored to execute commands according to user specifications. It serves a pivotal role in managing Rust project builds, handling outputs, and supporting features such as JUnit reporting and code coverage. Our modifications ensure that the command executed utilize the cache efficiently, which result in a faster compilation time. # Example of using `EXECUTE` with a simple copy command DO +EXECUTE --cmd=\"cp $CARGO_INSTALL_ROOT/config.toml $CARGO_HOME/config.toml\" CARGO : This FUNCTION serves as a shim of the original lib/rust CARGO FUNCTION to guarantee consistent usage of the appropriate upstream Rust library. Therefore, users of catalyst-ci who wish to use rust+CARGO from lib/rust should utilize the +CARGO implementation provided in this repository. # Example of using `CARGO` to install a Rust tool DO rust-ci+CARGO --args=\"install cargo-nextest --version=0.9.70 --locked\" COPY_OUTPUT : This FUNCTION serves as a shim of the original lib/rust COPY_OUTPUT to facilitate the SAVE of ARTIFACT from the target folder (mounted cache) into the image layer. This FUNCTION will always trying to minimize the total size of the copied files, which result in a faster copy. # Example of using `COPY_OUTPUT` where `SAVE ARTIFACT` is used # The `COPY_OUTPUT` will copy the output to `target` folder DO rust+COPY_OUTPUT --output=\"nextest/ci/junit.xml\" SAVE ARTIFACT target/nextest/ci/junit.xml AS LOCAL \"$junit\" Note that in order to called the above FUNCTIONs, rust+INIT should be called first. Conclusion \u00b6 You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Rust project, as you can see it is pretty simple.","title":"Rust"},{"location":"guides/languages/rust/#rust","text":"","title":"Rust"},{"location":"guides/languages/rust/#introduction","text":"Tip If you're just looking for a complete example, click here . This guide will provide detailed instructions for how the example was built. This guide will get you started with using the Catalyst CI to work with Rust based projects. To begin, clone the Catalyst CI repository: git clone https://github.com/input-output-hk/catalyst-ci.git Navigate to examples/rust to find a basic Rust project, with the Earthfile in it. This is the Earthfile we will be building in this guide. You can choose to either delete the file and start from scratch, or read the guide and follow along in the file. Also we will take a look how we are setup Rust projects and what configuration is used.","title":"Introduction"},{"location":"guides/languages/rust/#building-the-earthfile","text":"Note The below sections will walk through building our Earthfile step-by-step. In each section, only the fragments of the Earthfile relative to that section are displayed. This means that, as you go through each section, you should be cumulatively building the Earthfile . If you get stuck at any point, you can always take a look at the example .","title":"Building the Earthfile"},{"location":"guides/languages/rust/#prepare-base-builder","text":"VERSION 0.8 IMPORT ./../../earthly/rust AS rust-ci # Set up our target toolchains, and copy our files. builder: DO rust-ci+SETUP COPY --dir .cargo .config crates . COPY Cargo.toml . COPY clippy.toml deny.toml rustfmt.toml . The first target builder is responsible for preparing configured Rust environments and, install all needed tools and dependencies.","title":"Prepare base builder"},{"location":"guides/languages/rust/#builder-steps","text":"First step of +builder target is to prepare a Rust environment via +installer target, which is called in +SETUP FUNCTION. The +installer target installs necessary tools for +rust-base target and copies common scripts and standardized Rust configs. The +rust-base provides a base Rustup build environment. It installs necessary packages, including development libraries and tools. Clippy linter, LLVM tools for generating code coverage, and nightly toolchain are installed. Next step is to copy source code of the project. Note that you need to copy only needed files for Rust build process, any other irrelevant stuff should omitted. And finally finalize the build with +SETUP FUNCTION which takes no arguments. Warning Please ensure that Rust version set in rust-toolchain.toml matches the Docker image tag uses in +rust-base target.","title":"Builder steps"},{"location":"guides/languages/rust/#running-checks","text":"# Run check using the most efficient host tooling # CI Automated Entry point. check: FROM +builder DO rust-ci+EXECUTE --cmd=\"/scripts/std_checks.py\" # Test which runs check with all supported host tooling. Needs qemu or rosetta to run. # Only used to validate tooling is working across host toolsets. all-hosts-check: BUILD --platform=linux/amd64 --platform=linux/arm64 +check With prepared environment and all data, we're now ready to start operating with the source code and configuration files. The +check target performs all checks and validation procedures using the help of std_checks.py script. This script performs static checks of the Rust project as cargo fmt , cargo machete , cargo deny which will validate formatting, find unused dependencies and any supply chain issues with dependencies. Here is the list of steps (look at ./earthly/rust/scripts/std_checks.py ): cargo fmtchk ( cargo alias , look at ./earthly/rust/stdcfgs/cargo_config.toml )Checking Rust Code Format. Checking configuration files for consistency. cargo machete - Checking for Unused Dependencies. cargo deny check - Checking for Supply Chain Issues. As it was mentioned above, it validates configuration files as .cargo/config.toml , rustfmt.toml , .config/nextest.toml , clippy.toml , deny.toml to be the same as defined in earthly/rust/stdcfgs directory of the catalyst-ci repo. So when you are going to setup a new Rust project, copy these configuration files described above to the appropriate location of your Rust project. Another target as +all-hosts-check just invokes +check with the specified --platform . It is needed for the local development to double check that everything works for different platforms. It is important to define a linux target platform with a proper CPU architecture for the Rust project when you are building it inside Docker and check the build process with different scenarios. The same approach will be seen in other targets throughout this guide.","title":"Running checks"},{"location":"guides/languages/rust/#build","text":"# Run build using the most efficient host tooling # CI Automated Entry point. build: FROM +builder # This WILL save the junit and coverage reports even if it fails. DO rust-ci+EXECUTE \\ --cmd=\"/scripts/std_build.py --cov_report=$HOME/coverage-report.info --libs=bar --bins=foo/foo\" \\ --junit=\"example.junit-report.xml\" \\ --coverage=\"example.coverage-report.info\" \\ --output=\"release/[^\\./]+\" \\ --docs=\"true\" SAVE ARTIFACT target/release/foo foo # Test which runs check with all supported host tooling. Needs qemu or rosetta to run. # Only used to validate tooling is working across host toolsets. all-hosts-build: BUILD --platform=linux/amd64 --platform=linux/arm64 +build After successful performing checks of the Rust project we can finally build artifacts. Obviously it inherits +builder target environment and then performs build of the binary. Important to note that in this particular example we are dealing with the executable Rust project, so it produces binary as a final artifact. We will discuss another scenario of building a Rust library later. Actual build process is done with the std_build.py script. Here is the full list of configuration of this script: usage: std_build.py [ -h ] [ -v ] [ --build_flags BUILD_FLAGS ] [ --doctest_flags DOCTEST_FLAGS ] [ --test_flags TEST_FLAGS ] [ --bench_flags BENCH_FLAGS ] [ --with_test ] [ --cov_report COV_REPORT ] [ --with_bench ] [ --libs LIBS ] [ --bins BINS ] Rust build processing. options: -h, --help Show this help message and exit. -v --verbose Show the output of executed commands verbosely. --build_flags BUILD_FLAGS Additional command-line flags that can be passed to the ` cargo build ` command. --lint_flags LINT_FLAGS Additional command-line flags that can be passed to the ` cargo lint ` command. --doctest_flags DOCTEST_FLAGS Additional command-line flags that can be passed to the ` cargo testdocs ` command. --test_flags TEST_FLAGS Additional command-line flags that can be passed to the ` cargo testunit ` command. --bench_flags BENCH_FLAGS Additional command-line flags that can be passed to the ` cargo bench ` command. --cov_report COV_REPORT The output coverage report file path. If omitted, coverage will not be run. --disable_tests Flag to disable to run tests ( including unit tests and doc tests ) . --disable_benches Flag to disable to run benchmarks. --disable_docs Flag to disable docs building ( including graphs, trees etc. ) or not. --libs LIBS The list of lib crates ` cargo-modules ` docs to build separated by comma. --bins BINS The list of binaries ` cargo-modules ` docs to build and make a smoke tests on them. Note that the libs argument takes a list of library crate's names in your Rust project, e.g. --libs=\"crate1 crate2\" . The bins argument takes a list of binary crate's names and binary names in your Rust project, e.g. --bins=\"crate1/bin1 crate1/bin2 crate2/bin1\" , note that each binary name correspond to each crate and separated in this list with / symbol. Under this build process we perform different steps of compiling and validating of our Rust project, here is the list of steps (look at ./earthly/rust/scripts/std_build.py and ./earthly/rust/scripts/std_docs.py ): cargo build - Building all code in the workspace. cargo lint ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml ) Checking all Clippy Lints in the workspace. cargo docs ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Documentation can be generated OK. cargo testunit ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Self contained Unit tests all pass. cargo testdocs ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Documentation tests all pass. cargo testcov ( cargo alias , look at ./earthly/rust/stdcfgs/config.toml )Checking Self contained Unit tests all pass and collect coverage. cargo bench - Checking Benchmarks all run to completion. cargo depgraph - Generating dependency graph based on the Rust code. Generated artifacts are doc/workspace.dot , doc/full.dot , doc/all.dot files. cargo modules - Generating modules trees and graphs based on the Rust code. Generated artifacts are doc/$crate.$bin.bin.modules.tree , doc/$crate.$bin.bin.modules.dot for the specified --bins=\"crate1/bin1\" argument and target/doc/$crate.lib.modules.tree , target/doc/$crate.lib.modules.dot for the specified --libs=\"crate1\" argument. Running smoke tests on provided binary names ( --bins argument). Final step is to provide desired artifacts: docs and binary. Note that all commands within the std_build.py are written to be run in parallel, resulting in a faster speeds.","title":"Build"},{"location":"guides/languages/rust/#test","text":"As you already mentioned that running of unit tests is done during the build process, but if you need some integration tests please follow this PostgreSQL builder , Rust will have the same approach.","title":"Test"},{"location":"guides/languages/rust/#release-and-publish","text":"To prepare a release artifact and publish it to some external container registries please follow this guide . It is pretty strait forward for this builder process, because as a part of +build target we already creating a docker image.","title":"Release and publish"},{"location":"guides/languages/rust/#rust-nightly-channel","text":"Be aware that we are running some tools in the nightly channel, such as cargo fmt and cargo docs . It is highly likely that the nightly toolchain version on the CI machines differs from what you have locally. Unfortunately, Rust tooling does not have the capability to preserve and maintain consistency between stable and nightly toolchains simultaneously. In our builds, we only preserve the stable toolchain version ( rust-toolchain.toml file).","title":"Rust nightly channel"},{"location":"guides/languages/rust/#rust-tools","text":"All the necessary Rust tools can be found in tool .","title":"Rust tools"},{"location":"guides/languages/rust/#rust-functions","text":"While leveraging the Earthly lib/rust , the following Rust FUNCTIONs are customize to align with our specific requirements that our project needed. EXECUTE : This FUNCTION, adapted from the Earthly lib/rust , is tailored to execute commands according to user specifications. It serves a pivotal role in managing Rust project builds, handling outputs, and supporting features such as JUnit reporting and code coverage. Our modifications ensure that the command executed utilize the cache efficiently, which result in a faster compilation time. # Example of using `EXECUTE` with a simple copy command DO +EXECUTE --cmd=\"cp $CARGO_INSTALL_ROOT/config.toml $CARGO_HOME/config.toml\" CARGO : This FUNCTION serves as a shim of the original lib/rust CARGO FUNCTION to guarantee consistent usage of the appropriate upstream Rust library. Therefore, users of catalyst-ci who wish to use rust+CARGO from lib/rust should utilize the +CARGO implementation provided in this repository. # Example of using `CARGO` to install a Rust tool DO rust-ci+CARGO --args=\"install cargo-nextest --version=0.9.70 --locked\" COPY_OUTPUT : This FUNCTION serves as a shim of the original lib/rust COPY_OUTPUT to facilitate the SAVE of ARTIFACT from the target folder (mounted cache) into the image layer. This FUNCTION will always trying to minimize the total size of the copied files, which result in a faster copy. # Example of using `COPY_OUTPUT` where `SAVE ARTIFACT` is used # The `COPY_OUTPUT` will copy the output to `target` folder DO rust+COPY_OUTPUT --output=\"nextest/ci/junit.xml\" SAVE ARTIFACT target/nextest/ci/junit.xml AS LOCAL \"$junit\" Note that in order to called the above FUNCTIONs, rust+INIT should be called first.","title":"Rust FUNCTIONs"},{"location":"guides/languages/rust/#conclusion","text":"You can see the final Earthfile here and any other files in the same directory. We have learnt how to maintain and setup Rust project, as you can see it is pretty simple.","title":"Conclusion"},{"location":"onboarding/","text":"Welcome \u00b6 Welcome to the onboarding section of the documentation. This section will guide you through the fundamentals of the Catalyst CI process and introduce you to the various tools and processes that we use. Overview \u00b6 Note This section will discuss concepts related to Earthly . If you are not familiar with Earthly, please head over to the appendix to learn more about it before continuing. The CI process works through a discovery mechanism that identifies Earthfile s in a repository and filters them by target. During every run, the CI will automatically discover and execute a select number of reserved targets. Each of these targets serves a single purpose, and together they are responsible for executing the entire release process. The CI process is designed to be modular and reusable across various different requirements. By default, if a specific target is not found in the discovery phase, it simply passes and moves on to the next one. This allows slowly building out a repository and only implementing the targets that make sense at that time. The discovery and execution nature of the CI allows developers to contractually define the outputs of the particular subproject they happen to be working within. For example, a developer can introduce a new Earthfile into the service-a subdirectory of a mono-repo and begin using the reserved target names to interact with the CI. This promotes self-service and establishes a clear boundary of ownership, whereby developers only need to be concerned about maintaining a single file in their subproject. The CI process is well-documented, and troubleshooting unexpected errors only requires knowledge of Earthly and GitHub Actions . All the code is contained in a single open-source repository and contributions are welcome. The remainder of the overview section will focus on discussing some of these concepts in more detail. Discovery \u00b6 The discovery process serves as a critical piece in the overall CI strategy. It enables a declarative approach whereby developers can declare the deliverables of their particular subproject and rely on the CI process to reconcile them. This reduces the friction of onboarding while simultaneously establishing a separation of concerns in a complex mono-repo environment. During a single run, the CI will go through multiple phases of discovery. In each of these discovery phases, a custom CLI provided by the catalyst-ci repository is executed. The CLI is responsible for recursively scanning the repository for Earthfile s and filtering them by target. The CLI will return a list of Earthfile path and a map where the key is the Earthfile path and the value is a list of filtered targets. For example, in the check phase of the CI, check and check-* will be executed. The wildcard * serves as a regular search term, representing one or more other characters. The output of the check phase may look like the following: Map: { \"/home/work/test\" : [ \"check-test1\" , \"check-test2\" , \"check-test3\" , \"check-test-test4\" ], \"/home/work/test2\" : [ \"check\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] This list of path is fed into a matrix job that multiplexes executing the filtered targets from each of the discovered Earthfile s. The filtered targets will be retrieved from the map according to which Earthfile is currently running. For example, from the above example, running /home/work/test will run the targets check-test1 , check-test2 , check-test3 and check-test-test4 . Executing each discovered Earthfile in parallel will maximize network throughput and create a more easily digestible view of the CI status. For example, by doing this, every individual Earthfile gets its own dedicated job and logs. This can be easily seen from the GitHub Actions UI. Execution \u00b6 After each discovery phase, a list of targets will be executed by the CI. Execution is handled by Earthly and usually occurs on a remote Earthly runner that maximizes the benefits of caching. The exact steps that are executed by the target are defined by the developer. While most targets generally have a clearly defined scope, the goal is to enable adaptability by offloading the logic to the developer who is more aware of their immediate context. Some targets have additional processing beyond simply executing the target and returning. For example, the publish target is expected to produce a single container image that is then further processed by the CI system. The image will go through static analysis and ultimately get published to multiple image registries depending on the context. The exact targets that are available, as well as their scope and function, can be explored more in the reference documentation. Pipeline \u00b6 flowchart LR A[Check] --> B[Build] --> C[Package] --> D[Test] D --> E[Release] D --> F[Publish] D --> G[Docs] The full CI process consists of combining the discovery and execution mechanisms into a complete pipeline, as shown above. Each of the boxes represent a distinct stage which consists of discovering and then executing a target. As previously mentioned, some stages, like the release , publish , and docs stages, have additional logic that occurs after executing the target. Each stage is self-contained and the only dependency occurs when validating that the previous stage was successful. For example, the build stage will not execute until the check stage has passed. Recall that stages consist of executing multiple targets in parallel. This means that all subprojects within a repository must pass the check stage before any building will begin. This fits into the overall goal of ensuring that the default branch is always in a healthy state and it also promotes cross-team collaboration. The exact scope of each stage is documented in the reference section. However, as a short introduction, here is a brief summary of each one: check - This stage is expected to run all necessary checks to validate the health of the project. This includes formatting, linting, and other static analysis tools. The goal of this stage is to provide a quick way to validate the overall health of the code and avoid wasting cycles on building unhealthy code. build - This stage is expected to build any artifacts provided by a given subproject. The primary purpose of this target is to validate that things are building without error. It also ensures that builds are cached before executing subsequent steps that typically depend on these builds. package - This stage is expected to package multiple artifacts into a single package. It is typically used outside the scope of a single subproject, and instead combines outputs from multiple subprojects into a single deliverable. As such, it typically doesn't appear within the scope of a single subproject and is instead found in Earthfile s at higher points in the repository hierarchy. test - This stage is expected to run tests that prove the subproject, or multiple subprojects, are working as expected. The target can be used to run any sort of test, including unit tests, smoke tests, and integration tests. release - This stage is expected to produce a single release artifact. This could be a binary, a collection of resources, or even certain reports. When a tag commit is pushed, the CI will build this target and include the produced artifact as part of a GitHub Release. publish - This stage is expected to produce a single container image. After the image is built by executing the target, the CI will perform other steps to transform the image. For example, tagging it with the git commit hash and performing general static analysis. The CI will automatically build and publish this image to configured registries during certain types of git events. docs - This stage is expected to build and publish documentation. Each of the above stages are purely optional and can be combined to perform different types of CI workflows. For smaller projects, only a number of stages will be utilized initially. However, as a project grows, it can begin incorporating more stages without having to fundamentally alter the CI system. Usage \u00b6 Now that we've covered how the CI process works at a conceptual level, how can we use it practically? As a developer, the main interface you need to be most concerned with is the Earthfile . Each \"stage\" discussed in the previous section can be directly correlated to an Earthly target. Two patterns target or target-* can be used according to your usage and preferences. In case of target , it will scan for targets that match the exact target name (ie., target ) In case of target-* , it will scan for targets that start with target- and are followed by any number of digits or characters (The wildcard * serves as a regular search term, representing one or more other characters.) Warning Wildcard ( target-* ) is only compatible with targets that do not produce any artifacts or images. The current design is only supported in the check and test stages. The examples are provided below: In the CI's check phase, if check is used, the following output will be returned: Map: { \"/home/work/test\" : [ \"check\" ], \"/home/work/test2\" : [ \"check\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] If the check-* is used, the following output will be returned Map: { \"/home/work/test\" : [ \"check-test1\" , \"check-test2\" , \"check-test3\" , \"check-test-test4\" ], \"/home/work/test2\" : [ \"check-test1\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] If you're contributing a new subproject with deliverables, you'll need to include an initial Earthfile as part of the contribution. Likewise, if you add a new deliverable to an existing project, you'll need to make sure it's captured in the existing Earthfile . Not all Earthfile s are constrained to a single subproject. In many cases, an Earthfile exists at higher points in the repository hierarchy that performs packaging and testing across multiple subprojects. This is especially true for integration testing, and it something you need to take into account when providing new features. Not all targets need to be present in your Earthfile . For a project that is still gaining maturity, it might make sense to only define the check and build targets until the project is ready to be tested and shipped. Getting Started \u00b6 Before creating and/or modifying an Earthfile , it's imperative to review the style guide . Due to the relative flexibility of Earthly, it's possible to structure an Earthfile in dozens of valid ways. To provide consistency across our projects, we have implemented a style guide which brings a level of standardization to Earthfile s. The next step after reviewing the style guide is taking a look at available guides for performing specific tasks with Catalyst CI. The guides are broken up by language or topic and provide a starter template for getting off the ground quickly. Reviewing the guides also helps with connecting the concepts discussed in this onboarding guide with actual code. If the task you're working on is not covered in a guide, it's still recommended you read at least one of the other guides in order get a more in-depth understanding of building with Catalyst CI. Experimentation is also encouraged. The CI process runs on every single commit, even commits to PRs. You can utilize this fact to begin experimenting with an Earthfile and seeing how the CI reacts to different targets. The only limitation is that not all targets execute fully in a PR setting (i.e. no artifacts are published/released). Finally, if you get stuck, or have a need to understand the the CI process more, there is reference documentation available which covers not only individual targets, but also how the entire CI process operates under the hood. You may also use the discussions section of the catalyst-ci repository to ask questions specific to the CI process. You are now equipped and ready to start using the Catalyst CI! We are very open-source friendly and will review all feedback/PRs made against the repository. So please be encouraged to contribute. Authentication \u00b6 Catalyst CI uses a number of services that require API authentication. The CI can in-theory be used without it. However, this is not recommended and is untested as it results in throttling which can randomly break builds. Note: Never commit the .secret file to any repo, and never add secrets to the .secret.template file. Docker HUB \u00b6 CI pulls many images from docker hub, if you are not properly authenticated, this can result in throttling. To authenticate: Create an account at Docker Hub Use the credentials from that account to login locally with docker login . If you are not properly authenticated, running earthly for any target will warn: Warning: you are not logged into registry-1.docker.io, you may experience rate-limiting when pulling images. GitHub Token \u00b6 Some CI functions require API access to Github. While those API's can be used without authentication it is easy to hit rate limits which fail builds. To Authenticate, go to Github and create a new personal access token. The Token only requires public_repo and read:packages permissions. Like So: Copy the token, and create a .secret file in the root of the repo with: cp .secret.template .secret and paste your new token into that file. This step needs to be repeated for every repo using catalyst-ci. You also need docker to login to ghcr.io using this same token: docker login ghcr.io -u <GITHUB_USERNAME> -p <GITHUB_TOKEN> Some operation may fail, and you will see the following warning message if you are not properly authenticated with GitHub. Warning: you are not logged into ghcr.io, you may experience rate-limiting when pulling images","title":"Welcome"},{"location":"onboarding/#welcome","text":"Welcome to the onboarding section of the documentation. This section will guide you through the fundamentals of the Catalyst CI process and introduce you to the various tools and processes that we use.","title":"Welcome"},{"location":"onboarding/#overview","text":"Note This section will discuss concepts related to Earthly . If you are not familiar with Earthly, please head over to the appendix to learn more about it before continuing. The CI process works through a discovery mechanism that identifies Earthfile s in a repository and filters them by target. During every run, the CI will automatically discover and execute a select number of reserved targets. Each of these targets serves a single purpose, and together they are responsible for executing the entire release process. The CI process is designed to be modular and reusable across various different requirements. By default, if a specific target is not found in the discovery phase, it simply passes and moves on to the next one. This allows slowly building out a repository and only implementing the targets that make sense at that time. The discovery and execution nature of the CI allows developers to contractually define the outputs of the particular subproject they happen to be working within. For example, a developer can introduce a new Earthfile into the service-a subdirectory of a mono-repo and begin using the reserved target names to interact with the CI. This promotes self-service and establishes a clear boundary of ownership, whereby developers only need to be concerned about maintaining a single file in their subproject. The CI process is well-documented, and troubleshooting unexpected errors only requires knowledge of Earthly and GitHub Actions . All the code is contained in a single open-source repository and contributions are welcome. The remainder of the overview section will focus on discussing some of these concepts in more detail.","title":"Overview"},{"location":"onboarding/#discovery","text":"The discovery process serves as a critical piece in the overall CI strategy. It enables a declarative approach whereby developers can declare the deliverables of their particular subproject and rely on the CI process to reconcile them. This reduces the friction of onboarding while simultaneously establishing a separation of concerns in a complex mono-repo environment. During a single run, the CI will go through multiple phases of discovery. In each of these discovery phases, a custom CLI provided by the catalyst-ci repository is executed. The CLI is responsible for recursively scanning the repository for Earthfile s and filtering them by target. The CLI will return a list of Earthfile path and a map where the key is the Earthfile path and the value is a list of filtered targets. For example, in the check phase of the CI, check and check-* will be executed. The wildcard * serves as a regular search term, representing one or more other characters. The output of the check phase may look like the following: Map: { \"/home/work/test\" : [ \"check-test1\" , \"check-test2\" , \"check-test3\" , \"check-test-test4\" ], \"/home/work/test2\" : [ \"check\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] This list of path is fed into a matrix job that multiplexes executing the filtered targets from each of the discovered Earthfile s. The filtered targets will be retrieved from the map according to which Earthfile is currently running. For example, from the above example, running /home/work/test will run the targets check-test1 , check-test2 , check-test3 and check-test-test4 . Executing each discovered Earthfile in parallel will maximize network throughput and create a more easily digestible view of the CI status. For example, by doing this, every individual Earthfile gets its own dedicated job and logs. This can be easily seen from the GitHub Actions UI.","title":"Discovery"},{"location":"onboarding/#execution","text":"After each discovery phase, a list of targets will be executed by the CI. Execution is handled by Earthly and usually occurs on a remote Earthly runner that maximizes the benefits of caching. The exact steps that are executed by the target are defined by the developer. While most targets generally have a clearly defined scope, the goal is to enable adaptability by offloading the logic to the developer who is more aware of their immediate context. Some targets have additional processing beyond simply executing the target and returning. For example, the publish target is expected to produce a single container image that is then further processed by the CI system. The image will go through static analysis and ultimately get published to multiple image registries depending on the context. The exact targets that are available, as well as their scope and function, can be explored more in the reference documentation.","title":"Execution"},{"location":"onboarding/#pipeline","text":"flowchart LR A[Check] --> B[Build] --> C[Package] --> D[Test] D --> E[Release] D --> F[Publish] D --> G[Docs] The full CI process consists of combining the discovery and execution mechanisms into a complete pipeline, as shown above. Each of the boxes represent a distinct stage which consists of discovering and then executing a target. As previously mentioned, some stages, like the release , publish , and docs stages, have additional logic that occurs after executing the target. Each stage is self-contained and the only dependency occurs when validating that the previous stage was successful. For example, the build stage will not execute until the check stage has passed. Recall that stages consist of executing multiple targets in parallel. This means that all subprojects within a repository must pass the check stage before any building will begin. This fits into the overall goal of ensuring that the default branch is always in a healthy state and it also promotes cross-team collaboration. The exact scope of each stage is documented in the reference section. However, as a short introduction, here is a brief summary of each one: check - This stage is expected to run all necessary checks to validate the health of the project. This includes formatting, linting, and other static analysis tools. The goal of this stage is to provide a quick way to validate the overall health of the code and avoid wasting cycles on building unhealthy code. build - This stage is expected to build any artifacts provided by a given subproject. The primary purpose of this target is to validate that things are building without error. It also ensures that builds are cached before executing subsequent steps that typically depend on these builds. package - This stage is expected to package multiple artifacts into a single package. It is typically used outside the scope of a single subproject, and instead combines outputs from multiple subprojects into a single deliverable. As such, it typically doesn't appear within the scope of a single subproject and is instead found in Earthfile s at higher points in the repository hierarchy. test - This stage is expected to run tests that prove the subproject, or multiple subprojects, are working as expected. The target can be used to run any sort of test, including unit tests, smoke tests, and integration tests. release - This stage is expected to produce a single release artifact. This could be a binary, a collection of resources, or even certain reports. When a tag commit is pushed, the CI will build this target and include the produced artifact as part of a GitHub Release. publish - This stage is expected to produce a single container image. After the image is built by executing the target, the CI will perform other steps to transform the image. For example, tagging it with the git commit hash and performing general static analysis. The CI will automatically build and publish this image to configured registries during certain types of git events. docs - This stage is expected to build and publish documentation. Each of the above stages are purely optional and can be combined to perform different types of CI workflows. For smaller projects, only a number of stages will be utilized initially. However, as a project grows, it can begin incorporating more stages without having to fundamentally alter the CI system.","title":"Pipeline"},{"location":"onboarding/#usage","text":"Now that we've covered how the CI process works at a conceptual level, how can we use it practically? As a developer, the main interface you need to be most concerned with is the Earthfile . Each \"stage\" discussed in the previous section can be directly correlated to an Earthly target. Two patterns target or target-* can be used according to your usage and preferences. In case of target , it will scan for targets that match the exact target name (ie., target ) In case of target-* , it will scan for targets that start with target- and are followed by any number of digits or characters (The wildcard * serves as a regular search term, representing one or more other characters.) Warning Wildcard ( target-* ) is only compatible with targets that do not produce any artifacts or images. The current design is only supported in the check and test stages. The examples are provided below: In the CI's check phase, if check is used, the following output will be returned: Map: { \"/home/work/test\" : [ \"check\" ], \"/home/work/test2\" : [ \"check\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] If the check-* is used, the following output will be returned Map: { \"/home/work/test\" : [ \"check-test1\" , \"check-test2\" , \"check-test3\" , \"check-test-test4\" ], \"/home/work/test2\" : [ \"check-test1\" ] } Path: [ \"/home/work/test\" , \"home/work/test2\" ] If you're contributing a new subproject with deliverables, you'll need to include an initial Earthfile as part of the contribution. Likewise, if you add a new deliverable to an existing project, you'll need to make sure it's captured in the existing Earthfile . Not all Earthfile s are constrained to a single subproject. In many cases, an Earthfile exists at higher points in the repository hierarchy that performs packaging and testing across multiple subprojects. This is especially true for integration testing, and it something you need to take into account when providing new features. Not all targets need to be present in your Earthfile . For a project that is still gaining maturity, it might make sense to only define the check and build targets until the project is ready to be tested and shipped.","title":"Usage"},{"location":"onboarding/#getting-started","text":"Before creating and/or modifying an Earthfile , it's imperative to review the style guide . Due to the relative flexibility of Earthly, it's possible to structure an Earthfile in dozens of valid ways. To provide consistency across our projects, we have implemented a style guide which brings a level of standardization to Earthfile s. The next step after reviewing the style guide is taking a look at available guides for performing specific tasks with Catalyst CI. The guides are broken up by language or topic and provide a starter template for getting off the ground quickly. Reviewing the guides also helps with connecting the concepts discussed in this onboarding guide with actual code. If the task you're working on is not covered in a guide, it's still recommended you read at least one of the other guides in order get a more in-depth understanding of building with Catalyst CI. Experimentation is also encouraged. The CI process runs on every single commit, even commits to PRs. You can utilize this fact to begin experimenting with an Earthfile and seeing how the CI reacts to different targets. The only limitation is that not all targets execute fully in a PR setting (i.e. no artifacts are published/released). Finally, if you get stuck, or have a need to understand the the CI process more, there is reference documentation available which covers not only individual targets, but also how the entire CI process operates under the hood. You may also use the discussions section of the catalyst-ci repository to ask questions specific to the CI process. You are now equipped and ready to start using the Catalyst CI! We are very open-source friendly and will review all feedback/PRs made against the repository. So please be encouraged to contribute.","title":"Getting Started"},{"location":"onboarding/#authentication","text":"Catalyst CI uses a number of services that require API authentication. The CI can in-theory be used without it. However, this is not recommended and is untested as it results in throttling which can randomly break builds. Note: Never commit the .secret file to any repo, and never add secrets to the .secret.template file.","title":"Authentication"},{"location":"onboarding/#docker-hub","text":"CI pulls many images from docker hub, if you are not properly authenticated, this can result in throttling. To authenticate: Create an account at Docker Hub Use the credentials from that account to login locally with docker login . If you are not properly authenticated, running earthly for any target will warn: Warning: you are not logged into registry-1.docker.io, you may experience rate-limiting when pulling images.","title":"Docker HUB"},{"location":"onboarding/#github-token","text":"Some CI functions require API access to Github. While those API's can be used without authentication it is easy to hit rate limits which fail builds. To Authenticate, go to Github and create a new personal access token. The Token only requires public_repo and read:packages permissions. Like So: Copy the token, and create a .secret file in the root of the repo with: cp .secret.template .secret and paste your new token into that file. This step needs to be repeated for every repo using catalyst-ci. You also need docker to login to ghcr.io using this same token: docker login ghcr.io -u <GITHUB_USERNAME> -p <GITHUB_TOKEN> Some operation may fail, and you will see the following warning message if you are not properly authenticated with GitHub. Warning: you are not logged into ghcr.io, you may experience rate-limiting when pulling images","title":"GitHub Token"},{"location":"reference/","text":"Reference \u00b6 This section contains in-depth documentation about the various components that make up the Catalyst CI process. The CI process does provide a useful layer of abstraction for developers to use, however, it's not intended to be a black box. The full system is built on two simple technologies: Earthly and GitHub Actions. A combination of these two systems is what ultimately constructs the whole pipeline. If you need help with troubleshooting the CI process, or have a desire to modify the process to meet a particular need, this section will prove helpful. It is broken up into the foundational components of the CI process, with each component getting an in-depth breakdown of how it works.","title":"Reference"},{"location":"reference/#reference","text":"This section contains in-depth documentation about the various components that make up the Catalyst CI process. The CI process does provide a useful layer of abstraction for developers to use, however, it's not intended to be a black box. The full system is built on two simple technologies: Earthly and GitHub Actions. A combination of these two systems is what ultimately constructs the whole pipeline. If you need help with troubleshooting the CI process, or have a desire to modify the process to meet a particular need, this section will prove helpful. It is broken up into the foundational components of the CI process, with each component getting an in-depth breakdown of how it works.","title":"Reference"},{"location":"reference/actions/","text":"GitHub Actions \u00b6 Catalyst CI is made up of several GitHub Actions that simplify the steps required to perform the CI process. All of these GitHub Actions are compiled into reusable workflows which perform a majority of the CI logic. Overview \u00b6 The following actions are provided by Catalyst CI: configure-runner discover install merge push run setup This section will only highlight the actions which are commonly used in most workflows. Additionally, we will not cover these actions in depth. If you're interested in learning more about a specific action, please click the link above and review the README . Actions \u00b6 Setup \u00b6 The setup action is by far the most common action and shows up in a majority of workflows. It performs the necessary steps to setup the local GitHub runner to perform CI tasks. This includes: Installing Earthly Installing the custom CI CLI from a given version or from an artifact generated in CI CLI release target Configuring access to AWS Authenticating with container registries Configuring the Earthly remote runner Most of these steps are configurable and can be individually disabled. When creating custom workflows, it's highly recommended to use this action to perform common set up tasks. This action uses the configure-runner and install actions underneath the hood. Using these actions individually should be avoided unless absolutely necessary. Note that attempting to lock to a specific tag eventually breaks when a new version of the CLI that is not backwards compatible is released. This can be solved by building an artifact by calling release target, thus avoiding a dependency on a release. By using Earthly (with a remote runner) the local build will be extremely efficient and shouldn't add too much time to the CI pipeline. Discover \u00b6 The discover action is another common action that shows up in many workflows. It performs the \"discovery\" mechanism of finding Earthfiles with filtered targets from specific targets. For example, the check workflow, which run check and check-* , uses this action to discover all Earthfiles that match check and check-* targets. The custom CI CLI must be installed or built locally (see the above section) in order for this action to work. This action is useful when creating custom workflows which extend the existing Catalyst CI process. It can be used to create similar logic for discovering and acting upon specific Earthly targets contained in a repository. Run \u00b6 The run action is another common action that shows up in many workflows. It is responsible for executing the earthly CLI underneath the hood. A custom action was created to perform this task for the following reasons: It simplifies long and hard to read Earthly invocations into a simple contractual interface. It allows capturing and parsing output for additional information (i.e., the names of produced container images) It allows bolting on additional functionality (i.e., automatic retries) When creating custom workflows, it's highly recommended to use this action when calling Earthly for the above reasons. If the action does not support the invocation you need, it's better to modify the action rather than manually execute the earthly CLI. The only exception to this rule is when the invocation is unlikely to be used in more than one place.","title":"GitHub Actions"},{"location":"reference/actions/#github-actions","text":"Catalyst CI is made up of several GitHub Actions that simplify the steps required to perform the CI process. All of these GitHub Actions are compiled into reusable workflows which perform a majority of the CI logic.","title":"GitHub Actions"},{"location":"reference/actions/#overview","text":"The following actions are provided by Catalyst CI: configure-runner discover install merge push run setup This section will only highlight the actions which are commonly used in most workflows. Additionally, we will not cover these actions in depth. If you're interested in learning more about a specific action, please click the link above and review the README .","title":"Overview"},{"location":"reference/actions/#actions","text":"","title":"Actions"},{"location":"reference/actions/#setup","text":"The setup action is by far the most common action and shows up in a majority of workflows. It performs the necessary steps to setup the local GitHub runner to perform CI tasks. This includes: Installing Earthly Installing the custom CI CLI from a given version or from an artifact generated in CI CLI release target Configuring access to AWS Authenticating with container registries Configuring the Earthly remote runner Most of these steps are configurable and can be individually disabled. When creating custom workflows, it's highly recommended to use this action to perform common set up tasks. This action uses the configure-runner and install actions underneath the hood. Using these actions individually should be avoided unless absolutely necessary. Note that attempting to lock to a specific tag eventually breaks when a new version of the CLI that is not backwards compatible is released. This can be solved by building an artifact by calling release target, thus avoiding a dependency on a release. By using Earthly (with a remote runner) the local build will be extremely efficient and shouldn't add too much time to the CI pipeline.","title":"Setup"},{"location":"reference/actions/#discover","text":"The discover action is another common action that shows up in many workflows. It performs the \"discovery\" mechanism of finding Earthfiles with filtered targets from specific targets. For example, the check workflow, which run check and check-* , uses this action to discover all Earthfiles that match check and check-* targets. The custom CI CLI must be installed or built locally (see the above section) in order for this action to work. This action is useful when creating custom workflows which extend the existing Catalyst CI process. It can be used to create similar logic for discovering and acting upon specific Earthly targets contained in a repository.","title":"Discover"},{"location":"reference/actions/#run","text":"The run action is another common action that shows up in many workflows. It is responsible for executing the earthly CLI underneath the hood. A custom action was created to perform this task for the following reasons: It simplifies long and hard to read Earthly invocations into a simple contractual interface. It allows capturing and parsing output for additional information (i.e., the names of produced container images) It allows bolting on additional functionality (i.e., automatic retries) When creating custom workflows, it's highly recommended to use this action when calling Earthly for the above reasons. If the action does not support the invocation you need, it's better to modify the action rather than manually execute the earthly CLI. The only exception to this rule is when the invocation is unlikely to be used in more than one place.","title":"Run"},{"location":"reference/function/","text":"Functions \u00b6 Overview \u00b6 The Catalyst CI repository provides a number of Earthly Functions . You can think of a Function as a reusable snippet of Earthly code that serves the same purpose as functions in a common programming language. Functions are helpful for several reasons: They keep Earthfiles DRY They can encapsulate complex logic into a simple contractual interface They enforce standardization and prevent solving the same problem in multiple different ways The third reason is particularly useful for Catalyst as we have multiple repositories with dozens of Earthfiles often solving similar problems. Usage \u00b6 You are highly encouraged to review the currently available Functions in the Catalyst CI repository . The folder structure is broken out by language/technology and should be relatively easy to navigate. You can incorporate these Functions into your Earthfiles by using something like below: DO github.com/input-output-hk/catalyst-ci/earthly/<folder>+<Function_NAME> --arg1=value1 Replacing folder and Function_NAME respectively. The passing of an argument is optional, as some Functions do not require any input arguments. Contributing \u00b6 Please feel encouraged to contribute Functions to the repository. If you're seeing the same logic being re-used across multiple Earthfiles in a repository, this is a good candidate for refactoring into a Function. Additionally, for SMEs who are aware of language best practices, encoding those into a Function will help increase the overall health of the CI process.","title":"Functions"},{"location":"reference/function/#functions","text":"","title":"Functions"},{"location":"reference/function/#overview","text":"The Catalyst CI repository provides a number of Earthly Functions . You can think of a Function as a reusable snippet of Earthly code that serves the same purpose as functions in a common programming language. Functions are helpful for several reasons: They keep Earthfiles DRY They can encapsulate complex logic into a simple contractual interface They enforce standardization and prevent solving the same problem in multiple different ways The third reason is particularly useful for Catalyst as we have multiple repositories with dozens of Earthfiles often solving similar problems.","title":"Overview"},{"location":"reference/function/#usage","text":"You are highly encouraged to review the currently available Functions in the Catalyst CI repository . The folder structure is broken out by language/technology and should be relatively easy to navigate. You can incorporate these Functions into your Earthfiles by using something like below: DO github.com/input-output-hk/catalyst-ci/earthly/<folder>+<Function_NAME> --arg1=value1 Replacing folder and Function_NAME respectively. The passing of an argument is optional, as some Functions do not require any input arguments.","title":"Usage"},{"location":"reference/function/#contributing","text":"Please feel encouraged to contribute Functions to the repository. If you're seeing the same logic being re-used across multiple Earthfiles in a repository, this is a good candidate for refactoring into a Function. Additionally, for SMEs who are aware of language best practices, encoding those into a Function will help increase the overall health of the CI process.","title":"Contributing"},{"location":"reference/targets/","text":"Targets \u00b6 As discussed in onboarding, the Catalyst CI automatically searches for and executes distinct Earthly targets. By creating these targets in your Earthfile , you can hook into the Catalyst CI process with minimal effort. This section is dedicated to explaining what these targets are, how they work, and how to use them. Tip The targets discussed below are not required to be implemented in every single Earthfile . Consider each target a building block that can be composed into a complete structure that CI runs. The system is meant to be adaptable to different workflows. Check \u00b6 Summary \u00b6 The check or check-* target is responsible for validating that given subproject is healthy and up to the appropriate standards. This target should be used by all subprojects to improve the upkeep of code. No additional tasks are performed before or after running the target. How it Works \u00b6 The check and check-* targets are the first target run in the CI pipeline and must pass before any other targets are run. The CI will call the check and check-* targets and fail if it returns a non-zero exit code. Usage \u00b6 It's important to avoid adding any steps that may have flaky results to the check and check-* target. Reducing the runtime of the check phase by avoiding any lengthy processes is also advisable. This includes things like complex integrations tests or E2E tests that should have their own dedicated workflows. The goal of the check and check-* targets are to \"fail fast\" and avoid running a lengthy CI pipeline if there are immediate problems with the code. Some typical tasks that would be appropriate for the check or check-* target are as follows: Validating code format Linting code Running static analysis tools (i.e. vulnerability scanners) Build \u00b6 Summary \u00b6 The build target is responsible for building artifacts. It serves two purposes: To validate that a given build works prior to performing any other steps To cache the build so future steps can re-use it without a performance impact. No additional tasks are performed before or after running the target. The target must pass before subsequent targets are called. How it Works \u00b6 The build target is the second target run in the CI pipeline and must pass before any other targets are run. The CI will call the build target and fail if it returns a non-zero exit code. Usage \u00b6 The build artifact should only be used for running \"build\" processes. What defines a build process is unique to each project. For example, it could be anything from compiling a binary to transpiling a medium into its final form (i.e., Typescript -> Javascript). Downstream targets should always depend on the build target for maximizing cache hits. For example, the test and release targets should either inherit from the build target or copy artifacts from it. Package \u00b6 Summary \u00b6 The package target is responsible for taking multiple artifacts and packaging them together. In mono-repos especially, deliverables sometime consist of more than one artifact being produced by different subprojects. This target is intended to provide an additional step where this packaging can happen before the test phase where these packages are usually utilized in E2E or integration testing. How it Works \u00b6 The package target is the third target run in the CI pipeline and must pass before any other targets are run. The CI will call the package target and fail if it returns a non-zero exit code. Usage \u00b6 The package target is very similar to the build target in that it should be used for building artifacts. However, the build target is geared specifically at building an artifact from the context of a single project (i.e., a single binary). The package target is instead focused on composing the outputs of multiple build artifacts into a single package. What constitutes a package is intentionally left vague, as the definition can change from project to project. In smaller repos, this target should be skipped. Test \u00b6 Summary \u00b6 The test and test-* targets are responsible for running tests to validate things are working as expected. The target is intended to be versatile, and can be used to run several different formats of testing. For example: Unit tests Smoke tests Integration tests How it Works \u00b6 The test and test-* targets are the fourth target run in the CI pipeline and must pass before any other targets are run. The CI will call the test and test-* targets and fail if it returns a non-zero exit code. Usage \u00b6 The test and test-* targets is intended to be versatile. In many cases, separate Earthfile s that are outside of the scope of a single subproject are created to hold test or test-* targets which runs integration tests. At the same time, individual subprojects may utilize this target to run their own unit tests. The only requirement is that the target should only be used to run tests. This target is the final target that is run (and must pass) before artifacts are released and/or published. Publish \u00b6 Summary \u00b6 The publish target is responsible for building and publishing a container image to image registries. This target should be used when a subproject needs to produce and publish a container image. The CI will execute this target after the test phase, assuming it passes. How it Works \u00b6 After executing the target, the CI will automatically detect the name and tag of the resulting image and save it for future steps. If the commit that triggered the CI is from a PR, the resulting image will not be published to an image registry. Instead, after building the image, the CI will immediately stop. This allows end-users to validate that an image is building correctly during the PR process without cluttering downstream image registries with incomplete and/or broken images. If the commit that triggered the CI is a merge into the default branch (i.e. main ), the resulting image is re-tagged with the commit hash and published to the Project Catalyst internal registry. If the resulting image is deployable, the CI will automatically deploy it to the dev cluster (i.e. dev.projectcatalyst.io ). This ensures that the dev cluster always reflects changes from the mainline branch. Finally, if the commit that triggered the CI contains a tag, the steps discussed in the previous section are also performed, but with additional steps. The resulting image is not only tagged with the commit hash, but also with the git tag contained in the commit. The image is also published to the public GHCR registry associated with the GitHub repository. Usage \u00b6 When creating the target image, the only requirement is that the target produce a single image at the end using SAVE IMAGE . It's recommended that you use the latest tag, as by default the CI ignores the tag produced by the target. The CI will automatically handle auxiliary tasks like image scanning and/or signing, so these steps should be omitted. Release \u00b6 The release target is responsible for building and releasing artifacts to GitHub. This target should be used when a subproject produces artifacts (i.e. a binary) that are appropriate to include in a GitHub release. For example, a subproject may produce a binary that is intended to be used directly (i.e. a CLI) or it may produce a set of files that end-users need access to during a release cycle. The CI will execute this target after the test target, assuming it passes. How it Works \u00b6 After executing the target, the CI will automatically detect any artifacts that were produced by the target and mark them to be saved. If the commit that triggered the CI does not contain a git tag, then the CI will immediately stop. This allows end-users to validate that their release artifacts build as expected without relying on a release cycle. If instead the commit contains a git tag, then the resulting artifacts are compressed into a single tarball and uploaded as an artifact of the individual GitHub Action job. The compression happens regardless of whether a single or multiple artifacts were produced. After the release target has been run for every subproject, the produced artifacts from all subprojects are then attached into a single GitHub release for the given git tag (i.e., 1.0.0 ). Usage \u00b6 When creating the release image, you may use as many SAVE ARTIFACT statements as you would like, however, it's recommended to only use one. At a minimum, the target must produce at least a single artifact. An artifact may be a single file, multiple files, or even a complex folder structure. Artifacts should have some relevance for a GitHub release. For example, making the target save the local source code is redundant since GitHub automatically includes all source code when a new release is created. However, a consumer may want to be able to download precompiled versions of a binary (without relying on a container). In this case, it makes sense to create a release target that produces the binary as an artifact. Note Targets can be written in 2 patterns target and target-* . The wildcard * serves as a regular search term, representing one or more other characters. Specifically, one or more numbers or lowercase characters. Warning Wildcard ( target-* ) is only compatible with targets that do not produce any artifacts or images. The current design is only supported in the check and test stages.","title":"Targets"},{"location":"reference/targets/#targets","text":"As discussed in onboarding, the Catalyst CI automatically searches for and executes distinct Earthly targets. By creating these targets in your Earthfile , you can hook into the Catalyst CI process with minimal effort. This section is dedicated to explaining what these targets are, how they work, and how to use them. Tip The targets discussed below are not required to be implemented in every single Earthfile . Consider each target a building block that can be composed into a complete structure that CI runs. The system is meant to be adaptable to different workflows.","title":"Targets"},{"location":"reference/targets/#check","text":"","title":"Check"},{"location":"reference/targets/#summary","text":"The check or check-* target is responsible for validating that given subproject is healthy and up to the appropriate standards. This target should be used by all subprojects to improve the upkeep of code. No additional tasks are performed before or after running the target.","title":"Summary"},{"location":"reference/targets/#how-it-works","text":"The check and check-* targets are the first target run in the CI pipeline and must pass before any other targets are run. The CI will call the check and check-* targets and fail if it returns a non-zero exit code.","title":"How it Works"},{"location":"reference/targets/#usage","text":"It's important to avoid adding any steps that may have flaky results to the check and check-* target. Reducing the runtime of the check phase by avoiding any lengthy processes is also advisable. This includes things like complex integrations tests or E2E tests that should have their own dedicated workflows. The goal of the check and check-* targets are to \"fail fast\" and avoid running a lengthy CI pipeline if there are immediate problems with the code. Some typical tasks that would be appropriate for the check or check-* target are as follows: Validating code format Linting code Running static analysis tools (i.e. vulnerability scanners)","title":"Usage"},{"location":"reference/targets/#build","text":"","title":"Build"},{"location":"reference/targets/#summary_1","text":"The build target is responsible for building artifacts. It serves two purposes: To validate that a given build works prior to performing any other steps To cache the build so future steps can re-use it without a performance impact. No additional tasks are performed before or after running the target. The target must pass before subsequent targets are called.","title":"Summary"},{"location":"reference/targets/#how-it-works_1","text":"The build target is the second target run in the CI pipeline and must pass before any other targets are run. The CI will call the build target and fail if it returns a non-zero exit code.","title":"How it Works"},{"location":"reference/targets/#usage_1","text":"The build artifact should only be used for running \"build\" processes. What defines a build process is unique to each project. For example, it could be anything from compiling a binary to transpiling a medium into its final form (i.e., Typescript -> Javascript). Downstream targets should always depend on the build target for maximizing cache hits. For example, the test and release targets should either inherit from the build target or copy artifacts from it.","title":"Usage"},{"location":"reference/targets/#package","text":"","title":"Package"},{"location":"reference/targets/#summary_2","text":"The package target is responsible for taking multiple artifacts and packaging them together. In mono-repos especially, deliverables sometime consist of more than one artifact being produced by different subprojects. This target is intended to provide an additional step where this packaging can happen before the test phase where these packages are usually utilized in E2E or integration testing.","title":"Summary"},{"location":"reference/targets/#how-it-works_2","text":"The package target is the third target run in the CI pipeline and must pass before any other targets are run. The CI will call the package target and fail if it returns a non-zero exit code.","title":"How it Works"},{"location":"reference/targets/#usage_2","text":"The package target is very similar to the build target in that it should be used for building artifacts. However, the build target is geared specifically at building an artifact from the context of a single project (i.e., a single binary). The package target is instead focused on composing the outputs of multiple build artifacts into a single package. What constitutes a package is intentionally left vague, as the definition can change from project to project. In smaller repos, this target should be skipped.","title":"Usage"},{"location":"reference/targets/#test","text":"","title":"Test"},{"location":"reference/targets/#summary_3","text":"The test and test-* targets are responsible for running tests to validate things are working as expected. The target is intended to be versatile, and can be used to run several different formats of testing. For example: Unit tests Smoke tests Integration tests","title":"Summary"},{"location":"reference/targets/#how-it-works_3","text":"The test and test-* targets are the fourth target run in the CI pipeline and must pass before any other targets are run. The CI will call the test and test-* targets and fail if it returns a non-zero exit code.","title":"How it Works"},{"location":"reference/targets/#usage_3","text":"The test and test-* targets is intended to be versatile. In many cases, separate Earthfile s that are outside of the scope of a single subproject are created to hold test or test-* targets which runs integration tests. At the same time, individual subprojects may utilize this target to run their own unit tests. The only requirement is that the target should only be used to run tests. This target is the final target that is run (and must pass) before artifacts are released and/or published.","title":"Usage"},{"location":"reference/targets/#publish","text":"","title":"Publish"},{"location":"reference/targets/#summary_4","text":"The publish target is responsible for building and publishing a container image to image registries. This target should be used when a subproject needs to produce and publish a container image. The CI will execute this target after the test phase, assuming it passes.","title":"Summary"},{"location":"reference/targets/#how-it-works_4","text":"After executing the target, the CI will automatically detect the name and tag of the resulting image and save it for future steps. If the commit that triggered the CI is from a PR, the resulting image will not be published to an image registry. Instead, after building the image, the CI will immediately stop. This allows end-users to validate that an image is building correctly during the PR process without cluttering downstream image registries with incomplete and/or broken images. If the commit that triggered the CI is a merge into the default branch (i.e. main ), the resulting image is re-tagged with the commit hash and published to the Project Catalyst internal registry. If the resulting image is deployable, the CI will automatically deploy it to the dev cluster (i.e. dev.projectcatalyst.io ). This ensures that the dev cluster always reflects changes from the mainline branch. Finally, if the commit that triggered the CI contains a tag, the steps discussed in the previous section are also performed, but with additional steps. The resulting image is not only tagged with the commit hash, but also with the git tag contained in the commit. The image is also published to the public GHCR registry associated with the GitHub repository.","title":"How it Works"},{"location":"reference/targets/#usage_4","text":"When creating the target image, the only requirement is that the target produce a single image at the end using SAVE IMAGE . It's recommended that you use the latest tag, as by default the CI ignores the tag produced by the target. The CI will automatically handle auxiliary tasks like image scanning and/or signing, so these steps should be omitted.","title":"Usage"},{"location":"reference/targets/#release","text":"The release target is responsible for building and releasing artifacts to GitHub. This target should be used when a subproject produces artifacts (i.e. a binary) that are appropriate to include in a GitHub release. For example, a subproject may produce a binary that is intended to be used directly (i.e. a CLI) or it may produce a set of files that end-users need access to during a release cycle. The CI will execute this target after the test target, assuming it passes.","title":"Release"},{"location":"reference/targets/#how-it-works_5","text":"After executing the target, the CI will automatically detect any artifacts that were produced by the target and mark them to be saved. If the commit that triggered the CI does not contain a git tag, then the CI will immediately stop. This allows end-users to validate that their release artifacts build as expected without relying on a release cycle. If instead the commit contains a git tag, then the resulting artifacts are compressed into a single tarball and uploaded as an artifact of the individual GitHub Action job. The compression happens regardless of whether a single or multiple artifacts were produced. After the release target has been run for every subproject, the produced artifacts from all subprojects are then attached into a single GitHub release for the given git tag (i.e., 1.0.0 ).","title":"How it Works"},{"location":"reference/targets/#usage_5","text":"When creating the release image, you may use as many SAVE ARTIFACT statements as you would like, however, it's recommended to only use one. At a minimum, the target must produce at least a single artifact. An artifact may be a single file, multiple files, or even a complex folder structure. Artifacts should have some relevance for a GitHub release. For example, making the target save the local source code is redundant since GitHub automatically includes all source code when a new release is created. However, a consumer may want to be able to download precompiled versions of a binary (without relying on a container). In this case, it makes sense to create a release target that produces the binary as an artifact. Note Targets can be written in 2 patterns target and target-* . The wildcard * serves as a regular search term, representing one or more other characters. Specifically, one or more numbers or lowercase characters. Warning Wildcard ( target-* ) is only compatible with targets that do not produce any artifacts or images. The current design is only supported in the check and test stages.","title":"Usage"},{"location":"reference/workflows/","text":"Workflows \u00b6 The Catalyst CI process works by combining several high-level reusable workflows into a single workflow that is used across all of our repositories. The purpose for this is to standardize the CI process across all repositories as well as provide control for easily updating the CI process without having to make changes across multiple repositories. This section gives a brief overview of these reusable workflows, which can aid in troubleshooting purposes. Overview \u00b6 Most reusable workflows have a one-to-one relationship with the Earthly targets discussed in the previous section: ci.yml is responsible for running the entire CI pipeline run.yml is responsible for executing targets with no additional steps (i.e., check , build , and package targets) publish.yml is responsible for handling the publish target release.yml is responsible for handling the release target Each workflow is self-contained and independent of the other workflows. However, in most cases, they are tied together with conditionals (i.e. publish only runs if check succeeds). Each workflow typically uses one or more custom GitHub Actions that are also provided by the Catalyst CI system. These individual actions will be discussed in the next section. Since most of the workflow logic was discussed in the previous section, this section will refrain from duplicating that effort and instead focus on how to use the workflows (including covering their inputs). Common Inputs \u00b6 AWS \u00b6 Most of the workflows accept an optional AWS role and region. The workflow will attempt to automatically authenticate and assume the role prior to performing any other steps. In most cases, this is necessary, because the Catalyst CI uses a remote Earthly runner to improve caching efforts. The credentials for the remote runner are held in AWS and need to be retrieved by the workflow. The only other case where AWS authentication is required is during the publish workflow where images are pushed to ECR. Name Type Description Required Default aws_role_arn string The ARN of the AWS role that will be assumed by the workflow No \"\" aws_region string The AWS region that will be used by the workflow No \"\" Earthly Runner \u00b6 As noted above, Catalyst CI uses a remote Earthly runner in order to maximize cache hits. As a result, all workflows that interact with Earthly will accept optional inputs describing the address of the runner as well as the name of an AWS secret containing the authentication details. The workflow will configure the local GitHub runner using the TLS credentials retrieved from AWS so that it can successfully connect and interact with the remote Earthly runner. Name Type Description Required Default earthly_runner_address string The address of the Earthly runner that will be used No \"\" earthly_runner_secret string The ID of the AWS secret holding Earthly runner credentials No \"\" earthly_version string The version of Earthly to use. No latest CLI \u00b6 Most workflows utilize the custom CLI provided by the Catalyst CI repository. It's possible to specify a specific version of the CI to be installed (as opposed to the default of installing the latest). Name Type Description Required Default ci_cli_version string The version of the CI CLI to use. No latest CI \u00b6 The CI workflow is responsible for executing the entire CI pipeline. This workflow is a composition of the other reusable workflows covered in this section. It's purpose is to reduce the friction for introducing the CI process into a repository by consolidating it to a single workflow. Inputs \u00b6 Name Type Description Required Default aws_ecr_registry string The AWS ECR registry that will be used to publish images No \"\" force_artifact bool If true, the workflow will always produce an artifact No false tags string A line separated list of additional tags that will be applied to published images. No \"\" Run \u00b6 The run workflow is a general purpose workflow that discovers and executes a given Earthly target. Many of the CI steps follow this same pattern and this workflow serves the purpose of reducing boilerplate. For adding ad-hoc steps, specifically ones that just need to execute a target, this is the correct workflow to use. Inputs \u00b6 Name Type Description Required Default target string The target to discover and run Yes N/A Publish \u00b6 The publish workflow is responsible for performing the logic related to the publish target. It uses the custom run GitHub Action to execute the target and parse the name/tag of the resulting image. It then uses the custom push GitHub Action to re-tag the image and push it to the appropriate image registries. Inputs \u00b6 Name Type Description Required Default aws_ecr_registry string The AWS ECR registry that will be used to publish images No \"\" default_branch string The default branch of the repository. No master tags string A line separated list of additional tags that will be applied to published images. No \"\" target string The target used to mark check builds No publish Release \u00b6 The release workflow is responsible for performing logic related to the release target. It uses the custom run GitHub Action to execute the target and store the produced artifacts to a local directory on the runner. These artifacts are then compressed and ultimately uploaded as artifacts for the job and/or a new GitHub release. Inputs \u00b6 Name Type Description Required Default target string The target used to mark check builds No release force_artifact bool If true, the workflow will always produce an artifact No false Deploy \u00b6 The deploy workflow is responsible for deploying services to the Catalyst testing environments. It uses a similar auto-discovery mechanism as the main workflows except that it finds and reads deployment.yml files. Each deployment.yml file specifies one or more overrides that are necessary to deploy an updated image in our GitOps repository. The deploy workflow will automatically apply these overrides and commit the changes to the repository. Inputs \u00b6 Name Type Description Required Default deployment_repo string The URL of the repository to merge with No input-output-hk/catalyst-world environment string The target environment to deploy No dev Pages \u00b6 The pages workflow is responsible for building documentation and deploying to GitHub Pages. It can be configured to point to an Earthfile and target that produces static documentation. The workflow will execute the target, and if the commit is a merge to the default branch, push the resulting files to the gh_pages branch. Inputs \u00b6 Name Type Description Required Default earthfile string The path to the folder containing the Earthfile that will be built Yes N/A target string The target that will be used to build docs Yes N/A","title":"Workflows"},{"location":"reference/workflows/#workflows","text":"The Catalyst CI process works by combining several high-level reusable workflows into a single workflow that is used across all of our repositories. The purpose for this is to standardize the CI process across all repositories as well as provide control for easily updating the CI process without having to make changes across multiple repositories. This section gives a brief overview of these reusable workflows, which can aid in troubleshooting purposes.","title":"Workflows"},{"location":"reference/workflows/#overview","text":"Most reusable workflows have a one-to-one relationship with the Earthly targets discussed in the previous section: ci.yml is responsible for running the entire CI pipeline run.yml is responsible for executing targets with no additional steps (i.e., check , build , and package targets) publish.yml is responsible for handling the publish target release.yml is responsible for handling the release target Each workflow is self-contained and independent of the other workflows. However, in most cases, they are tied together with conditionals (i.e. publish only runs if check succeeds). Each workflow typically uses one or more custom GitHub Actions that are also provided by the Catalyst CI system. These individual actions will be discussed in the next section. Since most of the workflow logic was discussed in the previous section, this section will refrain from duplicating that effort and instead focus on how to use the workflows (including covering their inputs).","title":"Overview"},{"location":"reference/workflows/#common-inputs","text":"","title":"Common Inputs"},{"location":"reference/workflows/#aws","text":"Most of the workflows accept an optional AWS role and region. The workflow will attempt to automatically authenticate and assume the role prior to performing any other steps. In most cases, this is necessary, because the Catalyst CI uses a remote Earthly runner to improve caching efforts. The credentials for the remote runner are held in AWS and need to be retrieved by the workflow. The only other case where AWS authentication is required is during the publish workflow where images are pushed to ECR. Name Type Description Required Default aws_role_arn string The ARN of the AWS role that will be assumed by the workflow No \"\" aws_region string The AWS region that will be used by the workflow No \"\"","title":"AWS"},{"location":"reference/workflows/#earthly-runner","text":"As noted above, Catalyst CI uses a remote Earthly runner in order to maximize cache hits. As a result, all workflows that interact with Earthly will accept optional inputs describing the address of the runner as well as the name of an AWS secret containing the authentication details. The workflow will configure the local GitHub runner using the TLS credentials retrieved from AWS so that it can successfully connect and interact with the remote Earthly runner. Name Type Description Required Default earthly_runner_address string The address of the Earthly runner that will be used No \"\" earthly_runner_secret string The ID of the AWS secret holding Earthly runner credentials No \"\" earthly_version string The version of Earthly to use. No latest","title":"Earthly Runner"},{"location":"reference/workflows/#cli","text":"Most workflows utilize the custom CLI provided by the Catalyst CI repository. It's possible to specify a specific version of the CI to be installed (as opposed to the default of installing the latest). Name Type Description Required Default ci_cli_version string The version of the CI CLI to use. No latest","title":"CLI"},{"location":"reference/workflows/#ci","text":"The CI workflow is responsible for executing the entire CI pipeline. This workflow is a composition of the other reusable workflows covered in this section. It's purpose is to reduce the friction for introducing the CI process into a repository by consolidating it to a single workflow.","title":"CI"},{"location":"reference/workflows/#inputs","text":"Name Type Description Required Default aws_ecr_registry string The AWS ECR registry that will be used to publish images No \"\" force_artifact bool If true, the workflow will always produce an artifact No false tags string A line separated list of additional tags that will be applied to published images. No \"\"","title":"Inputs"},{"location":"reference/workflows/#run","text":"The run workflow is a general purpose workflow that discovers and executes a given Earthly target. Many of the CI steps follow this same pattern and this workflow serves the purpose of reducing boilerplate. For adding ad-hoc steps, specifically ones that just need to execute a target, this is the correct workflow to use.","title":"Run"},{"location":"reference/workflows/#inputs_1","text":"Name Type Description Required Default target string The target to discover and run Yes N/A","title":"Inputs"},{"location":"reference/workflows/#publish","text":"The publish workflow is responsible for performing the logic related to the publish target. It uses the custom run GitHub Action to execute the target and parse the name/tag of the resulting image. It then uses the custom push GitHub Action to re-tag the image and push it to the appropriate image registries.","title":"Publish"},{"location":"reference/workflows/#inputs_2","text":"Name Type Description Required Default aws_ecr_registry string The AWS ECR registry that will be used to publish images No \"\" default_branch string The default branch of the repository. No master tags string A line separated list of additional tags that will be applied to published images. No \"\" target string The target used to mark check builds No publish","title":"Inputs"},{"location":"reference/workflows/#release","text":"The release workflow is responsible for performing logic related to the release target. It uses the custom run GitHub Action to execute the target and store the produced artifacts to a local directory on the runner. These artifacts are then compressed and ultimately uploaded as artifacts for the job and/or a new GitHub release.","title":"Release"},{"location":"reference/workflows/#inputs_3","text":"Name Type Description Required Default target string The target used to mark check builds No release force_artifact bool If true, the workflow will always produce an artifact No false","title":"Inputs"},{"location":"reference/workflows/#deploy","text":"The deploy workflow is responsible for deploying services to the Catalyst testing environments. It uses a similar auto-discovery mechanism as the main workflows except that it finds and reads deployment.yml files. Each deployment.yml file specifies one or more overrides that are necessary to deploy an updated image in our GitOps repository. The deploy workflow will automatically apply these overrides and commit the changes to the repository.","title":"Deploy"},{"location":"reference/workflows/#inputs_4","text":"Name Type Description Required Default deployment_repo string The URL of the repository to merge with No input-output-hk/catalyst-world environment string The target environment to deploy No dev","title":"Inputs"},{"location":"reference/workflows/#pages","text":"The pages workflow is responsible for building documentation and deploying to GitHub Pages. It can be configured to point to an Earthfile and target that produces static documentation. The workflow will execute the target, and if the commit is a merge to the default branch, push the resulting files to the gh_pages branch.","title":"Pages"},{"location":"reference/workflows/#inputs_5","text":"Name Type Description Required Default earthfile string The path to the folder containing the Earthfile that will be built Yes N/A target string The target that will be used to build docs Yes N/A","title":"Inputs"},{"location":"style/","text":"Style Guide \u00b6 Introduction \u00b6 This style guide is intended for individuals who are contributing towards the various Earthfile s within Catalyst repositories. It provides a set of standards that we use in creating these files. In most circumstances, the standards provided by this style guide should not be violated. If an exception must me made, the rationale should be included in the respective PR. Any Earthfile which does not adhere to this style guide will be rejected if no further justification is made. Organization \u00b6 Adhere to a consistent structure \u00b6 The following structure should be used to provide a consistent structure to Earthfile s: VERSION 0.8 # Should be the same across the repository # Use IMPORT to enhance the readability and consistency IMPORT ../other_project as other-project deps: FROM <base image> # This target should download and install all external dependencies. This # includes language dependencies as well as system dependencies. src: FROM +deps # This target should copy in all source code. # By doing this, it makes it clear what's considered source code. # It also consolidates this step to a single target and avoids trying to # track the source files across multiple targets. check: FROM +src # This target is used by the CI and should perform linting/formatting/static # analysis checks. build: FROM +src SAVE ARTIFACT ./artifact # This target is used by the CI and should be used to build the project. package: FROM +build COPY ./artifact pkg COPY other-project+build/artifact pkg # This target is uncommon in most Earthfiles, however, certain subprojects # have dependencies on other subprojects which should be defined in this # target. We define it here to serve as an example, however, we don't use it # in future steps. test: FROM +build # This target is used by the CI and should be used to running all tests that # are related to the project. This includes unit tests and basic smoke tests. release: FROM +build SAVE ARTIFACT ./artifact # This target is used by the CI and should use `SAVE ARTIFACT` to save the # result of the build step in cases where the artifact should be included # with the GitHub release (i.e., things that are self-contained like CLIs). # Note that in many cases, this will look identical to the `build` step. # However, to the CI, these are two distinct steps. Also, in some cases, the # release target may have additional steps to perform. publish: FROM <base image> COPY +build/artifact . SAVE IMAGE image:latest # This target is used by the CI and should use `SAVE IMAGE` to save a # container image that should be published to a registry by the CI. It # typically copies artifacts from the build target and then sets up the # required container environment. While the above structure is not perfect for every situation, it's flexible enough to meet most requirements. When steering away from this structure, every effort should be made to keep as much of it as possible for the sake of consistency. Avoid using the base target \u00b6 Every Earthfile has an invisible \"base\" target. This target is made up of the commands that appear outside of an existing target. For example: VERSION 0.8 FROM ubuntu:latest # Apart of the base target WORKDIR /work # Apart of the base target By default, any target which does not inherit from a base image will use the FROM statement included in the base target. This can become especially confusing when the target is far away from the base target which is usually put at the beginning of the file. There's no technical advantage for using the base target, and at most it makes code a bit more DRY. However, this comes at the expense of clarity. As such, the base target should be avoided, and individual targets should be clear about their intentions: VERSION 0.8 deps: FROM ubuntu:latest WORKDIR /work Syntax \u00b6 Always tag remote Earthfile references \u00b6 When referencing an Earthfile from another repository, always append a git tag to it. For example: DO github.com/input-output-hk/catalyst-ci/earthly/udc+NAME:tag Where tag is the git tag. This ensures that upstream changes do not incidentally break builds. Avoid LOCALLY \u00b6 The LOCALLY directive causes Earthly to execute all commands on the local machine instead of inside of a container. This directive is useful for troubleshooting, but otherwise it fits a very small number of use cases. The official Earthly best practices document recommends against using this directive in most cases. It can be destructive, complete with different results each time, and by default is not run during CI. For these reasons, usage of it should be avoided where possible. Avoid --no-cache \u00b6 The RUN command allows passing a --no-cache flag which will force Earthly to skip caching this particular command. The result is that the cache will always be broken at this step. This is especially frustrating when downstream targets inherit a target using this flag and all caching proceeds to immediately stop. To prevent this, the --no-cache should be avoided at all times. The only acceptable time to use it is for debugging purposes. Keep build as the source of truth for build artifacts \u00b6 The build target should be used as the single source of truth for building a given subproject's artifacts. The target may call other targets to accomplish the build, however, the build target should contain the authoritative source. Practically, this means that a subproject should only have one way to build it (via the build target). In addition to the above, targets which rely on built artifacts should always reference build . This can be through inheriting from it or by directly copying artifacts. The main point is that a subproject should not have multiple builds scattered in various places. Each subproject has an authoritative build target that all targets use when fetching build artifacts. Prefer FUNCTION \u00b6 The primary purpose of a FUNCTION is to reduce boilerplate and promote reusing common workflows. Many build patterns tend to be repetitive. For example, copying a package lockfile and installing dependencies is very common. In these cases, a FUNCTION should be preferred. The catalyst-ci repository provides a number of FUNCTIONs in the earthly subdirectory. These should be used prior to writing a new one. If a common use case is not covered in this subdirectory, a PR should be opened to add it. The use of FUNCTIONs in Earthly contributes to a more modular and organized build system, enhancing code readability and maintainability. Use IMPORT when calling on Target or FUNCTION from other Earthfile \u00b6 Instead of referencing other Target or FUNCTION using path, importing the entire Earthfile with the IMPORT command is preferable. This is helpful when several targets in other accessible Earthfile need to be used. Also, this enhance the readability of the code. For example, instead of VERSION 0.8 package: FROM +build COPY ./artifact pkg COPY ../other_project+build/artifact pkg use this IMPORT command VERSION 0.8 IMPORT ../other_project as other-project package: FROM +build COPY ./artifact pkg COPY other-project+build/artifact pkg","title":"Style Guide"},{"location":"style/#style-guide","text":"","title":"Style Guide"},{"location":"style/#introduction","text":"This style guide is intended for individuals who are contributing towards the various Earthfile s within Catalyst repositories. It provides a set of standards that we use in creating these files. In most circumstances, the standards provided by this style guide should not be violated. If an exception must me made, the rationale should be included in the respective PR. Any Earthfile which does not adhere to this style guide will be rejected if no further justification is made.","title":"Introduction"},{"location":"style/#organization","text":"","title":"Organization"},{"location":"style/#adhere-to-a-consistent-structure","text":"The following structure should be used to provide a consistent structure to Earthfile s: VERSION 0.8 # Should be the same across the repository # Use IMPORT to enhance the readability and consistency IMPORT ../other_project as other-project deps: FROM <base image> # This target should download and install all external dependencies. This # includes language dependencies as well as system dependencies. src: FROM +deps # This target should copy in all source code. # By doing this, it makes it clear what's considered source code. # It also consolidates this step to a single target and avoids trying to # track the source files across multiple targets. check: FROM +src # This target is used by the CI and should perform linting/formatting/static # analysis checks. build: FROM +src SAVE ARTIFACT ./artifact # This target is used by the CI and should be used to build the project. package: FROM +build COPY ./artifact pkg COPY other-project+build/artifact pkg # This target is uncommon in most Earthfiles, however, certain subprojects # have dependencies on other subprojects which should be defined in this # target. We define it here to serve as an example, however, we don't use it # in future steps. test: FROM +build # This target is used by the CI and should be used to running all tests that # are related to the project. This includes unit tests and basic smoke tests. release: FROM +build SAVE ARTIFACT ./artifact # This target is used by the CI and should use `SAVE ARTIFACT` to save the # result of the build step in cases where the artifact should be included # with the GitHub release (i.e., things that are self-contained like CLIs). # Note that in many cases, this will look identical to the `build` step. # However, to the CI, these are two distinct steps. Also, in some cases, the # release target may have additional steps to perform. publish: FROM <base image> COPY +build/artifact . SAVE IMAGE image:latest # This target is used by the CI and should use `SAVE IMAGE` to save a # container image that should be published to a registry by the CI. It # typically copies artifacts from the build target and then sets up the # required container environment. While the above structure is not perfect for every situation, it's flexible enough to meet most requirements. When steering away from this structure, every effort should be made to keep as much of it as possible for the sake of consistency.","title":"Adhere to a consistent structure"},{"location":"style/#avoid-using-the-base-target","text":"Every Earthfile has an invisible \"base\" target. This target is made up of the commands that appear outside of an existing target. For example: VERSION 0.8 FROM ubuntu:latest # Apart of the base target WORKDIR /work # Apart of the base target By default, any target which does not inherit from a base image will use the FROM statement included in the base target. This can become especially confusing when the target is far away from the base target which is usually put at the beginning of the file. There's no technical advantage for using the base target, and at most it makes code a bit more DRY. However, this comes at the expense of clarity. As such, the base target should be avoided, and individual targets should be clear about their intentions: VERSION 0.8 deps: FROM ubuntu:latest WORKDIR /work","title":"Avoid using the base target"},{"location":"style/#syntax","text":"","title":"Syntax"},{"location":"style/#always-tag-remote-earthfile-references","text":"When referencing an Earthfile from another repository, always append a git tag to it. For example: DO github.com/input-output-hk/catalyst-ci/earthly/udc+NAME:tag Where tag is the git tag. This ensures that upstream changes do not incidentally break builds.","title":"Always tag remote Earthfile references"},{"location":"style/#avoid-locally","text":"The LOCALLY directive causes Earthly to execute all commands on the local machine instead of inside of a container. This directive is useful for troubleshooting, but otherwise it fits a very small number of use cases. The official Earthly best practices document recommends against using this directive in most cases. It can be destructive, complete with different results each time, and by default is not run during CI. For these reasons, usage of it should be avoided where possible.","title":"Avoid LOCALLY"},{"location":"style/#avoid-no-cache","text":"The RUN command allows passing a --no-cache flag which will force Earthly to skip caching this particular command. The result is that the cache will always be broken at this step. This is especially frustrating when downstream targets inherit a target using this flag and all caching proceeds to immediately stop. To prevent this, the --no-cache should be avoided at all times. The only acceptable time to use it is for debugging purposes.","title":"Avoid --no-cache"},{"location":"style/#keep-build-as-the-source-of-truth-for-build-artifacts","text":"The build target should be used as the single source of truth for building a given subproject's artifacts. The target may call other targets to accomplish the build, however, the build target should contain the authoritative source. Practically, this means that a subproject should only have one way to build it (via the build target). In addition to the above, targets which rely on built artifacts should always reference build . This can be through inheriting from it or by directly copying artifacts. The main point is that a subproject should not have multiple builds scattered in various places. Each subproject has an authoritative build target that all targets use when fetching build artifacts.","title":"Keep build as the source of truth for build artifacts"},{"location":"style/#prefer-function","text":"The primary purpose of a FUNCTION is to reduce boilerplate and promote reusing common workflows. Many build patterns tend to be repetitive. For example, copying a package lockfile and installing dependencies is very common. In these cases, a FUNCTION should be preferred. The catalyst-ci repository provides a number of FUNCTIONs in the earthly subdirectory. These should be used prior to writing a new one. If a common use case is not covered in this subdirectory, a PR should be opened to add it. The use of FUNCTIONs in Earthly contributes to a more modular and organized build system, enhancing code readability and maintainability.","title":"Prefer FUNCTION"},{"location":"style/#use-import-when-calling-on-target-or-function-from-other-earthfile","text":"Instead of referencing other Target or FUNCTION using path, importing the entire Earthfile with the IMPORT command is preferable. This is helpful when several targets in other accessible Earthfile need to be used. Also, this enhance the readability of the code. For example, instead of VERSION 0.8 package: FROM +build COPY ./artifact pkg COPY ../other_project+build/artifact pkg use this IMPORT command VERSION 0.8 IMPORT ../other_project as other-project package: FROM +build COPY ./artifact pkg COPY other-project+build/artifact pkg","title":"Use IMPORT when calling on Target or FUNCTION from other Earthfile"},{"location":"architecture/09_architecture_decisions/","text":"Architecture Decisions \u00b6 Index graph TD 0001-arch-std[0001 Architecture Documentation Standard] click 0001-arch-std \"/catalyst-ci/architecture/09_architecture_decisions/0001-arch-std/\" _blank 0001-arch-std:::mermaid-accepted 0001-arch-std:::mermaid-common 0002-adr[0002 Architecture Decision Records] click 0002-adr \"/catalyst-ci/architecture/09_architecture_decisions/0002-adr/\" _blank 0002-adr:::mermaid-accepted 0002-adr:::mermaid-common 0001-arch-std -- Extended --> 0002-adr 0003-language[0003 Language] click 0003-language \"/catalyst-ci/architecture/09_architecture_decisions/0003-language/\" _blank 0003-language:::mermaid-accepted 0003-language:::mermaid-common 0004-spelling[0004 Spelling] click 0004-spelling \"/catalyst-ci/architecture/09_architecture_decisions/0004-spelling/\" _blank 0004-spelling:::mermaid-accepted 0004-spelling:::mermaid-common 0003-language -- Extended --> 0004-spelling 0005-rust[0005 Rust] click 0005-rust \"/catalyst-ci/architecture/09_architecture_decisions/0005-rust/\" _blank 0005-rust:::mermaid-draft 0005-rust:::mermaid-common 0006-rust-cargo-lock[0006 Rust Cargo Lock] click 0006-rust-cargo-lock \"/catalyst-ci/architecture/09_architecture_decisions/0006-rust-cargo-lock/\" _blank 0006-rust-cargo-lock:::mermaid-accepted 0006-rust-cargo-lock:::mermaid-common 0005-rust -- Extended --> 0006-rust-cargo-lock 0007-minimum-rust-version-supported[0007 Rust Version configuration in `cargo.toml`] click 0007-minimum-rust-version-supported \"/catalyst-ci/architecture/09_architecture_decisions/0007-minimum-rust-version-supported/\" _blank 0007-minimum-rust-version-supported:::mermaid-accepted 0007-minimum-rust-version-supported:::mermaid-common 0005-rust -- Extended --> 0007-minimum-rust-version-supported classDef mermaid-draft fill:#a3a3a3; classDef mermaid-common color:#595959; classDef mermaid-proposed fill:#b6d8ff; classDef mermaid-common color:#595959; classDef mermaid-accepted fill:#b4eda0; classDef mermaid-common color:#595959; classDef mermaid-rejected fill:#ffd5d1; classDef mermaid-common color:#595959; classDef mermaid-superseded fill:#ffebb6; classDef mermaid-common color:#595959;","title":"Architecture Decisions"},{"location":"architecture/09_architecture_decisions/#architecture-decisions","text":"Index graph TD 0001-arch-std[0001 Architecture Documentation Standard] click 0001-arch-std \"/catalyst-ci/architecture/09_architecture_decisions/0001-arch-std/\" _blank 0001-arch-std:::mermaid-accepted 0001-arch-std:::mermaid-common 0002-adr[0002 Architecture Decision Records] click 0002-adr \"/catalyst-ci/architecture/09_architecture_decisions/0002-adr/\" _blank 0002-adr:::mermaid-accepted 0002-adr:::mermaid-common 0001-arch-std -- Extended --> 0002-adr 0003-language[0003 Language] click 0003-language \"/catalyst-ci/architecture/09_architecture_decisions/0003-language/\" _blank 0003-language:::mermaid-accepted 0003-language:::mermaid-common 0004-spelling[0004 Spelling] click 0004-spelling \"/catalyst-ci/architecture/09_architecture_decisions/0004-spelling/\" _blank 0004-spelling:::mermaid-accepted 0004-spelling:::mermaid-common 0003-language -- Extended --> 0004-spelling 0005-rust[0005 Rust] click 0005-rust \"/catalyst-ci/architecture/09_architecture_decisions/0005-rust/\" _blank 0005-rust:::mermaid-draft 0005-rust:::mermaid-common 0006-rust-cargo-lock[0006 Rust Cargo Lock] click 0006-rust-cargo-lock \"/catalyst-ci/architecture/09_architecture_decisions/0006-rust-cargo-lock/\" _blank 0006-rust-cargo-lock:::mermaid-accepted 0006-rust-cargo-lock:::mermaid-common 0005-rust -- Extended --> 0006-rust-cargo-lock 0007-minimum-rust-version-supported[0007 Rust Version configuration in `cargo.toml`] click 0007-minimum-rust-version-supported \"/catalyst-ci/architecture/09_architecture_decisions/0007-minimum-rust-version-supported/\" _blank 0007-minimum-rust-version-supported:::mermaid-accepted 0007-minimum-rust-version-supported:::mermaid-common 0005-rust -- Extended --> 0007-minimum-rust-version-supported classDef mermaid-draft fill:#a3a3a3; classDef mermaid-common color:#595959; classDef mermaid-proposed fill:#b6d8ff; classDef mermaid-common color:#595959; classDef mermaid-accepted fill:#b4eda0; classDef mermaid-common color:#595959; classDef mermaid-rejected fill:#ffd5d1; classDef mermaid-common color:#595959; classDef mermaid-superseded fill:#ffebb6; classDef mermaid-common color:#595959;","title":"Architecture Decisions"}]}